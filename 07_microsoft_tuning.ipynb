{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf98a9e1-f3e0-4c0a-96c1-30f305901246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.9.18 (main, Oct 24 2023, 09:18:18) \n",
      "[GCC 11.4.0]\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "11.8 8\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple, Union, Any, Optional\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "print(\"Python version\", sys.version)\n",
    "\n",
    "# Ignore pandas warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "\n",
    "from src.datasets import daocensus\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "sys_details = tf.sysconfig.get_build_info()\n",
    "cuda = sys_details.get(\"cuda_version\", -1)\n",
    "cudnn = sys_details.get(\"cudnn_version\", -1)\n",
    "print(cuda, cudnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "798161a7-5414-4626-9dfb-6d71823bf4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Others config\n",
    "SEED: int = 57\n",
    "RAY_RESULTS_PATH: Path = Path('~/ray_results').expanduser()\n",
    "\n",
    "# Dataset splits config\n",
    "N_SPLITS: int = 10\n",
    "SKIP_SPLIT: int = 0\n",
    "\n",
    "# Training config\n",
    "MAX_EPOCHS: int = 200\n",
    "EPOCHS_PER_ITER: int = 5\n",
    "\n",
    "# Eval config\n",
    "TOP_K: List[int] = [5, 10]\n",
    "METRICS: List[str] = [\"recall\", \"ndcg\", \"precision\", \"map\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ff2f2-bdaa-46eb-87d1-c4481734b8c0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "765a4892-6a85-40ab-a65d-c0d76b0569b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116560 entries, 0 to 116559\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   platform       116560 non-null  object        \n",
      " 1   name           116560 non-null  object        \n",
      " 2   id             116560 non-null  object        \n",
      " 3   proposal       116560 non-null  category      \n",
      " 4   deployment     116560 non-null  object        \n",
      " 5   platform_vote  116560 non-null  object        \n",
      " 6   voter          116560 non-null  object        \n",
      " 7   date           116560 non-null  datetime64[ns]\n",
      " 8   choice         116560 non-null  object        \n",
      " 9   weight         116560 non-null  float64       \n",
      "dtypes: category(1), datetime64[ns](1), float64(1), object(7)\n",
      "memory usage: 8.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1942 entries, 0 to 1941\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   platform             1942 non-null   object        \n",
      " 1   name                 1942 non-null   object        \n",
      " 2   platform_deployment  1942 non-null   object        \n",
      " 3   id                   1942 non-null   category      \n",
      " 4   deployment           1942 non-null   object        \n",
      " 5   platform_proposal    1942 non-null   object        \n",
      " 6   author               1942 non-null   category      \n",
      " 7   date                 1942 non-null   datetime64[ns]\n",
      " 8   votes_count          1942 non-null   int64         \n",
      " 9   proposal_id          1942 non-null   object        \n",
      " 10  title                1942 non-null   object        \n",
      " 11  description          1942 non-null   object        \n",
      " 12  start                1942 non-null   datetime64[ns]\n",
      " 13  end                  1942 non-null   datetime64[ns]\n",
      "dtypes: category(2), datetime64[ns](3), int64(1), object(8)\n",
      "memory usage: 599.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dfptext = pd.read_csv('./snapshot_proposals.csv')[['proposal_id', 'title', 'description', 'start', 'end']]\n",
    "dfv, dfp = daocensus.get(\"./data/daos-census\", 'Decentraland', 'snapshot')\n",
    "dfv['voter'] = dfv['voter'].astype('str')\n",
    "dfp = dfp.merge(dfptext, how='left', left_on='platform_proposal', right_on='proposal_id')\n",
    "dfp[['start', 'end']] = dfp[['start', 'end']].astype('datetime64')\n",
    "print(dfv.info())\n",
    "print(dfp.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df339c08-4f99-4933-886c-6ab774f09e63",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b003927-cfab-4f9a-91f8-1376f038f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xe7af1c70f8f089c4c3bd71999692c6c5a15d9e2a</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-17 12:28:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xc54a6c3778016b06cbd126ccc3b5bc06c5f666fb</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-17 02:16:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xd82d005e8f8d5385db40ba23884a5c967bb1e8af</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-17 00:38:22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xf4c64db66ffb301985f5ecd85c8f3f9c02f2659d</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-16 18:47:08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xd5e9ef1cedad0d135d543d286a2c190b16cbb89e</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-16 18:32:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       userID  \\\n",
       "0  0xe7af1c70f8f089c4c3bd71999692c6c5a15d9e2a   \n",
       "1  0xc54a6c3778016b06cbd126ccc3b5bc06c5f666fb   \n",
       "2  0xd82d005e8f8d5385db40ba23884a5c967bb1e8af   \n",
       "3  0xf4c64db66ffb301985f5ecd85c8f3f9c02f2659d   \n",
       "4  0xd5e9ef1cedad0d135d543d286a2c190b16cbb89e   \n",
       "\n",
       "                                 itemID           timestamp  rating  \n",
       "0  b86aa059-3d31-5d41-a472-70962816f779 2021-12-17 12:28:01       1  \n",
       "1  b86aa059-3d31-5d41-a472-70962816f779 2021-12-17 02:16:23       1  \n",
       "2  b86aa059-3d31-5d41-a472-70962816f779 2021-12-17 00:38:22       1  \n",
       "3  b86aa059-3d31-5d41-a472-70962816f779 2021-12-16 18:47:08       1  \n",
       "4  b86aa059-3d31-5d41-a472-70962816f779 2021-12-16 18:32:15       1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_microsoft(dfv):\n",
    "    df = dfv[['voter', 'proposal', 'date']].rename(columns={\n",
    "        'voter': 'userID',\n",
    "        'proposal': 'itemID',\n",
    "        'date': 'timestamp',\n",
    "    })\n",
    "    df['itemID'] = df['itemID'].astype('str')\n",
    "    df['rating'] = 1\n",
    "    return df\n",
    "\n",
    "df = to_microsoft(dfv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faab8dc-8192-47b5-96df-7458bd890ffb",
   "metadata": {},
   "source": [
    "# Split data\n",
    "\n",
    "Each proposal remains open for a few days, our environment is different of a movies recommender system. For this reason, we will use a TimeSeriesSplit instead of a K-Fold to cross-validate the model.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_013.png)\n",
    "\n",
    "El TimeSeriesSplit de scikit-learn no nos vale porque el número de elementos en cada split es el mismo, pero el tamaño del intervalo, no. Como queremos simular un comportamiento realista, haremos el split dividiendo por intervalos de igual longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f661ac7-df23-49ad-9671-cfa65d4b44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import metrics as metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "445d9909-609a-4cf3-8e24-6fa36946a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0, train from: 2021-05-24 to 2021-08-04, test from: 2021-08-04 to 2021-08-10\n",
      "  len(train): 3453, len(test): 48\n",
      "  users(train): 581, users(test): 27\n",
      "\n",
      "  highest possible recall@5:\t0.9894\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.3407\n",
      "  highest possible map@5:\t0.9894\n",
      "------------------------------\n",
      "Split 1, train from: 2021-08-04 to 2021-10-14, test from: 2021-10-15 to 2021-10-19\n",
      "  len(train): 6397, len(test): 132\n",
      "  users(train): 930, users(test): 121\n",
      "\n",
      "  highest possible recall@5:\t0.9976\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.2149\n",
      "  highest possible map@5:\t0.9976\n",
      "------------------------------\n",
      "Split 2, train from: 2021-10-14 to 2021-12-25, test from: 2021-12-25 to 2021-12-31\n",
      "  len(train): 15187, len(test): 99\n",
      "  users(train): 2388, users(test): 47\n",
      "\n",
      "  highest possible recall@5:\t0.9721\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.3660\n",
      "  highest possible map@5:\t0.9721\n",
      "------------------------------\n",
      "Split 3, train from: 2021-12-25 to 2022-03-06, test from: 2022-03-06 to 2022-03-16\n",
      "  len(train): 23389, len(test): 157\n",
      "  users(train): 3227, users(test): 79\n",
      "\n",
      "  highest possible recall@5:\t0.9859\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.3722\n",
      "  highest possible map@5:\t0.9859\n",
      "------------------------------\n",
      "Split 4, train from: 2022-03-06 to 2022-05-17, test from: 2022-05-17 to 2022-05-30\n",
      "  len(train): 28957, len(test): 283\n",
      "  users(train): 3714, users(test): 103\n",
      "\n",
      "  highest possible recall@5:\t0.9470\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.3592\n",
      "  highest possible map@5:\t0.9470\n",
      "------------------------------\n",
      "Split 5, train from: 2022-05-17 to 2022-07-27, test from: 2022-07-27 to 2022-08-10\n",
      "  len(train): 35766, len(test): 219\n",
      "  users(train): 4257, users(test): 103\n",
      "\n",
      "  highest possible recall@5:\t0.9715\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.3767\n",
      "  highest possible map@5:\t0.9715\n",
      "------------------------------\n",
      "Split 6, train from: 2022-07-27 to 2022-10-07, test from: 2022-10-07 to 2022-10-19\n",
      "  len(train): 45343, len(test): 252\n",
      "  users(train): 4710, users(test): 88\n",
      "\n",
      "  highest possible recall@5:\t0.9547\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4932\n",
      "  highest possible map@5:\t0.9547\n",
      "------------------------------\n",
      "Split 7, train from: 2022-10-07 to 2022-12-17, test from: 2022-12-18 to 2022-12-30\n",
      "  len(train): 58917, len(test): 566\n",
      "  users(train): 5265, users(test): 172\n",
      "\n",
      "  highest possible recall@5:\t0.9235\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4977\n",
      "  highest possible map@5:\t0.9235\n",
      "------------------------------\n",
      "Split 8, train from: 2022-12-17 to 2023-02-27, test from: 2023-02-27 to 2023-03-12\n",
      "  len(train): 84884, len(test): 161\n",
      "  users(train): 6406, users(test): 120\n",
      "\n",
      "  highest possible recall@5:\t1.0000\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.2683\n",
      "  highest possible map@5:\t1.0000\n",
      "------------------------------\n",
      "Split 9, train from: 2023-02-27 to 2023-05-10, test from: 2023-05-10 to 2023-05-22\n",
      "  len(train): 105988, len(test): 341\n",
      "  users(train): 6857, users(test): 125\n",
      "\n",
      "  highest possible recall@5:\t0.9616\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4720\n",
      "  highest possible map@5:\t0.9616\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.model_selection import timeIntervalSplit, timeIntervalSplitCurrent\n",
    "\n",
    "max_train_prev = df['timestamp'].min().date()\n",
    "folds = list(timeIntervalSplitCurrent(df, N_SPLITS, dfp, skip=SKIP_SPLIT, remove_not_in_train_col='userID', return_open=True))\n",
    "for i, (dftrain, dftest, t, open_proposals) in enumerate(folds):\n",
    "    min_train = dftrain['timestamp'].min().date()\n",
    "    max_train = dftrain['timestamp'].max().date()\n",
    "    min_test  = dftest['timestamp'].min().date()\n",
    "    max_test  = dftest['timestamp'].max().date()\n",
    "    train_diff = (max_train-max_train_prev).days\n",
    "    test_diff = (max_test-min_test).days\n",
    "\n",
    "    train_users = len(set(dftrain['userID']))\n",
    "    test_users = len(set(dftest['userID']))\n",
    "    \n",
    "    print(f\"Split {i}, train from: {max_train_prev} to {max_train}, test from: {min_test} to {max_test}\")\n",
    "    print(f\"  len(train): {len(dftrain)}, len(test): {len(dftest)}\")\n",
    "    print(f\"  users(train): {train_users}, users(test): {test_users}\")\n",
    "\n",
    "    print()\n",
    "    dftest['prediction'] = 1\n",
    "    for m in METRICS:\n",
    "        f = metrics_dict[f'{m}_at_k']\n",
    "        print(f\"  highest possible {m}@{TOP_K[0]}:\\t{f(dftest, dftest, k=TOP_K[0], relevancy_method='top_k'):.4f}\")\n",
    "\n",
    "    print(\"-\"*30)\n",
    "\n",
    "    max_train_prev = max_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c881c43-d308-40ff-b6b4-d54458e1bc32",
   "metadata": {},
   "source": [
    "# Defining training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a502e2d-3398-405f-9029-d3abc69033dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.utils.python_utils import get_top_k_scored_items\n",
    "\n",
    "class LightGCNCustom(LightGCN):\n",
    "    # Copied from LightGCN.fit but RETURNING the data and deleting unnecessary things\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.epochs_done = 0\n",
    "    \n",
    "    def fit_epoch(self):\n",
    "        \"\"\"Fit the model on self.data.train.\n",
    "        \"\"\"\n",
    "        loss, mf_loss, emb_loss = 0.0, 0.0, 0.0\n",
    "        n_batch = self.data.train.shape[0] // self.batch_size + 1\n",
    "        for idx in range(n_batch):\n",
    "            users, pos_items, neg_items = self.data.train_loader(self.batch_size)\n",
    "            _, batch_loss, batch_mf_loss, batch_emb_loss = self.sess.run(\n",
    "                [self.opt, self.loss, self.mf_loss, self.emb_loss],\n",
    "                feed_dict={\n",
    "                    self.users: users,\n",
    "                    self.pos_items: pos_items,\n",
    "                    self.neg_items: neg_items,\n",
    "                },\n",
    "            )\n",
    "            loss += batch_loss / n_batch\n",
    "            mf_loss += batch_mf_loss / n_batch\n",
    "            emb_loss += batch_emb_loss / n_batch\n",
    "\n",
    "        if np.isnan(loss):\n",
    "            print(\"ERROR: loss is nan.\")\n",
    "            sys.exit()\n",
    "\n",
    "        self.epochs_done += 1\n",
    "\n",
    "        return loss, mf_loss, emb_loss\n",
    "\n",
    "    def recommend_k_items(\n",
    "        self, test, top_k=10, sort_top_k=True, remove_seen=True, use_id=False, recommend_from=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Copy-pasted from LightGCN but adding the `recommend_from` argument\n",
    "        \"\"\"\n",
    "        data = self.data\n",
    "        if not use_id:\n",
    "            user_ids = np.array([data.user2id[x] for x in test[data.col_user].unique()])\n",
    "        else:\n",
    "            user_ids = np.array(test[data.col_user].unique())\n",
    "\n",
    "        test_scores = self.score(user_ids, remove_seen=remove_seen)\n",
    "\n",
    "        ### START NEW BEHAVIOUR\n",
    "        if recommend_from is not None:\n",
    "            from_idx = np.array([data.item2id[x] for x in set(recommend_from)])\n",
    "            msk = np.ones(test_scores.shape[1], bool)\n",
    "            msk[from_idx] = False\n",
    "\n",
    "            # Set the score of that proposal to zero for every user\n",
    "            test_scores[:, msk] = -np.inf\n",
    "        ### END NEW BEHAVIOUR\n",
    "\n",
    "        top_items, top_scores = get_top_k_scored_items(\n",
    "            scores=test_scores, top_k=top_k, sort_top_k=sort_top_k\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                data.col_user: np.repeat(\n",
    "                    test[data.col_user].drop_duplicates().values, top_items.shape[1]\n",
    "                ),\n",
    "                data.col_item: top_items.flatten()\n",
    "                if use_id\n",
    "                else [data.id2item[item] for item in top_items.flatten()],\n",
    "                data.col_prediction: top_scores.flatten(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return df.replace(-np.inf, np.nan).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923adb82-9733-4e21-a378-7263c5532353",
   "metadata": {},
   "source": [
    "## Small test of `LightGCNCustom`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41d1cf90-bd11-4a87-b0aa-bf0e25d559af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e57c58e-3091-4357-969a-c7bafedd29c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items: 1836 user: 6857\n",
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(\n",
    "    model_type='lightgcn',\n",
    "    n_layers=3,\n",
    "    batch_size=512,\n",
    "    embed_size=64,\n",
    "    epochs=2,\n",
    "    learning_rate=0.001,\n",
    "    decay=0.001,\n",
    "    metrics=[\"recall\", \"ndcg\", \"precision\", \"map\"],\n",
    "    eval_epoch=2,\n",
    "    top_k=TOP_K[0],\n",
    "    save_model=False,\n",
    "    MODEL_DIR='./data/model/lightgcn/',\n",
    ")\n",
    "dataloader = ImplicitCF(train=folds[-1][0], test=folds[-1][1], seed=SEED)\n",
    "print(\"items:\", dataloader.n_items, \"user:\", dataloader.n_users)\n",
    "model = LightGCNCustom(data=dataloader, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fe49e83-f291-4383-97c2-167a706ae717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (train)0.7s: train loss = 0.60012 = (mf)0.59938 + (embed)0.00075\n",
      "Epoch 2 (train)0.5s + (eval)0.1s: train loss = 0.35302 = (mf)0.34912 + (embed)0.00389, recall = 0.00400, ndcg = 0.00394, precision = 0.00320, map = 0.00200\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a12ab695-94f8-431e-8a7f-03bf17f2fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.004, 0.00394083821985168, 0.0032, 0.002]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.run_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b131c2d-6df2-4292-8f12-caaf409562ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293</td>\n",
       "      <td>1175</td>\n",
       "      <td>6.377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>293</td>\n",
       "      <td>1835</td>\n",
       "      <td>1.713224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.863316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>466</td>\n",
       "      <td>1835</td>\n",
       "      <td>1.273528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.401709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>245</td>\n",
       "      <td>1835</td>\n",
       "      <td>1.812435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.404130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>578</td>\n",
       "      <td>1175</td>\n",
       "      <td>3.914507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>578</td>\n",
       "      <td>1835</td>\n",
       "      <td>0.961036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.990316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID  itemID  prediction\n",
       "0       293    1175    6.377600\n",
       "1       293    1835    1.713224\n",
       "2       293       0   -4.863316\n",
       "3       466    1835    1.273528\n",
       "4       466       0   -1.401709\n",
       "..      ...     ...         ...\n",
       "369     245    1835    1.812435\n",
       "370     245       0   -5.404130\n",
       "372     578    1175    3.914507\n",
       "373     578    1835    0.961036\n",
       "374     578       0   -2.990316\n",
       "\n",
       "[303 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.recommend_k_items(dataloader.test, top_k=3, use_id=True, remove_seen=True, recommend_from={'b86aa059-3d31-5d41-a472-70962816f779', '56b4d333-4138-5aa3-9890-3502b9478079', 'd083109e-4819-54b9-a01c-67bd5a770f65' })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994a5dd-efe5-47bf-a8a1-803316d9fc75",
   "metadata": {},
   "source": [
    "# Defining trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5d010bf-3a9c-4931-9d02-6589b3164438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "class TrainLightGCN(tune.Trainable):\n",
    "    def setup(\n",
    "        self,\n",
    "        config: Dict[str, Any],\n",
    "        folds: List[Tuple[pd.DataFrame, pd.DataFrame]],\n",
    "    ):\n",
    "        self.config = config\n",
    "        config['batch_size'] = 2**config['batch_size']\n",
    "        # self.fold = config['__trial_index__']\n",
    "        self.fold = config['fold']\n",
    "\n",
    "        self.hparams = prepare_hparams(\n",
    "            model_type='lightgcn',\n",
    "            n_layers=config['conv_layers'],\n",
    "            batch_size=config['batch_size'],\n",
    "            embed_size=config['embedding_dim'],\n",
    "            epochs=EPOCHS_PER_ITER,\n",
    "            learning_rate=config['learning_rate'],\n",
    "            decay=config['l2'],\n",
    "            metrics=METRICS,\n",
    "            eval_epoch=-1,\n",
    "            top_k=TOP_K[0],\n",
    "            save_model=False,\n",
    "            MODEL_DIR='./data/model/lightgcn/',\n",
    "        )\n",
    "\n",
    "        train, test, self.t, self.open_proposals = folds[self.fold]\n",
    "        self.dataloader = ImplicitCF(train=train, test=test, seed=SEED)\n",
    "        self.model = LightGCNCustom(self.hparams, self.dataloader, seed=SEED)\n",
    "        self.total_train = 0\n",
    "        self.total_eval = 0\n",
    "\n",
    "    @property\n",
    "    def iteration(self):\n",
    "        return self.model.epochs_done\n",
    "\n",
    "    @property\n",
    "    def training_iteration(self):\n",
    "        return self.model.epochs_done\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        As a rule of thumb, the execution time of step should be large enough to avoid overheads \n",
    "        (i.e. more than a few seconds), but short enough to report progress periodically \n",
    "        (i.e. at most a few minutes).\n",
    "        \"\"\"\n",
    "        assert EPOCHS_PER_ITER > 0\n",
    "\n",
    "        train_start = time.time()\n",
    "        for _ in range(EPOCHS_PER_ITER):\n",
    "            ret = self.model.fit_epoch()\n",
    "        eval_start = train_end = time.time()\n",
    "\n",
    "        eval_dict = {'model_'+k:v for k,v in zip(self.model.metrics, self.model.run_eval())}\n",
    "        for k in TOP_K:\n",
    "            recs = self.model.recommend_k_items(\n",
    "                self.dataloader.test, \n",
    "                top_k=k,\n",
    "                use_id=True, \n",
    "                remove_seen=True, \n",
    "                recommend_from=self.open_proposals,\n",
    "            )\n",
    "            \n",
    "            eval_dict[f'precision@{k}'] = precision_at_k(self.dataloader.test, recs, k=k)\n",
    "            eval_dict[f'ndcg@{k}'] = ndcg_at_k(self.dataloader.test, recs, k=k)\n",
    "            eval_dict[f'recall@{k}'] = recall_at_k(self.dataloader.test, recs, k=k)\n",
    "            eval_dict[f'map@{k}'] = map_at_k(self.dataloader.test, recs, k=k)\n",
    "\n",
    "        eval_end = time.time()\n",
    "\n",
    "        self.total_train += train_end - train_start\n",
    "        self.total_eval += eval_end - eval_start\n",
    "        \n",
    "        return {\n",
    "            'iteration': self.iteration,\n",
    "            'loss': ret[0],\n",
    "            'mf_loss': ret[1],\n",
    "            'emb_loss': ret[2],\n",
    "            **eval_dict,\n",
    "            'time_train': train_end-train_start,\n",
    "            'time_test': eval_end-eval_start,\n",
    "            'time_total_train': self.total_train,\n",
    "            'time_total_test': self.total_eval,\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"model\")\n",
    "        self.model.saver.save(\n",
    "            sess=self.model.sess,\n",
    "            save_path=checkpoint_path,\n",
    "        )\n",
    "        return checkpoint_dir\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        self.model.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a748c7-63e9-412b-9eb9-ee4df4f7e3d8",
   "metadata": {},
   "source": [
    "## Small test of `TrainLightGCN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1bcddf1-c9bd-423f-80d7-972b3e8d3212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n"
     ]
    }
   ],
   "source": [
    "model = LightGCNCustom(\n",
    "    hparams,\n",
    "    dataloader,\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd79128d-1890-44ea-8400-b1804ea9767f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (train)0.6s: train loss = 0.60165 = (mf)0.60090 + (embed)0.00075\n",
      "Epoch 2 (train)0.4s + (eval)0.1s: train loss = 0.35004 = (mf)0.34610 + (embed)0.00394, recall = 0.00400, ndcg = 0.00394, precision = 0.00320, map = 0.00200\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16276fe4-d63d-4e7a-bcc8-38d8f5be299c",
   "metadata": {},
   "source": [
    "# Big experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6cf4b2a-7028-439e-98c4-568e120b0a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lamarck'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.uname().nodename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "427c4b72-593a-41ff-9fd6-991e8e3a0445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/daviddavo/ray_results')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAY_RESULTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5ad6f33-effe-4f48-850e-8044af3a88dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No experiment found, creating new tuner\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "paths = list(RAY_RESULTS_PATH.glob('TrainLightGCN_*'))\n",
    "last_experiment = max(paths, key=lambda x: x.stat().st_ctime) if paths else None\n",
    "last_experiment = None\n",
    "\n",
    "### SET TRAINING RESOURCES\n",
    "if os.uname().nodename == 'lamarck':\n",
    "    # assert torch.cuda.is_available()\n",
    "    \n",
    "    NUM_SAMPLES = 500\n",
    "    # Every run takes approx half a gig of vram (no optimizations)\n",
    "    # The RTX 4090 has 24GB so we can run the model about 48 times\n",
    "    resources_per_trial={\n",
    "        'cpu': 1,\n",
    "        # GPU has 25GiB, and each run might take up to 2GiB (torch version was lighter)\n",
    "        # so each run might take up to 1/12th of the GPU\n",
    "        # I use 1/16th so I don't take all the resources in the machine\n",
    "        'gpu': 1/16,\n",
    "    }\n",
    "else:\n",
    "    NUM_SAMPLES = 1\n",
    "    resources_per_trial={\n",
    "        'cpu': 1,\n",
    "        # It takes about 1.5 GiB with full training data, but I put a bit more because\n",
    "        # this notebook also takes a bit of memory\n",
    "        'memory': 2e9,\n",
    "    }\n",
    "\n",
    "### RESTORE EXPERIMENT OR CREATE A NEW ONE\n",
    "if last_experiment and tune.Tuner.can_restore(last_experiment):\n",
    "    print(f\"Restoring last experiment: {last_experiment}\")\n",
    "    tuner = tune.Tuner.restore(\n",
    "        str(last_experiment),\n",
    "        trainable=tune.with_resources(\n",
    "            tune.with_parameters(TrainLightGCN, folds=folds),\n",
    "            resources_per_trial,\n",
    "        ),\n",
    "        restart_errored=True\n",
    "    )\n",
    "else:\n",
    "    print(\"No experiment found, creating new tuner\")\n",
    "    # search_alg = HyperOptSearch()\n",
    "    # search_alg = tune.search.Repeater(None, N_SPLITS-SKIP_SPLIT)\n",
    "    search_alg = None\n",
    "    \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(TrainLightGCN, folds=folds),\n",
    "            resources_per_trial,\n",
    "        ),\n",
    "        run_config=train.RunConfig(\n",
    "            stop={'training_iteration': MAX_EPOCHS/EPOCHS_PER_ITER, 'time_total_s': 300},\n",
    "            storage_path=RAY_RESULTS_PATH,\n",
    "        ),\n",
    "        param_space=dict(\n",
    "            # every in this grid will be executed NUM_SAMPLES times\n",
    "            fold=tune.grid_search(range(N_SPLITS-SKIP_SPLIT)),\n",
    "            # batch size between 2**4 (32) and 2**10 (1024)\n",
    "            batch_size=tune.randint(4,10),\n",
    "            embedding_dim=tune.qlograndint(1, 1000, 5),\n",
    "            conv_layers=tune.randint(1,6),\n",
    "            learning_rate=tune.qloguniform(1e-4, 1, 1e-4),\n",
    "            l2=tune.loguniform(1e-7, 1e-2),\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            search_alg=search_alg,\n",
    "            # num_samples=(N_SPLITS-SKIP_SPLIT)*NUM_SAMPLES,\n",
    "            num_samples=NUM_SAMPLES,\n",
    "            metric='loss',\n",
    "            mode='min',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c968ecd5-d62c-4d57-846f-4bb7202a97c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-15 14:30:28</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.81        </td></tr>\n",
       "<tr><td>Memory:      </td><td>7.5/125.6 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 16.0/24 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_layers</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">  fold</th><th style=\"text-align: right;\">         l2</th><th style=\"text-align: right;\">  learning_rate</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TrainLightGCN_85872_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">            130</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.000248734</td><td style=\"text-align: right;\">         0.0018</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">            235</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">0.000868815</td><td style=\"text-align: right;\">         0.0064</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">8.99856e-06</td><td style=\"text-align: right;\">         0.1795</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             10</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">4.01627e-07</td><td style=\"text-align: right;\">         0.0074</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             55</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">2.0557e-07 </td><td style=\"text-align: right;\">         0.315 </td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             55</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">2.69786e-07</td><td style=\"text-align: right;\">         0.0041</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">            360</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">1.29391e-07</td><td style=\"text-align: right;\">         0.0001</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">            320</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">1.31335e-07</td><td style=\"text-align: right;\">         0.0052</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             20</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">0.00605056 </td><td style=\"text-align: right;\">         0.0492</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">            265</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">0.00096415 </td><td style=\"text-align: right;\">         0.1402</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.000170709</td><td style=\"text-align: right;\">         0.0006</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             30</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">0.00102284 </td><td style=\"text-align: right;\">         0.0037</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">            105</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">0.0323349  </td><td style=\"text-align: right;\">         0.8645</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             40</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">0.00182322 </td><td style=\"text-align: right;\">         0.1128</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">            120</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">1.91816e-05</td><td style=\"text-align: right;\">         0.0001</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             70</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">0.000338094</td><td style=\"text-align: right;\">         0.8926</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">            235</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">1.45305e-05</td><td style=\"text-align: right;\">         0.0004</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             45</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">5.57215e-06</td><td style=\"text-align: right;\">         0.0008</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">            135</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">3.56759e-06</td><td style=\"text-align: right;\">         0.0001</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             50</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">1.41573e-06</td><td style=\"text-align: right;\">         0.8744</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00020</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             25</td><td style=\"text-align: right;\">     0</td><td style=\"text-align: right;\">0.000486958</td><td style=\"text-align: right;\">         0.0174</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00021</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             35</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">0.0265607  </td><td style=\"text-align: right;\">         0.2349</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00022</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             60</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">1.06648e-06</td><td style=\"text-align: right;\">         0.0012</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00023</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">            195</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">0.000690889</td><td style=\"text-align: right;\">         0.0029</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00024</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">            200</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">0.00603499 </td><td style=\"text-align: right;\">         0.0205</td></tr>\n",
       "<tr><td>TrainLightGCN_85872_00025</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             95</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">4.92604e-07</td><td style=\"text-align: right;\">         0.8993</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 14:30:28,520\tWARNING tune.py:194 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "\u001b[2m\u001b[36m(pid=1398125)\u001b[0m 2023-11-15 14:30:28.936257: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[2m\u001b[36m(pid=1398125)\u001b[0m 2023-11-15 14:30:28.936293: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[2m\u001b[36m(pid=1398125)\u001b[0m 2023-11-15 14:30:28.936310: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=1398125)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=1398125)\u001b[0m   df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainLightGCN pid=1398125)\u001b[0m Already create adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=1398125)\u001b[0m Already normalize adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=1398125)\u001b[0m Using xavier initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 14:30:33,081\tINFO tune.py:1143 -- Total run time: 5.37 seconds (0.80 seconds for the tuning loop).\n",
      "2023-11-15 14:30:33,082\tWARNING tune.py:1158 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27\", trainable=...)\n",
      "2023-11-15 14:30:33,086\tWARNING experiment_analysis.py:205 -- Failed to fetch metrics for 26 trial(s):\n",
      "- TrainLightGCN_85872_00000: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00000: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00000_0_batch_size=9,conv_layers=2,embedding_dim=130,fold=0,l2=0.0002,learning_rate=0.0018_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00001: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00001: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00001_1_batch_size=5,conv_layers=5,embedding_dim=235,fold=1,l2=0.0009,learning_rate=0.0064_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00002: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00002: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00002_2_batch_size=5,conv_layers=3,embedding_dim=15,fold=2,l2=0.0000,learning_rate=0.1795_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00003: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00003: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00003_3_batch_size=6,conv_layers=2,embedding_dim=10,fold=3,l2=0.0000,learning_rate=0.0074_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00004: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00004: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00004_4_batch_size=4,conv_layers=3,embedding_dim=55,fold=4,l2=0.0000,learning_rate=0.3150_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00005: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00005: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00005_5_batch_size=5,conv_layers=4,embedding_dim=55,fold=5,l2=0.0000,learning_rate=0.0041_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00006: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00006: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00006_6_batch_size=4,conv_layers=2,embedding_dim=360,fold=6,l2=0.0000,learning_rate=0.0001_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00007: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00007: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00007_7_batch_size=6,conv_layers=2,embedding_dim=320,fold=7,l2=0.0000,learning_rate=0.0052_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00008: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00008: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00008_8_batch_size=9,conv_layers=4,embedding_dim=20,fold=8,l2=0.0061,learning_rate=0.0492_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00009: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00009: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00009_9_batch_size=7,conv_layers=4,embedding_dim=265,fold=9,l2=0.0010,learning_rate=0.1402_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00010: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00010: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00010_10_batch_size=9,conv_layers=5,embedding_dim=15,fold=0,l2=0.0002,learning_rate=0.0006_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00011: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00011: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00011_11_batch_size=6,conv_layers=3,embedding_dim=30,fold=1,l2=0.0010,learning_rate=0.0037_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00012: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00012: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00012_12_batch_size=4,conv_layers=3,embedding_dim=105,fold=2,l2=0.0323,learning_rate=0.8645_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00013: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00013: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00013_13_batch_size=4,conv_layers=3,embedding_dim=40,fold=3,l2=0.0018,learning_rate=0.1128_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00014: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00014: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00014_14_batch_size=8,conv_layers=5,embedding_dim=120,fold=4,l2=0.0000,learning_rate=0.0001_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00015: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00015: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00015_15_batch_size=6,conv_layers=4,embedding_dim=70,fold=5,l2=0.0003,learning_rate=0.8926_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00016: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00016: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00016_16_batch_size=5,conv_layers=2,embedding_dim=235,fold=6,l2=0.0000,learning_rate=0.0004_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00017: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00017: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00017_17_batch_size=7,conv_layers=5,embedding_dim=45,fold=7,l2=0.0000,learning_rate=0.0008_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00018: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00018: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00018_18_batch_size=7,conv_layers=4,embedding_dim=135,fold=8,l2=0.0000,learning_rate=0.0001_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00019: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00019: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00019_19_batch_size=8,conv_layers=4,embedding_dim=50,fold=9,l2=0.0000,learning_rate=0.8744_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00020: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00020: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00020_20_batch_size=8,conv_layers=3,embedding_dim=25,fold=0,l2=0.0005,learning_rate=0.0174_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00021: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00021: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00021_21_batch_size=6,conv_layers=2,embedding_dim=35,fold=1,l2=0.0266,learning_rate=0.2349_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00022: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00022: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00022_22_batch_size=6,conv_layers=3,embedding_dim=60,fold=2,l2=0.0000,learning_rate=0.0012_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00023: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00023: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00023_23_batch_size=8,conv_layers=3,embedding_dim=195,fold=3,l2=0.0007,learning_rate=0.0029_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00024: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00024: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00024_24_batch_size=5,conv_layers=2,embedding_dim=200,fold=4,l2=0.0060,learning_rate=0.0205_2023-11-15_14-30-27')\n",
      "- TrainLightGCN_85872_00025: FileNotFoundError('Could not fetch metrics for TrainLightGCN_85872_00025: both result.json and progress.csv were not found at /home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00025_25_batch_size=8,conv_layers=4,embedding_dim=95,fold=5,l2=0.0000,learning_rate=0.8993_2023-11-15_14-30-27')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00000_0_batch_size=9,conv_layers=2,embedding_dim=130,fold=0,l2=0.0002,learning_rate=0.0018_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00001_1_batch_size=5,conv_layers=5,embedding_dim=235,fold=1,l2=0.0009,learning_rate=0.0064_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00002_2_batch_size=5,conv_layers=3,embedding_dim=15,fold=2,l2=0.0000,learning_rate=0.1795_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00003_3_batch_size=6,conv_layers=2,embedding_dim=10,fold=3,l2=0.0000,learning_rate=0.0074_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00004_4_batch_size=4,conv_layers=3,embedding_dim=55,fold=4,l2=0.0000,learning_rate=0.3150_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00005_5_batch_size=5,conv_layers=4,embedding_dim=55,fold=5,l2=0.0000,learning_rate=0.0041_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00006_6_batch_size=4,conv_layers=2,embedding_dim=360,fold=6,l2=0.0000,learning_rate=0.0001_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00007_7_batch_size=6,conv_layers=2,embedding_dim=320,fold=7,l2=0.0000,learning_rate=0.0052_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00008_8_batch_size=9,conv_layers=4,embedding_dim=20,fold=8,l2=0.0061,learning_rate=0.0492_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00009_9_batch_size=7,conv_layers=4,embedding_dim=265,fold=9,l2=0.0010,learning_rate=0.1402_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00010_10_batch_size=9,conv_layers=5,embedding_dim=15,fold=0,l2=0.0002,learning_rate=0.0006_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00011_11_batch_size=6,conv_layers=3,embedding_dim=30,fold=1,l2=0.0010,learning_rate=0.0037_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00012_12_batch_size=4,conv_layers=3,embedding_dim=105,fold=2,l2=0.0323,learning_rate=0.8645_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00013_13_batch_size=4,conv_layers=3,embedding_dim=40,fold=3,l2=0.0018,learning_rate=0.1128_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00014_14_batch_size=8,conv_layers=5,embedding_dim=120,fold=4,l2=0.0000,learning_rate=0.0001_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00015_15_batch_size=6,conv_layers=4,embedding_dim=70,fold=5,l2=0.0003,learning_rate=0.8926_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00016_16_batch_size=5,conv_layers=2,embedding_dim=235,fold=6,l2=0.0000,learning_rate=0.0004_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00017_17_batch_size=7,conv_layers=5,embedding_dim=45,fold=7,l2=0.0000,learning_rate=0.0008_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00018_18_batch_size=7,conv_layers=4,embedding_dim=135,fold=8,l2=0.0000,learning_rate=0.0001_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00019_19_batch_size=8,conv_layers=4,embedding_dim=50,fold=9,l2=0.0000,learning_rate=0.8744_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00020_20_batch_size=8,conv_layers=3,embedding_dim=25,fold=0,l2=0.0005,learning_rate=0.0174_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00021_21_batch_size=6,conv_layers=2,embedding_dim=35,fold=1,l2=0.0266,learning_rate=0.2349_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00022_22_batch_size=6,conv_layers=3,embedding_dim=60,fold=2,l2=0.0000,learning_rate=0.0012_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00023_23_batch_size=8,conv_layers=3,embedding_dim=195,fold=3,l2=0.0007,learning_rate=0.0029_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00024_24_batch_size=5,conv_layers=2,embedding_dim=200,fold=4,l2=0.0060,learning_rate=0.0205_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    metrics={},\n",
       "    path='/home/daviddavo/ray_results/TrainLightGCN_2023-11-15_14-30-27/TrainLightGCN_85872_00025_25_batch_size=8,conv_layers=4,embedding_dim=95,fold=5,l2=0.0000,learning_rate=0.8993_2023-11-15_14-30-27',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb78823-fa7b-4857-8187-1a2e94e20012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
