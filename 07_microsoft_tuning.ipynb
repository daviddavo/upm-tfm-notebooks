{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf98a9e1-f3e0-4c0a-96c1-30f305901246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.9.18 (main, Oct 24 2023, 09:18:18) \n",
      "[GCC 11.4.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 11:28:48.962744: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-28 11:28:48.962767: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-28 11:28:48.962777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 8\n",
      "Ray version: 2.7.1\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple, Union, Any, Optional\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "print(\"Python version\", sys.version)\n",
    "\n",
    "# Ignore pandas warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "\n",
    "from src.datasets import daocensus\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "\n",
    "tf.config.list_physical_devices(\"GPU\")\n",
    "sys_details = tf.sysconfig.get_build_info()\n",
    "cuda = sys_details.get(\"cuda_version\", -1)\n",
    "cudnn = sys_details.get(\"cudnn_version\", -1)\n",
    "print(cuda, cudnn)\n",
    "print('Ray version:', ray.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798161a7-5414-4626-9dfb-6d71823bf4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Others config\n",
    "SEED: int = 57\n",
    "RAY_RESULTS_PATH: Path = Path('~/ray_results').expanduser()\n",
    "\n",
    "# Dataset config\n",
    "DAO_NAME = 'Decentraland'\n",
    "\n",
    "# Dataset splits config\n",
    "SPLIT_FREQ = '1W' # Split weekly\n",
    "LAST_SPLITS = 10 # Use just last 10 splits\n",
    "\n",
    "# Training config\n",
    "MAX_EPOCHS: int = 200\n",
    "EPOCHS_PER_ITER: int = 5\n",
    "SAMPLES_PER_SPLIT: int = 100\n",
    "OPTIM_METRIC: str = 'ndcg@10'\n",
    "\n",
    "# Eval config\n",
    "TOP_K: List[int] = [5, 10]\n",
    "METRICS: List[str] = [\"recall\", \"ndcg\", \"precision\", \"map\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ff2f2-bdaa-46eb-87d1-c4481734b8c0",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765a4892-6a85-40ab-a65d-c0d76b0569b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116560 entries, 0 to 116559\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   platform       116560 non-null  object        \n",
      " 1   name           116560 non-null  object        \n",
      " 2   id             116560 non-null  object        \n",
      " 3   proposal       116560 non-null  category      \n",
      " 4   deployment     116560 non-null  object        \n",
      " 5   platform_vote  116560 non-null  object        \n",
      " 6   voter          116560 non-null  object        \n",
      " 7   date           116560 non-null  datetime64[ns]\n",
      " 8   choice         116560 non-null  object        \n",
      " 9   weight         116560 non-null  float64       \n",
      "dtypes: category(1), datetime64[ns](1), float64(1), object(7)\n",
      "memory usage: 8.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1942 entries, 0 to 1941\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   platform             1942 non-null   object        \n",
      " 1   name                 1942 non-null   object        \n",
      " 2   platform_deployment  1942 non-null   object        \n",
      " 3   id                   1942 non-null   category      \n",
      " 4   deployment           1942 non-null   object        \n",
      " 5   platform_proposal    1942 non-null   object        \n",
      " 6   author               1942 non-null   category      \n",
      " 7   date                 1942 non-null   datetime64[ns]\n",
      " 8   votes_count          1942 non-null   int64         \n",
      " 9   proposal_id          1942 non-null   object        \n",
      " 10  title                1942 non-null   object        \n",
      " 11  description          1942 non-null   object        \n",
      " 12  start                1942 non-null   datetime64[ns]\n",
      " 13  end                  1942 non-null   datetime64[ns]\n",
      "dtypes: category(2), datetime64[ns](3), int64(1), object(8)\n",
      "memory usage: 599.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dfptext = pd.read_csv('./snapshot_proposals.csv')[['proposal_id', 'title', 'description', 'start', 'end']]\n",
    "dfv, dfp = daocensus.get(\"./data/daos-census\", DAO_NAME, 'snapshot')\n",
    "dfv['voter'] = dfv['voter'].astype('str')\n",
    "dfp = dfp.merge(dfptext, how='left', left_on='platform_proposal', right_on='proposal_id')\n",
    "dfp[['start', 'end']] = dfp[['start', 'end']].astype('datetime64')\n",
    "print(dfv.info())\n",
    "print(dfp.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df339c08-4f99-4933-886c-6ab774f09e63",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b003927-cfab-4f9a-91f8-1376f038f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xe7af1c70f8f089c4c3bd71999692c6c5a15d9e2a</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-17 12:28:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0xc54a6c3778016b06cbd126ccc3b5bc06c5f666fb</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-17 02:16:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0xd82d005e8f8d5385db40ba23884a5c967bb1e8af</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-17 00:38:22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0xf4c64db66ffb301985f5ecd85c8f3f9c02f2659d</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-16 18:47:08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0xd5e9ef1cedad0d135d543d286a2c190b16cbb89e</td>\n",
       "      <td>b86aa059-3d31-5d41-a472-70962816f779</td>\n",
       "      <td>2021-12-16 18:32:15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       userID  \\\n",
       "0  0xe7af1c70f8f089c4c3bd71999692c6c5a15d9e2a   \n",
       "1  0xc54a6c3778016b06cbd126ccc3b5bc06c5f666fb   \n",
       "2  0xd82d005e8f8d5385db40ba23884a5c967bb1e8af   \n",
       "3  0xf4c64db66ffb301985f5ecd85c8f3f9c02f2659d   \n",
       "4  0xd5e9ef1cedad0d135d543d286a2c190b16cbb89e   \n",
       "\n",
       "                                 itemID           timestamp  rating  \n",
       "0  b86aa059-3d31-5d41-a472-70962816f779 2021-12-17 12:28:01       1  \n",
       "1  b86aa059-3d31-5d41-a472-70962816f779 2021-12-17 02:16:23       1  \n",
       "2  b86aa059-3d31-5d41-a472-70962816f779 2021-12-17 00:38:22       1  \n",
       "3  b86aa059-3d31-5d41-a472-70962816f779 2021-12-16 18:47:08       1  \n",
       "4  b86aa059-3d31-5d41-a472-70962816f779 2021-12-16 18:32:15       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_microsoft(dfv):\n",
    "    df = dfv[['voter', 'proposal', 'date']].rename(columns={\n",
    "        'voter': 'userID',\n",
    "        'proposal': 'itemID',\n",
    "        'date': 'timestamp',\n",
    "    })\n",
    "    df['itemID'] = df['itemID'].astype('str')\n",
    "    df['rating'] = 1\n",
    "    return df\n",
    "\n",
    "df = to_microsoft(dfv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faab8dc-8192-47b5-96df-7458bd890ffb",
   "metadata": {},
   "source": [
    "# Split data\n",
    "\n",
    "Each proposal remains open for a few days, our environment is different of a movies recommender system. For this reason, we will use a TimeSeriesSplit instead of a K-Fold to cross-validate the model.\n",
    "\n",
    "![](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_013.png)\n",
    "\n",
    "El TimeSeriesSplit de scikit-learn no nos vale porque el número de elementos en cada split es el mismo, pero el tamaño del intervalo, no. Como queremos simular un comportamiento realista, haremos el split dividiendo por intervalos de igual longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f661ac7-df23-49ad-9671-cfa65d4b44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import metrics as metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "445d9909-609a-4cf3-8e24-6fa36946a375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 0, train from: 2021-05-24 to 2023-05-07, test from: 2023-05-07 to 2023-05-14\n",
      "  t: 2023-05-07 15:29:29\n",
      "  len(train): 105603, len(test): 328\n",
      "  users(train): 6846, users(test): 120\n",
      "\n",
      "  highest possible recall@5:\t0.9443\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4267\n",
      "  highest possible map@5:\t0.9443\n",
      "------------------------------\n",
      "Split 1, train from: 2021-05-24 to 2023-05-14, test from: 2023-05-14 to 2023-05-21\n",
      "  t: 2023-05-14 15:29:29\n",
      "  len(train): 106687, len(test): 238\n",
      "  users(train): 6871, users(test): 88\n",
      "\n",
      "  highest possible recall@5:\t0.9604\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4614\n",
      "  highest possible map@5:\t0.9604\n",
      "------------------------------\n",
      "Split 2, train from: 2021-05-24 to 2023-05-21, test from: 2023-05-21 to 2023-05-28\n",
      "  t: 2023-05-21 15:29:29\n",
      "  len(train): 108276, len(test): 450\n",
      "  users(train): 6901, users(test): 144\n",
      "\n",
      "  highest possible recall@5:\t0.9309\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4569\n",
      "  highest possible map@5:\t0.9309\n",
      "------------------------------\n",
      "Split 3, train from: 2021-05-24 to 2023-05-28, test from: 2023-05-28 to 2023-06-04\n",
      "  t: 2023-05-28 15:29:29\n",
      "  len(train): 109210, len(test): 168\n",
      "  users(train): 6916, users(test): 72\n",
      "\n",
      "  highest possible recall@5:\t0.9815\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4361\n",
      "  highest possible map@5:\t0.9815\n",
      "------------------------------\n",
      "Split 4, train from: 2021-05-24 to 2023-06-04, test from: 2023-06-04 to 2023-06-11\n",
      "  t: 2023-06-04 15:29:29\n",
      "  len(train): 109899, len(test): 170\n",
      "  users(train): 6928, users(test): 67\n",
      "\n",
      "  highest possible recall@5:\t0.9822\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4836\n",
      "  highest possible map@5:\t0.9822\n",
      "------------------------------\n",
      "Split 5, train from: 2021-05-24 to 2023-06-11, test from: 2023-06-11 to 2023-06-18\n",
      "  t: 2023-06-11 15:29:29\n",
      "  len(train): 110751, len(test): 327\n",
      "  users(train): 6945, users(test): 112\n",
      "\n",
      "  highest possible recall@5:\t0.9351\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4625\n",
      "  highest possible map@5:\t0.9351\n",
      "------------------------------\n",
      "Split 6, train from: 2021-05-24 to 2023-06-18, test from: 2023-06-18 to 2023-06-25\n",
      "  t: 2023-06-18 15:29:29\n",
      "  len(train): 111537, len(test): 310\n",
      "  users(train): 6964, users(test): 98\n",
      "\n",
      "  highest possible recall@5:\t0.9435\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.5265\n",
      "  highest possible map@5:\t0.9435\n",
      "------------------------------\n",
      "Split 7, train from: 2021-05-24 to 2023-06-25, test from: 2023-06-25 to 2023-07-02\n",
      "  t: 2023-06-25 15:29:29\n",
      "  len(train): 112555, len(test): 134\n",
      "  users(train): 7011, users(test): 61\n",
      "\n",
      "  highest possible recall@5:\t0.9829\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4164\n",
      "  highest possible map@5:\t0.9829\n",
      "------------------------------\n",
      "Split 8, train from: 2021-05-24 to 2023-07-02, test from: 2023-07-02 to 2023-07-09\n",
      "  t: 2023-07-02 15:29:29\n",
      "  len(train): 113492, len(test): 592\n",
      "  users(train): 7066, users(test): 185\n",
      "\n",
      "  highest possible recall@5:\t0.9224\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4941\n",
      "  highest possible map@5:\t0.9224\n",
      "------------------------------\n",
      "Split 9, train from: 2021-05-24 to 2023-07-09, test from: 2023-07-09 to 2023-07-16\n",
      "  t: 2023-07-09 15:29:29\n",
      "  len(train): 115348, len(test): 685\n",
      "  users(train): 7206, users(test): 222\n",
      "\n",
      "  highest possible recall@5:\t0.9397\n",
      "  highest possible ndcg@5:\t1.0000\n",
      "  highest possible precision@5:\t0.4739\n",
      "  highest possible map@5:\t0.9397\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from src.model_selection import timeFreqSplitCurrent, timeIntervalSplitCurrent\n",
    "\n",
    "# max_train_prev = df['timestamp'].min().date()\n",
    "# N_SPLITS = 10; SKIP_SPLIT = 0\n",
    "# folds = list(timeIntervalSplitCurrent(df, N_SPLITS, dfp, skip=SKIP_SPLIT, remove_not_in_train_col='userID', return_open=True))\n",
    "folds = list(timeFreqSplitCurrent(df, SPLIT_FREQ, dfp, return_open=True, remove_not_in_train_col='userID'))[-LAST_SPLITS:]\n",
    "for i, (dftrain, dftest, t, open_proposals) in enumerate(folds):\n",
    "    min_train = dftrain['timestamp'].min().date()\n",
    "    max_train = dftrain['timestamp'].max().date()\n",
    "    min_test  = dftest['timestamp'].min().date()\n",
    "    max_test  = dftest['timestamp'].max().date()\n",
    "\n",
    "    train_users = len(set(dftrain['userID']))\n",
    "    test_users = len(set(dftest['userID']))\n",
    "    \n",
    "    print(f\"Split {i}, train from: {min_train} to {max_train}, test from: {min_test} to {max_test}\")\n",
    "    print(f\"  t: {t}\")\n",
    "    print(f\"  len(train): {len(dftrain)}, len(test): {len(dftest)}\")\n",
    "    print(f\"  users(train): {train_users}, users(test): {test_users}\")\n",
    "\n",
    "    print()\n",
    "    dftest['prediction'] = 1\n",
    "    for m in METRICS:\n",
    "        f = metrics_dict[f'{m}_at_k']\n",
    "        print(f\"  highest possible {m}@{TOP_K[0]}:\\t{f(dftest, dftest, k=TOP_K[0], relevancy_method='top_k'):.4f}\")\n",
    "\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c881c43-d308-40ff-b6b4-d54458e1bc32",
   "metadata": {},
   "source": [
    "# Defining training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a502e2d-3398-405f-9029-d3abc69033dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.deeprec.models.graphrec.lightgcn import LightGCN\n",
    "from recommenders.utils.python_utils import get_top_k_scored_items\n",
    "\n",
    "class LightGCNCustom(LightGCN):\n",
    "    # Copied from LightGCN.fit but RETURNING the data and deleting unnecessary things\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.epochs_done = 0\n",
    "    \n",
    "    def fit_epoch(self):\n",
    "        \"\"\"Fit the model on self.data.train.\n",
    "        \"\"\"\n",
    "        loss, mf_loss, emb_loss = 0.0, 0.0, 0.0\n",
    "        n_batch = self.data.train.shape[0] // self.batch_size + 1\n",
    "        for idx in range(n_batch):\n",
    "            users, pos_items, neg_items = self.data.train_loader(self.batch_size)\n",
    "            _, batch_loss, batch_mf_loss, batch_emb_loss = self.sess.run(\n",
    "                [self.opt, self.loss, self.mf_loss, self.emb_loss],\n",
    "                feed_dict={\n",
    "                    self.users: users,\n",
    "                    self.pos_items: pos_items,\n",
    "                    self.neg_items: neg_items,\n",
    "                },\n",
    "            )\n",
    "            loss += batch_loss / n_batch\n",
    "            mf_loss += batch_mf_loss / n_batch\n",
    "            emb_loss += batch_emb_loss / n_batch\n",
    "\n",
    "        if np.isnan(loss):\n",
    "            print(\"ERROR: loss is nan.\")\n",
    "            sys.exit()\n",
    "\n",
    "        self.epochs_done += 1\n",
    "\n",
    "        return loss, mf_loss, emb_loss\n",
    "\n",
    "    def recommend_k_items(\n",
    "        self, test, top_k=10, sort_top_k=True, remove_seen=True, use_id=False, recommend_from=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Copy-pasted from LightGCN but adding the `recommend_from` argument\n",
    "        \"\"\"\n",
    "        data = self.data\n",
    "        if not use_id:\n",
    "            user_ids = np.array([data.user2id[x] for x in test[data.col_user].unique()])\n",
    "        else:\n",
    "            user_ids = np.array(test[data.col_user].unique())\n",
    "\n",
    "        test_scores = self.score(user_ids, remove_seen=remove_seen)\n",
    "\n",
    "        ### START NEW BEHAVIOUR\n",
    "        if recommend_from is not None:\n",
    "            from_idx = np.array([data.item2id[x] for x in set(recommend_from)])\n",
    "            msk = np.ones(test_scores.shape[1], bool)\n",
    "            msk[from_idx] = False\n",
    "\n",
    "            # Set the score of that proposal to zero for every user\n",
    "            test_scores[:, msk] = -np.inf\n",
    "        ### END NEW BEHAVIOUR\n",
    "\n",
    "        top_items, top_scores = get_top_k_scored_items(\n",
    "            scores=test_scores, top_k=top_k, sort_top_k=sort_top_k\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                data.col_user: np.repeat(\n",
    "                    test[data.col_user].drop_duplicates().values, top_items.shape[1]\n",
    "                ),\n",
    "                data.col_item: top_items.flatten()\n",
    "                if use_id\n",
    "                else [data.id2item[item] for item in top_items.flatten()],\n",
    "                data.col_prediction: top_scores.flatten(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return df.replace(-np.inf, np.nan).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923adb82-9733-4e21-a378-7263c5532353",
   "metadata": {},
   "source": [
    "## Small test of `LightGCNCustom`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41d1cf90-bd11-4a87-b0aa-bf0e25d559af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.models.deeprec.DataModel.ImplicitCF import ImplicitCF\n",
    "from recommenders.models.deeprec.deeprec_utils import prepare_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e57c58e-3091-4357-969a-c7bafedd29c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items: 1939 user: 7206\n",
      "Already create adjacency matrix.\n",
      "Already normalize adjacency matrix.\n",
      "Using xavier initialization.\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(\n",
    "    model_type='lightgcn',\n",
    "    n_layers=3,\n",
    "    batch_size=512,\n",
    "    embed_size=64,\n",
    "    epochs=2,\n",
    "    learning_rate=0.001,\n",
    "    decay=0.001,\n",
    "    metrics=[\"recall\", \"ndcg\", \"precision\", \"map\"],\n",
    "    eval_epoch=2,\n",
    "    top_k=TOP_K[0],\n",
    "    save_model=False,\n",
    "    MODEL_DIR='./data/model/lightgcn/',\n",
    ")\n",
    "dataloader = ImplicitCF(train=folds[-1][0], test=folds[-1][1], seed=SEED)\n",
    "print(\"items:\", dataloader.n_items, \"user:\", dataloader.n_users)\n",
    "model = LightGCNCustom(data=dataloader, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe49e83-f291-4383-97c2-167a706ae717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (train)0.7s: train loss = 0.59596 = (mf)0.59514 + (embed)0.00083\n",
      "Epoch 2 (train)0.5s + (eval)0.6s: train loss = 0.34242 = (mf)0.33814 + (embed)0.00428, recall = 0.03303, ndcg = 0.03305, precision = 0.00991, map = 0.03194\n"
     ]
    }
   ],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a12ab695-94f8-431e-8a7f-03bf17f2fa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03303303303303304,\n",
       " 0.03305273711219786,\n",
       " 0.009909909909909911,\n",
       " 0.03193818818818819]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.run_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b131c2d-6df2-4292-8f12-caaf409562ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>itemID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.088201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5795</td>\n",
       "      <td>1938</td>\n",
       "      <td>0.447238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5795</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.982281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.459556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.119783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1292</td>\n",
       "      <td>1938</td>\n",
       "      <td>-0.610669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1292</td>\n",
       "      <td>1238</td>\n",
       "      <td>-2.921641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "      <td>1.241249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>1293</td>\n",
       "      <td>1938</td>\n",
       "      <td>-0.482672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1293</td>\n",
       "      <td>1238</td>\n",
       "      <td>-1.731134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>570 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID  itemID  prediction\n",
       "0       397       0   -7.088201\n",
       "3      5795    1938    0.447238\n",
       "4      5795       0   -0.982281\n",
       "6       328       0   -3.459556\n",
       "9       266       0   -8.119783\n",
       "..      ...     ...         ...\n",
       "661    1292    1938   -0.610669\n",
       "662    1292    1238   -2.921641\n",
       "663    1293       0    1.241249\n",
       "664    1293    1938   -0.482672\n",
       "665    1293    1238   -1.731134\n",
       "\n",
       "[570 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.recommend_k_items(dataloader.test, top_k=3, use_id=True, remove_seen=True, recommend_from={'b86aa059-3d31-5d41-a472-70962816f779', '56b4d333-4138-5aa3-9890-3502b9478079', 'd083109e-4819-54b9-a01c-67bd5a770f65' })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994a5dd-efe5-47bf-a8a1-803316d9fc75",
   "metadata": {},
   "source": [
    "# Defining trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5d010bf-3a9c-4931-9d02-6589b3164438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
    "\n",
    "class TrainLightGCN(tune.Trainable):\n",
    "    def setup(\n",
    "        self,\n",
    "        config: Dict[str, Any],\n",
    "        data,\n",
    "    ):\n",
    "        self.config = config\n",
    "\n",
    "        self.hparams = prepare_hparams(\n",
    "            model_type='lightgcn',\n",
    "            n_layers=config['conv_layers'],\n",
    "            batch_size=2**config['batch_size'],\n",
    "            embed_size=config['embedding_dim'],\n",
    "            epochs=EPOCHS_PER_ITER,\n",
    "            learning_rate=config['learning_rate'],\n",
    "            decay=config['l2'],\n",
    "            metrics=METRICS,\n",
    "            eval_epoch=-1,\n",
    "            top_k=TOP_K[0],\n",
    "            save_model=False,\n",
    "            MODEL_DIR='./data/model/lightgcn/',\n",
    "        )\n",
    "\n",
    "        train, test, self.t, self.open_proposals = data\n",
    "        self.dataloader = ImplicitCF(train=train, test=test, seed=SEED)\n",
    "        self.model = LightGCNCustom(self.hparams, self.dataloader, seed=SEED)\n",
    "        self.total_train = 0\n",
    "        self.total_eval = 0\n",
    "\n",
    "    @property\n",
    "    def iteration(self):\n",
    "        return self.model.epochs_done\n",
    "\n",
    "    @property\n",
    "    def training_iteration(self):\n",
    "        return self.model.epochs_done\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        As a rule of thumb, the execution time of step should be large enough to avoid overheads \n",
    "        (i.e. more than a few seconds), but short enough to report progress periodically \n",
    "        (i.e. at most a few minutes).\n",
    "        \"\"\"\n",
    "        assert EPOCHS_PER_ITER > 0\n",
    "\n",
    "        train_start = time.time()\n",
    "        for _ in range(EPOCHS_PER_ITER):\n",
    "            ret = self.model.fit_epoch()\n",
    "        eval_start = train_end = time.time()\n",
    "\n",
    "        eval_dict = {'model_'+k:v for k,v in zip(self.model.metrics, self.model.run_eval())}\n",
    "        for k in TOP_K:\n",
    "            recs = self.model.recommend_k_items(\n",
    "                self.dataloader.test, \n",
    "                top_k=k,\n",
    "                use_id=True, \n",
    "                remove_seen=True, \n",
    "                recommend_from=self.open_proposals,\n",
    "            )\n",
    "            \n",
    "            eval_dict[f'precision@{k}'] = precision_at_k(self.dataloader.test, recs, k=k)\n",
    "            eval_dict[f'ndcg@{k}'] = ndcg_at_k(self.dataloader.test, recs, k=k)\n",
    "            eval_dict[f'recall@{k}'] = recall_at_k(self.dataloader.test, recs, k=k)\n",
    "            eval_dict[f'map@{k}'] = map_at_k(self.dataloader.test, recs, k=k)\n",
    "\n",
    "        eval_end = time.time()\n",
    "\n",
    "        self.total_train += train_end - train_start\n",
    "        self.total_eval += eval_end - eval_start\n",
    "        \n",
    "        return {\n",
    "            'iteration': self.iteration,\n",
    "            'loss': ret[0],\n",
    "            'mf_loss': ret[1],\n",
    "            'emb_loss': ret[2],\n",
    "            **eval_dict,\n",
    "            'time_train': train_end-train_start,\n",
    "            'time_test': eval_end-eval_start,\n",
    "            'time_total_train': self.total_train,\n",
    "            'time_total_test': self.total_eval,\n",
    "        }\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"model\")\n",
    "        self.model.saver.save(\n",
    "            sess=self.model.sess,\n",
    "            save_path=checkpoint_path,\n",
    "        )\n",
    "        return checkpoint_dir\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        self.model.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16276fe4-d63d-4e7a-bcc8-38d8f5be299c",
   "metadata": {},
   "source": [
    "# Big experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6cf4b2a-7028-439e-98c4-568e120b0a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lamarck'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.uname().nodename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "427c4b72-593a-41ff-9fd6-991e8e3a0445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/daviddavo/ray_results')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RAY_RESULTS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5ad6f33-effe-4f48-850e-8044af3a88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "import datetime as dt\n",
    "\n",
    "def getTunerOnFold(f, points_to_evaluate = None):\n",
    "    name = f'LightGCN_dao={DAO_NAME},freq={SPLIT_FREQ},fold={f}'\n",
    "    paths = list(RAY_RESULTS_PATH.glob(f'{name}_*'))\n",
    "    last_experiment = max(paths, key=lambda x: x.stat().st_ctime) if paths else None\n",
    "    \n",
    "    ### SET TRAINING RESOURCES\n",
    "    if os.uname().nodename == 'lamarck':\n",
    "        # assert torch.cuda.is_available()\n",
    "        \n",
    "        NUM_SAMPLES = SAMPLES_PER_SPLIT\n",
    "        # Every run takes approx half a gig of vram (no optimizations)\n",
    "        # The RTX 4090 has 24GB so we can run the model about 48 times\n",
    "        resources_per_trial={\n",
    "            'cpu': 1,\n",
    "            # GPU has 25GiB, and each run might take up to 2GiB (torch version was lighter)\n",
    "            # so each run might take up to 1/12th of the GPU\n",
    "            # I use 1/16th so I don't take all the resources in the machine\n",
    "            'gpu': 1/16,\n",
    "        }\n",
    "    else:\n",
    "        NUM_SAMPLES = 1\n",
    "        resources_per_trial={\n",
    "            'cpu': 1,\n",
    "            # It takes about 1.5 GiB with full training data, but I put a bit more because\n",
    "            # this notebook also takes a bit of memory\n",
    "            'memory': 2e9,\n",
    "        }\n",
    "\n",
    "    dftrain,dftest,t,open_proposals = folds[f]\n",
    "    param_space = dict(\n",
    "        fold=f,\n",
    "        batch_size=tune.randint(6,10), # 64 - 1024\n",
    "        embedding_dim=tune.qlograndint(1, 1000, 5),\n",
    "        conv_layers=tune.randint(1,6),\n",
    "        learning_rate=tune.qloguniform(1e-4, 1, 1e-4),\n",
    "        l2=tune.loguniform(1e-7, 1e-2),\n",
    "    )\n",
    "    \n",
    "    ### RESTORE EXPERIMENT OR CREATE A NEW ONE\n",
    "    if last_experiment and tune.Tuner.can_restore(last_experiment):\n",
    "        print(f\"Restoring last experiment: {last_experiment}\")\n",
    "        tuner = tune.Tuner.restore(\n",
    "            str(last_experiment),\n",
    "            trainable=tune.with_resources(\n",
    "                # tune.with_parameters(TrainLightGCN,  train=dftrain, test=dftest, open_proposals=open_proposals),\n",
    "                tune.with_parameters(TrainLightGCN, data=folds[f]),\n",
    "                resources_per_trial,\n",
    "            ),\n",
    "            restart_errored=True,\n",
    "            param_space=param_space,\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No experiment found for fold {f}, creating new tuner with {NUM_SAMPLES} samples\")\n",
    "        search_alg = None\n",
    "        search_alg = HyperOptSearch(\n",
    "            # points_to_evaluate=[{\n",
    "            #     'batch_size': 8, # 2**8 = 256\n",
    "            #     'learning_rate': 10e-2,\n",
    "            #     'l2': 10e-6,\n",
    "            #     'embedding_dim': 100,\n",
    "            #     'conv_layers': 3,\n",
    "            # }],\n",
    "            points_to_evaluate = points_to_evaluate,\n",
    "            random_state_seed=SEED,\n",
    "        )\n",
    "        # search_alg = tune.search.Repeater(search_alg, N_SPLITS-SKIP_SPLIT)\n",
    "        \n",
    "        tuner = tune.Tuner(\n",
    "            tune.with_resources(\n",
    "                # tune.with_parameters(TrainLightGCN,  train=dftrain, test=dftest, open_proposals=open_proposals),\n",
    "                tune.with_parameters(TrainLightGCN, data=folds[f]),\n",
    "                resources_per_trial,\n",
    "            ),\n",
    "            run_config=train.RunConfig(\n",
    "                stop={'training_iteration': MAX_EPOCHS/EPOCHS_PER_ITER, 'time_total_train': 300},\n",
    "                name=name + f'_{dt.datetime.now().isoformat()}',\n",
    "                storage_path=RAY_RESULTS_PATH,\n",
    "            ),\n",
    "            param_space=param_space,\n",
    "            tune_config=tune.TuneConfig(\n",
    "                search_alg=search_alg,\n",
    "                num_samples=NUM_SAMPLES,\n",
    "                metric=OPTIM_METRIC,\n",
    "                mode='max',\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c968ecd5-d62c-4d57-846f-4bb7202a97c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-28 16:06:28</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:30.35        </td></tr>\n",
       "<tr><td>Memory:      </td><td>21.6/125.6 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 9.0/24 CPUs, 0.5625/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_layers</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">  fold</th><th style=\"text-align: right;\">         l2</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iteration</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">  mf_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TrainLightGCN_f8a91d1d</td><td>RUNNING </td><td>147.96.81.131:3562471</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">0.000298713</td><td style=\"text-align: right;\">         0.0227</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         17.9623</td><td style=\"text-align: right;\">         25</td><td style=\"text-align: right;\">0.0683163</td><td style=\"text-align: right;\">0.0623062</td></tr>\n",
       "<tr><td>TrainLightGCN_0626c10a</td><td>RUNNING </td><td>147.96.81.131:3562578</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             30</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">2.8606e-05 </td><td style=\"text-align: right;\">         0.2347</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         15.6351</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">0.500691 </td><td style=\"text-align: right;\">0.385722 </td></tr>\n",
       "<tr><td>TrainLightGCN_639eaab1</td><td>RUNNING </td><td>147.96.81.131:3562711</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">5.24282e-05</td><td style=\"text-align: right;\">         0.22  </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         18.5235</td><td style=\"text-align: right;\">         15</td><td style=\"text-align: right;\">0.184059 </td><td style=\"text-align: right;\">0.176665 </td></tr>\n",
       "<tr><td>TrainLightGCN_a94e9991</td><td>RUNNING </td><td>147.96.81.131:3562844</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">            300</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">8.92312e-07</td><td style=\"text-align: right;\">         0.0065</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>TrainLightGCN_9a93c389</td><td>RUNNING </td><td>147.96.81.131:3562985</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">            215</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">2.79193e-05</td><td style=\"text-align: right;\">         0.0005</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>TrainLightGCN_dd842aa1</td><td>RUNNING </td><td>147.96.81.131:3563132</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">0.00397996 </td><td style=\"text-align: right;\">         0.0038</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>TrainLightGCN_b4d25a70</td><td>RUNNING </td><td>147.96.81.131:3563263</td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">0.0011209  </td><td style=\"text-align: right;\">         0.0002</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>TrainLightGCN_4a009174</td><td>RUNNING </td><td>147.96.81.131:3563393</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">            405</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">0.00406073 </td><td style=\"text-align: right;\">         0.0014</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">         </td></tr>\n",
       "<tr><td>TrainLightGCN_7fcd0d8b</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">            205</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">6.80694e-06</td><td style=\"text-align: right;\">         0.0085</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">         </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3562471)\u001b[0m 2023-11-28 16:05:59.271220: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[2m\u001b[36m(pid=3562471)\u001b[0m 2023-11-28 16:05:59.271249: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[2m\u001b[36m(pid=3562471)\u001b[0m 2023-11-28 16:05:59.271260: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562471)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562471)\u001b[0m   df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562471)\u001b[0m Already create adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562471)\u001b[0m Already normalize adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562471)\u001b[0m Using xavier initialization.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562578)\u001b[0m Already normalize adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562578)\u001b[0m Using xavier initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3562711)\u001b[0m 2023-11-28 16:06:05.730776: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3562711)\u001b[0m 2023-11-28 16:06:05.730809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3562711)\u001b[0m 2023-11-28 16:06:05.730820: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562578)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562578)\u001b[0m   df = train if test is None else train.append(test)\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562711)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562711)\u001b[0m   df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562711)\u001b[0m Already create adjacency matrix.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562711)\u001b[0m Already normalize adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562711)\u001b[0m Using xavier initialization.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562844)\u001b[0m Already normalize adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562844)\u001b[0m Using xavier initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3562985)\u001b[0m 2023-11-28 16:06:12.526509: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3562985)\u001b[0m 2023-11-28 16:06:12.526544: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3562985)\u001b[0m 2023-11-28 16:06:12.526557: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562844)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562844)\u001b[0m   df = train if test is None else train.append(test)\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562985)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562985)\u001b[0m   df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562985)\u001b[0m Already create adjacency matrix.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562985)\u001b[0m Already normalize adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3562985)\u001b[0m Using xavier initialization.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563132)\u001b[0m Already normalize adjacency matrix.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563132)\u001b[0m Using xavier initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3563263)\u001b[0m 2023-11-28 16:06:19.862261: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3563263)\u001b[0m 2023-11-28 16:06:19.862298: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3563263)\u001b[0m 2023-11-28 16:06:19.862312: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563132)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563132)\u001b[0m   df = train if test is None else train.append(test)\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563263)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563263)\u001b[0m   df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563263)\u001b[0m Already create adjacency matrix.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563393)\u001b[0m Already normalize adjacency matrix.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563393)\u001b[0m Using xavier initialization.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3563524)\u001b[0m 2023-11-28 16:06:27.607906: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3563524)\u001b[0m 2023-11-28 16:06:27.607941: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3563524)\u001b[0m 2023-11-28 16:06:27.607952: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563393)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563393)\u001b[0m   df = train if test is None else train.append(test)\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563524)\u001b[0m /home/daviddavo/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/recommenders/models/deeprec/DataModel/ImplicitCF.py:73: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563524)\u001b[0m   df = train if test is None else train.append(test)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TrainLightGCN pid=3563524)\u001b[0m Already create adjacency matrix.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tuners = []\n",
    "results = []\n",
    "last_best_result = None\n",
    "for f in range(LAST_SPLITS):\n",
    "    best_prev_config = None\n",
    "    if last_best_result is not None:\n",
    "        best_prev_config = last_best_result.config.copy()\n",
    "        best_prev_config['fold'] += 1\n",
    "        best_prev_config = [best_prev_config]\n",
    "    \n",
    "    t = getTunerOnFold(f, best_prev_config)\n",
    "    tuners.append(t)\n",
    "\n",
    "    rg = t.fit()\n",
    "    results.append(rg)\n",
    "\n",
    "    # Assert that the prev config has been tried\n",
    "    if last_best_result is not None:\n",
    "        assert any( \n",
    "            all((r.config[k] == v for k, v in last_best_result.config.items() if k != 'fold'))\n",
    "            for r in rg if r.config\n",
    "        ), f\"The config has not been tested in fold {f}\"       \n",
    "    \n",
    "    last_best_result = rg.get_best_result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
