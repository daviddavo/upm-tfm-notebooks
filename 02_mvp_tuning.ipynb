{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Pytorch Geometric official example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1764915/1034952450.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/daviddavo/upm-tfm-notebooks/src/neg_sampling.py:13: UserWarning: This is copied from https://github.com/pyg-team/pytorch_geometric/pull/7816\n",
      "  warnings.warn('This is copied from https://github.com/pyg-team/pytorch_geometric/pull/7816')\n",
      "/home/daviddavo/upm-tfm-notebooks/src/neg_sampling.py:14: UserWarning: REMOVE WHEN MERGED\n",
      "  warnings.warn('REMOVE WHEN MERGED')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm.notebook import tqdm # Progress bars\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "# https://import-as.github.io\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as PyG\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import src\n",
    "from src.data import get_df, filter_df\n",
    "from src.graph_utils import shift_edge_indices, unshift_edge_indices\n",
    "from src.neg_sampling import structured_negative_sampling\n",
    "\n",
    "RANDOM_SEED = 1701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters table in [Google Drive](https://docs.google.com/spreadsheets/d/1riafpWt1563w9pbqdt1g2QZVkc7TfRWGzFaCG5rudDI/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Remove users with less than 6 votes from the dataset before splitting\n",
    "DatasetConfig = namedtuple('DatasetConfig', ('min_votes_per_user', 'allowed_dao_names', 'num_folds'))\n",
    "datasetConfig = DatasetConfig(\n",
    "    min_votes_per_user=6,\n",
    "    allowed_dao_names={'dxDAO', 'xDXdao'},\n",
    "    num_folds=5,\n",
    ")\n",
    "\n",
    "ModelConfig = namedtuple('ModelConfig', 'max_epochs batch_size learning_rate embedding_dim conv_layers l2')\n",
    "modelConfig = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    embedding_dim=32,\n",
    "    conv_layers=3,\n",
    "    l2=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:          16606\n",
      "Density:       0.3087%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  voter={ num_nodes=104 },\n",
       "  proposal={ num_nodes=2216 },\n",
       "  (voter, votes, proposal)={ edge_index=[2, 8303] },\n",
       "  (proposal, voted, voter)={ edge_index=[2, 8303] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, HeteroData, Data\n",
    "from src.datasets import Daostack\n",
    "\n",
    "def print_graph_stats(g: HeteroData):\n",
    "    density = (g.num_edges) / (g.num_nodes*(g.num_nodes-1))\n",
    "    print(f'Edges:   {g.num_edges:12}')\n",
    "    print(f'Density: {density*100:12.4f}%')\n",
    "\n",
    "data = Daostack(\"./data/dao-analyzer/\", min_vpu=datasetConfig.min_votes_per_user, allowed_daos=datasetConfig.allowed_dao_names)[0]\n",
    "print_graph_stats(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I thought the RandomLinkSplit function was not working properly, but it turns out that I wasn't understanding it very well. The tutorial I used for [01_mvp](./01_mvp.ipynb) is not very good either, it was written by students, and implemented before PyTorch Geometric bundled the LightGCN model with it.\n",
    "\n",
    "> I think this is totally correct. It seems like you are looking at the shapes of edge_index, while you may want to look at the shapes of edge_label and edge_label_index (which correctly model a 80/10/10 split ratio). Here, edge_index is solely used for message passing, i.e.,\n",
    "> \n",
    "> * for training, we exchange messages on all training edges\n",
    "> * for validation, we exchange messages on all training edges\n",
    "> * for testing, we exchange messages on all training and validation edges\n",
    "> Let me know if this resolves your concerns :)\n",
    ">\n",
    "> -- [Split Error in RandomLinkSplit · Issue #3668 · pyg-team/pytorch_geometric · GitHub](https://github.com/pyg-team/pytorch_geometric/issues/3668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6643] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6643] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1660] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1660] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6643] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6643] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1660] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1660] }\n",
       "  ))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def graph_k_fold(g: Data | HeteroData, folds, edge_type=None):\n",
    "    skf = StratifiedKFold(folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    # Stratify by voter\n",
    "    if edge_type is None:\n",
    "        edge_type = g.edge_types[0]\n",
    "        rev_edge_type = g.edge_types[1]\n",
    "        \n",
    "    edge_index = g[edge_type].edge_index\n",
    "    for train_idx, val_idx in skf.split(torch.zeros(edge_index.size(1)), edge_index[0]):\n",
    "        gtrain = g.edge_subgraph({\n",
    "            edge_type:torch.tensor(train_idx),\n",
    "            rev_edge_type:torch.tensor(train_idx),\n",
    "        })\n",
    "        assert gtrain.is_undirected()\n",
    "        assert len(gtrain[edge_type].edge_index[0].unique()) == len(g[edge_type].edge_index[0].unique())\n",
    "        # The negative samples should be different each epoch\n",
    "        # gtrain[edge_type].negative_samples = structured_negative_sampling(gtrain[edge_type].edge_index, (aux[edge_type[0]].num_nodes, aux[edge_type[2]].num_nodes))[2]\n",
    "        gval = g.edge_subgraph({\n",
    "            edge_type:torch.tensor(val_idx),\n",
    "            rev_edge_type:torch.tensor(val_idx),\n",
    "        })\n",
    "        assert gval.is_undirected()\n",
    "        assert len(gval[edge_type].edge_index[0].unique()) == len(g[edge_type].edge_index[0].unique())\n",
    "        assert (gtrain[edge_type].edge_index[0].unique() == gval[edge_type].edge_index[0].unique()).all()\n",
    "\n",
    "        folds.append((gtrain, gval))\n",
    "\n",
    "    return folds\n",
    "\n",
    "graph_folds = graph_k_fold(data, datasetConfig.num_folds)\n",
    "graph_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,1,2,3,4,5,6,7,8,9,10][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_excluding(model, edge_index, src_index, dst_index, exclude_edges=None, k = 1):\n",
    "    emb = model.get_embedding(edge_index)\n",
    "\n",
    "    out_src = emb[src_index]\n",
    "    out_dst = emb[dst_index]\n",
    "\n",
    "    pred = out_src @ out_dst.t()\n",
    "\n",
    "    if exclude_edges is not None:\n",
    "        inv_src = torch.full((src_index.max().item()+1,), -1, device=exclude_edges.device)\n",
    "        inv_src[src_index] = torch.arange(0, src_index.numel(), device=exclude_edges.device)\n",
    "\n",
    "        inv_dst = torch.full((dst_index.max().item()+1,), -1, device=exclude_edges.device)\n",
    "        inv_dst[dst_index] = torch.arange(0, dst_index.numel(), device=exclude_edges.device)\n",
    "        \n",
    "        exclude_src = inv_src[exclude_edges[0]]\n",
    "        exclude_dst = inv_dst[exclude_edges[1]]\n",
    "        \n",
    "        pred[exclude_src, exclude_dst] = -np.inf\n",
    "\n",
    "    top_index = pred.topk(k, dim=-1).indices\n",
    "    top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
    "\n",
    "    return top_index\n",
    "\n",
    "# hdata = data.to_homogeneous()\n",
    "# strain = shift_edge_indices(graph_folds[0][0])\n",
    "# users = torch.arange(strain['voter'].shift + 10, strain['voter'].end, 2)\n",
    "# items = torch.arange(strain['proposal'].shift, strain['proposal'].end)\n",
    "# recommend_excluding(model, hdata.edge_index, torch.tensor([4, 8]), items, k=10, exclude_edges=torch.tensor([[8,4,4,4], [2296, 282, 600, 905]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 14:24:38,497\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/daviddavo/.local/lib/python3.10/site-packages/ray/air/session.py:28: UserWarning: `get_checkpoint` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90391244333a4f09bedfff52e5a97b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 14:24:39,096\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/daviddavo/.local/lib/python3.10/site-packages/ray/air/session.py:28: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n",
      "2023-08-17 14:24:39,209\tWARNING session.py:100 -- In neither tune session nor train session!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------+----------------+----------+\n",
      "| Layer                  | Input Shape           | Output Shape   | #Param   |\n",
      "|------------------------+-----------------------+----------------+----------|\n",
      "| LightGCN               | [2, 8303]             | [8303]         | 74,240   |\n",
      "| ├─(embedding)Embedding | --                    | --             | 74,240   |\n",
      "| ├─(convs)ModuleList    | --                    | --             | --       |\n",
      "| │    └─(0)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "| │    └─(1)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "| │    └─(2)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "+------------------------+-----------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import LightGCN\n",
    "\n",
    "# Based on:\n",
    "# - https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# - https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
    "# - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "def train_daostack(train: HeteroData, validation: HeteroData, original: HeteroData, modelConfig: ModelConfig, disable_tqdm=False):\n",
    "    if not isinstance(modelConfig, ModelConfig):\n",
    "        modelConfig = ModelConfig(**modelConfig)\n",
    "    \n",
    "    model = LightGCN(\n",
    "        num_nodes=original.num_nodes,\n",
    "        embedding_dim=modelConfig.embedding_dim,\n",
    "        num_layers=modelConfig.conv_layers,\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=modelConfig.learning_rate)\n",
    "\n",
    "    checkpoint = session.get_checkpoint()\n",
    "\n",
    "    if checkpoint:\n",
    "        checkpoint_state = checkpoint.to_dict()\n",
    "        start_epoch = checkpoint_state[\"epoch\"]\n",
    "        model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    assert train.is_undirected()\n",
    "    assert validation.is_undirected()\n",
    "\n",
    "    # We need to convert the edge indices to homogeneous\n",
    "    # In hetero data the numbers are shared between the node types\n",
    "    # while in homo data they are shifted\n",
    "    original, train, validation = map(shift_edge_indices, [original, train, validation])\n",
    "    \n",
    "    # nodes = torch.arange(0, train.num_nodes, device=device)\n",
    "    users = torch.arange(train['voter'].shift, train['voter'].end, device=device)\n",
    "    items = torch.arange(train['proposal'].shift, train['proposal'].end, device=device)\n",
    "    n_users = train['voter'].num_nodes\n",
    "    n_items = train['proposal'].num_nodes\n",
    "\n",
    "    message_passing_edge_index = torch.concat([s.edge_index for s in train.edge_stores], dim=1)\n",
    "\n",
    "    # The official LightGCN usage also uses this line of code (well, for homo graphs)\n",
    "    # - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "    # In our case, we will use just voter ---> proposal\n",
    "    train_edge_label_index = train['voter', 'votes', 'proposal'].edge_index\n",
    "    assert (train_edge_label_index[0] < train['voter'].end).all()\n",
    "    assert (train['proposal'].shift <= train_edge_label_index[1]).all()\n",
    "\n",
    "    # TODO: Use LinkLoader instead (i don't know how)\n",
    "    # Waiting for pyg-team/pytorch_geometric#7817\n",
    "    # train_loader = PyG.loader.LinkLoader(\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        range(train_edge_label_index.size(1)), # dataset\n",
    "        batch_size=modelConfig.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _prec_rec(k: int, remove_training=False):\n",
    "        # gt: ground truth\n",
    "        if remove_training:\n",
    "            gt_index = validation['voter', 'votes', 'proposal'].edge_index\n",
    "            exclude_edges = train['voter', 'votes', 'proposal'].edge_index\n",
    "        else:\n",
    "            # All edges\n",
    "            gt_index = original['voter', 'votes', 'proposal'].edge_index\n",
    "            exclude_edges = None\n",
    "\n",
    "        R = item_count = PyG.utils.degree(gt_index[0], num_nodes=n_users)\n",
    "        # topr.size [104, R.max()]\n",
    "        topr = recommend_excluding(model, message_passing_edge_index, src_index=users, dst_index=items, k=int(R.max()), exclude_edges=exclude_edges)\n",
    "        n_samples = len(users)\n",
    "\n",
    "        # [104, 2216]\n",
    "        ground_truth = torch.full((n_users, n_items), False, dtype=torch.bool, device=device)\n",
    "        ground_truth[gt_index[0], gt_index[1] - original['proposal'].shift] = True\n",
    "\n",
    "        isin_rmat = ground_truth.gather(1, topr - original['proposal'].shift)\n",
    "        isin_mat = isin_rmat[:, :k]\n",
    "\n",
    "        prec = (isin_mat.sum(dim=-1) / k).sum() / n_samples\n",
    "        rec = (isin_mat.sum(dim=-1) / item_count).sum() / n_samples\n",
    "\n",
    "        # Now mask isin_rmat to get only up to :R elements\n",
    "        msk = torch.arange(1, R.max()+1, device=device) > R.unsqueeze(1)\n",
    "        isin_rmat[msk] = 0\n",
    "        rprec = (isin_rmat.sum(dim=-1) / R).sum() / n_samples\n",
    "\n",
    "        # print('prec, rec:', (prec, rec))\n",
    "        \n",
    "        return float(prec), float(rec), float(rprec)\n",
    "\n",
    "    for epoch in trange(start_epoch, modelConfig.max_epochs, disable=disable_tqdm):\n",
    "        # index is an array of batch_size that indicates which edges from \n",
    "        # train.edge_index we should use\n",
    "        acc_loss = n_samples = 0        \n",
    "        \n",
    "        for index in tqdm(train_loader, leave=False, delay=1, disable=disable_tqdm):\n",
    "            pos_edge_index = train_edge_label_index[:, index]\n",
    "            # TODO: Change to negative structured sampling like in original LightGCN implementation\n",
    "            neg_edge_index = torch.stack([\n",
    "                pos_edge_index[0],\n",
    "                torch.randint(train['proposal'].shift, train['proposal'].end,\n",
    "                          (pos_edge_index.size(1), ), device=device)\n",
    "            ], dim=0)\n",
    "            \n",
    "            edge_label_index = torch.cat([\n",
    "                pos_edge_index,\n",
    "                neg_edge_index,\n",
    "            ], dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pos_rank, neg_rank = model(message_passing_edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "            # Learning\n",
    "            loss = model.recommendation_loss(\n",
    "                pos_rank,\n",
    "                neg_rank,\n",
    "                node_id=edge_label_index.unique(),\n",
    "                lambda_reg=modelConfig.l2,\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_loss += float(loss) * pos_rank.numel()\n",
    "            n_samples += pos_rank.numel()\n",
    "\n",
    "        checkpoint = Checkpoint.from_dict({\n",
    "            'epoch': epoch,\n",
    "            'net_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        })\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pos_val_edge_index = validation['voter', 'votes', 'proposal'].edge_index\n",
    "            neg_val_edge_index = torch.stack([\n",
    "                pos_val_edge_index[0],\n",
    "                torch.randint(validation['proposal'].shift, validation['proposal'].end, (pos_val_edge_index.size(1),), device=device)\n",
    "            ], dim=0)\n",
    "            val_label_index = torch.cat([\n",
    "                pos_val_edge_index,\n",
    "                neg_val_edge_index,\n",
    "            ], dim=1)\n",
    "            pos_rank, neg_rank = model(message_passing_edge_index, val_label_index).chunk(2)\n",
    "            val_loss = model.recommendation_loss(\n",
    "                pos_rank, \n",
    "                neg_rank, \n",
    "                node_id=val_label_index.unique(), \n",
    "                lambda_reg=modelConfig.l2\n",
    "            ).item()\n",
    "            \n",
    "            prec5, rec5, rprec = _prec_rec(5, remove_training=False)\n",
    "            prec5t, rec5t, rprect = _prec_rec(5, remove_training=True)\n",
    "            session.report({\n",
    "                'loss': acc_loss/n_samples,\n",
    "                'val_loss': val_loss,\n",
    "                'rprec train': rprec, 'rprec test': rprect,\n",
    "                'p@5 train': prec5, 'p@5 test': prec5t,\n",
    "                'r@5 train': rec5, 'r@5 test': rec5t,\n",
    "            }, checkpoint=checkpoint)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Testing just syntax errors\n",
    "model = train_daostack(graph_folds[0][0].to(device), graph_folds[0][1].to(device), data.to(device), ModelConfig(**(modelConfig._asdict() | {'max_epochs':2})))\n",
    "print(PyG.nn.summary(model, data['voter', 'votes', 'proposal'].edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-17 15:56:18</td></tr>\n",
       "<tr><td>Running for: </td><td>01:31:37.15        </td></tr>\n",
       "<tr><td>Memory:      </td><td>40.6/125.6 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 24.0/24 CPUs, 0.75/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  ... 789 more trials not shown (14 RUNNING, 774 TERMINATED)\n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  __trial_index__</th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_layers</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">         l2</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  rprec train</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_aux_train_daostack_0a7d7cba</td><td>RUNNING   </td><td>147.96.81.131:1766262</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             25</td><td style=\"text-align: right;\">1.88629e-06</td><td style=\"text-align: right;\">        0.00282</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">        183.978 </td><td style=\"text-align: right;\">0.125328</td><td style=\"text-align: right;\">  0.844526</td><td style=\"text-align: right;\">     0.60739 </td></tr>\n",
       "<tr><td>_aux_train_daostack_0e629806</td><td>RUNNING   </td><td>147.96.81.131:1767242</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             25</td><td style=\"text-align: right;\">1.88629e-06</td><td style=\"text-align: right;\">        0.00282</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">        195.097 </td><td style=\"text-align: right;\">0.129559</td><td style=\"text-align: right;\">  0.823479</td><td style=\"text-align: right;\">     0.64876 </td></tr>\n",
       "<tr><td>_aux_train_daostack_236994a7</td><td>RUNNING   </td><td>147.96.81.131:1766471</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             75</td><td style=\"text-align: right;\">9.18826e-06</td><td style=\"text-align: right;\">        0.0043 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         11.2934</td><td style=\"text-align: right;\">0.220604</td><td style=\"text-align: right;\">  0.601125</td><td style=\"text-align: right;\">     0.460909</td></tr>\n",
       "<tr><td>_aux_train_daostack_3d8a9e28</td><td>RUNNING   </td><td>147.96.81.131:1766032</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">            115</td><td style=\"text-align: right;\">1.05648e-06</td><td style=\"text-align: right;\">        0.00337</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         42.181 </td><td style=\"text-align: right;\">0.135829</td><td style=\"text-align: right;\">  0.726379</td><td style=\"text-align: right;\">     0.628821</td></tr>\n",
       "<tr><td>_aux_train_daostack_3ffcf8e9</td><td>RUNNING   </td><td>147.96.81.131:1766210</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             75</td><td style=\"text-align: right;\">9.18826e-06</td><td style=\"text-align: right;\">        0.0043 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         16.947 </td><td style=\"text-align: right;\">0.203357</td><td style=\"text-align: right;\">  0.637971</td><td style=\"text-align: right;\">     0.482316</td></tr>\n",
       "<tr><td>_aux_train_daostack_45db069a</td><td>RUNNING   </td><td>147.96.81.131:1766523</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             65</td><td style=\"text-align: right;\">2.34467e-06</td><td style=\"text-align: right;\">        0.0223 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         66.712 </td><td style=\"text-align: right;\">0.21477 </td><td style=\"text-align: right;\">  1.41545 </td><td style=\"text-align: right;\">     0.720728</td></tr>\n",
       "<tr><td>_aux_train_daostack_4c37a031</td><td>RUNNING   </td><td>147.96.81.131:1766418</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             65</td><td style=\"text-align: right;\">2.34467e-06</td><td style=\"text-align: right;\">        0.0223 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         66.7118</td><td style=\"text-align: right;\">0.225403</td><td style=\"text-align: right;\">  1.41055 </td><td style=\"text-align: right;\">     0.71893 </td></tr>\n",
       "<tr><td>_aux_train_daostack_6013c92b</td><td>RUNNING   </td><td>147.96.81.131:1765765</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             25</td><td style=\"text-align: right;\">1.88629e-06</td><td style=\"text-align: right;\">        0.00282</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">        206.928 </td><td style=\"text-align: right;\">0.120031</td><td style=\"text-align: right;\">  0.80165 </td><td style=\"text-align: right;\">     0.629484</td></tr>\n",
       "<tr><td>_aux_train_daostack_63fbf10b</td><td>RUNNING   </td><td>147.96.81.131:1765928</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             75</td><td style=\"text-align: right;\">9.18826e-06</td><td style=\"text-align: right;\">        0.0043 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         22.5321</td><td style=\"text-align: right;\">0.183542</td><td style=\"text-align: right;\">  0.681548</td><td style=\"text-align: right;\">     0.532967</td></tr>\n",
       "<tr><td>_aux_train_daostack_65a596f8</td><td>RUNNING   </td><td>147.96.81.131:1766314</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             30</td><td style=\"text-align: right;\">3.27888e-07</td><td style=\"text-align: right;\">        0.00092</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         44.1677</td><td style=\"text-align: right;\">0.302842</td><td style=\"text-align: right;\">  0.480791</td><td style=\"text-align: right;\">     0.342652</td></tr>\n",
       "<tr><td>_aux_train_daostack_e7b5718a</td><td>PENDING   </td><td>                     </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             75</td><td style=\"text-align: right;\">9.18826e-06</td><td style=\"text-align: right;\">        0.0043 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>_aux_train_daostack_007f4626</td><td>TERMINATED</td><td>147.96.81.131:1766099</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             40</td><td style=\"text-align: right;\">1.58421e-05</td><td style=\"text-align: right;\">        0.00681</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        350.688 </td><td style=\"text-align: right;\">0.118606</td><td style=\"text-align: right;\">  0.887839</td><td style=\"text-align: right;\">     0.77569 </td></tr>\n",
       "<tr><td>_aux_train_daostack_01887c54</td><td>TERMINATED</td><td>147.96.81.131:1766366</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             60</td><td style=\"text-align: right;\">6.43956e-05</td><td style=\"text-align: right;\">        0.00211</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        151.744 </td><td style=\"text-align: right;\">0.117374</td><td style=\"text-align: right;\">  0.832717</td><td style=\"text-align: right;\">     0.687838</td></tr>\n",
       "<tr><td>_aux_train_daostack_01e82a1d</td><td>TERMINATED</td><td>147.96.81.131:1765712</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">            315</td><td style=\"text-align: right;\">0.000480704</td><td style=\"text-align: right;\">        0.00227</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         97.1325</td><td style=\"text-align: right;\">0.130261</td><td style=\"text-align: right;\">  0.737362</td><td style=\"text-align: right;\">     0.715757</td></tr>\n",
       "<tr><td>_aux_train_daostack_01f144fc</td><td>TERMINATED</td><td>147.96.81.131:1765928</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             45</td><td style=\"text-align: right;\">0.000924315</td><td style=\"text-align: right;\">        0.00025</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        344.951 </td><td style=\"text-align: right;\">0.289651</td><td style=\"text-align: right;\">  0.487725</td><td style=\"text-align: right;\">     0.379872</td></tr>\n",
       "<tr><td>_aux_train_daostack_021df1e4</td><td>TERMINATED</td><td>147.96.81.131:1766674</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             70</td><td style=\"text-align: right;\">2.61453e-07</td><td style=\"text-align: right;\">        0.00083</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        331.973 </td><td style=\"text-align: right;\">0.129967</td><td style=\"text-align: right;\">  0.803822</td><td style=\"text-align: right;\">     0.588787</td></tr>\n",
       "<tr><td>_aux_train_daostack_02ad6815</td><td>TERMINATED</td><td>147.96.81.131:1765873</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">            115</td><td style=\"text-align: right;\">0.000130653</td><td style=\"text-align: right;\">        0.04406</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        461.871 </td><td style=\"text-align: right;\">0.820064</td><td style=\"text-align: right;\">  3.88424 </td><td style=\"text-align: right;\">     0.718211</td></tr>\n",
       "<tr><td>_aux_train_daostack_02c8c40b</td><td>TERMINATED</td><td>147.96.81.131:1765928</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             10</td><td style=\"text-align: right;\">1.68819e-06</td><td style=\"text-align: right;\">        0.10941</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        340.268 </td><td style=\"text-align: right;\">0.537183</td><td style=\"text-align: right;\">  2.25975 </td><td style=\"text-align: right;\">     0.421876</td></tr>\n",
       "<tr><td>_aux_train_daostack_038fd854</td><td>TERMINATED</td><td>147.96.81.131:1765712</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">4.69463e-05</td><td style=\"text-align: right;\">        0.00779</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        287.645 </td><td style=\"text-align: right;\">0.115825</td><td style=\"text-align: right;\">  0.914666</td><td style=\"text-align: right;\">     0.725496</td></tr>\n",
       "<tr><td>_aux_train_daostack_03fdc9de</td><td>TERMINATED</td><td>147.96.81.131:1767242</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             20</td><td style=\"text-align: right;\">1.35027e-07</td><td style=\"text-align: right;\">        0.16085</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        172.128 </td><td style=\"text-align: right;\">2.24709 </td><td style=\"text-align: right;\"> 12.2892  </td><td style=\"text-align: right;\">     0.535048</td></tr>\n",
       "<tr><td>_aux_train_daostack_0421bec6</td><td>TERMINATED</td><td>147.96.81.131:1767242</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">            330</td><td style=\"text-align: right;\">9.39322e-07</td><td style=\"text-align: right;\">        5e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        315.753 </td><td style=\"text-align: right;\">0.26721 </td><td style=\"text-align: right;\">  0.541337</td><td style=\"text-align: right;\">     0.407784</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search import Repeater\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "def _aux_train_daostack(config):\n",
    "    # TODO: Is bad practice to pass a dataset trainable\n",
    "    # config['embedding_dim'] = 2**config['embedding_dim']\n",
    "    config['batch_size'] = 2**config['batch_size']\n",
    "    n_fold = config.pop('__trial_index__')\n",
    "    train, validation = graph_folds[n_fold]\n",
    "    train_daostack(train.to(device), validation.to(device), data.to(device), config, disable_tqdm=True)\n",
    "\n",
    "if os.uname().nodename == 'lamarck':\n",
    "    assert torch.cuda.is_available()\n",
    "    \n",
    "    NUM_SAMPLES = 250\n",
    "    # Every run takes approx half a gig of vram (no optimizations)\n",
    "    # The RTX 4090 has 24GB so we can run the model about 48 times\n",
    "    resources_per_trial={\n",
    "        'cpu': 1,\n",
    "        'gpu': 1/32,\n",
    "    }\n",
    "else:\n",
    "    NUM_SAMPLES = 1\n",
    "    resources_per_trial={\n",
    "        'cpu': 2,\n",
    "        'memory': 2e9,\n",
    "    }\n",
    "\n",
    "tryConfigs = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    conv_layers=tune.randint(2,6),\n",
    "    learning_rate=tune.qloguniform(1e-5, 1, 1e-5),\n",
    "    l2=tune.loguniform(1e-9, 1e-1),\n",
    "    # These will be 2 to the power\n",
    "    batch_size=tune.randint(4,10), # 16..1024\n",
    "    # embedding_dim=tune.randint(4,8), # 16..128\n",
    "    embedding_dim=tune.qlograndint(10, 500, 5),\n",
    ")\n",
    "\n",
    "# It is recommended to not use Repeater with a TrialScheduler. Early termination can negatively affect the average reported metric.\n",
    "asha_scheduler = None\n",
    "# asha_scheduler = ASHAScheduler(\n",
    "#     time_attr='training_iteration',\n",
    "#     max_t=50,\n",
    "#     grace_period=5,\n",
    "#     reduction_factor=3,\n",
    "#     brackets=1,\n",
    "# )\n",
    "\n",
    "search_alg = HyperOptSearch()\n",
    "search_alg = Repeater(search_alg,datasetConfig.num_folds)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(_aux_train_daostack, resources_per_trial),\n",
    "    param_space=tryConfigs._asdict(),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        # time_budget_s=60,\n",
    "        num_samples=datasetConfig.num_folds*NUM_SAMPLES,\n",
    "        scheduler=asha_scheduler,\n",
    "        search_alg=search_alg,\n",
    "        metric='rprec test',\n",
    "        mode='max',\n",
    "    )\n",
    ")\n",
    "exp = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = exp.get_dataframe().drop(columns=['hostname', 'node_ip', 'logdir', 'should_checkpoint', 'pid'])\n",
    "exp_df.sort_values('p@5 test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all of this\n",
    "\n",
    "Crearé una función que reciba una dirección de un usuario y retorne k propuestas que puedan interesarle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user: str, K: int = 12, ignore_train: bool=False):\n",
    "    uid = encoder_user.transform([user])[0]\n",
    "    print(f\"Recommending {K} proposals for user {user} (uid:{uid}) with {vpu.at[user]} votes\")\n",
    "    \n",
    "    # Getting embedding\n",
    "    out = model(edge_index)\n",
    "    user_embed, item_embed = torch.split(out, (model.n_users, model.n_items))\n",
    "    relevance_score = torch.matmul(user_embed, torch.transpose(item_embed, 0, 1))\n",
    "    if ignore_train:\n",
    "        i = torch.stack([\n",
    "            torch.LongTensor(train_df['uid'].values),\n",
    "            torch.LongTensor(train_df['pid'].values),\n",
    "        ])\n",
    "        v = torch.ones(len(train_df), dtype=torch.float64)\n",
    "        t_interactions = torch.sparse.FloatTensor(i, v, (model.n_users, model.n_items)).to_dense().to(device)\n",
    "        # mask out training user-item interactions from metric computation\n",
    "        # We are only interested in novel items, as a user won't be interested\n",
    "        # in \"voting again\"\n",
    "        relevance_score = torch.mul(relevance_score, (1 - t_interactions))\n",
    "    \n",
    "    topk_relevance_indices = torch.topk(relevance_score, K).indices\n",
    "    \n",
    "    pids = topk_relevance_indices[uid].tolist()\n",
    "    proposals = dfp.loc[encoder_prop.inverse_transform(pids)]\n",
    "    \n",
    "    proposals['userVoted'] = dfv.groupby('proposal')['voter'].apply(lambda x: user in set(x))\n",
    "    \n",
    "    print(f\"precision@{K}={sum(proposals['userVoted'])/len(proposals)*100:.2f}%\")\n",
    "    \n",
    "    return proposals\n",
    "\n",
    "user = \"0x334f12afb7d8740868be04719639616533075234\" # vpu[(12 < vpu) & (vpu < 38)].sample().index[0]\n",
    "recommend(user, ignore_train=True)[['network', 'createdAt', 'title', 'description', 'userVoted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv[dfv['proposal'] == '0xb92d2df99a47244c07a9d7ef73530c273f1d65230dbff9e95873d82c0314534e']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05b82e650fd04c8db60f0d16385870d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_de3e1c769d4b457fbefb0e08e62fab66",
       "max": 104,
       "style": "IPY_MODEL_451c94997d8445279e68734a642b1173",
       "value": 104
      }
     },
     "08e7e0f341634e8c98058184fafe64d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "096217db7b2547279ef1cf7e309ff291": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0d9f9f2ca3fd404393b7e141cbfde82a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e596644604374d8b919130758891662d",
       "style": "IPY_MODEL_c219b9b5df3144faafd6b3a40f0fcc90",
       "value": " 0/104 [00:00&lt;?, ?it/s]"
      }
     },
     "128ef7a5d3d74691ba953403b6a7dab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1afe05b6067c427d81cf0e7785bd5427": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2321236a61ab42999e96f607af33b5a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3121a095e35d42baa2e37c534894db9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1afe05b6067c427d81cf0e7785bd5427",
       "style": "IPY_MODEL_50a0d9640726444b8febd2a672b08533",
       "value": "  0%"
      }
     },
     "451c94997d8445279e68734a642b1173": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4dc9ed1052b7481ab038a0f7ff329f65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_faa35114f62c41218d834ccb8c0bf17c",
       "max": 104,
       "style": "IPY_MODEL_f9df54548f3848cfa189c1eabf4a1201",
       "value": 104
      }
     },
     "50a0d9640726444b8febd2a672b08533": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "52b1af4ca06243939875b280decf0ea0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_77738ee9e0e746188c849163a9520be8",
        "IPY_MODEL_79a3ca333af84b269cb0a1816fa4cfc2",
        "IPY_MODEL_9945701c612648c4a5870c86ef0637f6"
       ],
       "layout": "IPY_MODEL_ac8ab575c1c34277815fb4fd064d325a"
      }
     },
     "62afaf10bf114f2ba8757ada6b28a91e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "77738ee9e0e746188c849163a9520be8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d4f379a4a26d43e39bb1a6b9602db611",
       "style": "IPY_MODEL_79a77966855a45bba4dd11d1891478cd",
       "value": "100%"
      }
     },
     "79a3ca333af84b269cb0a1816fa4cfc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_08e7e0f341634e8c98058184fafe64d9",
       "max": 2,
       "style": "IPY_MODEL_c02b2e18d7184446b14ae06eaa9ed3e7",
       "value": 2
      }
     },
     "79a77966855a45bba4dd11d1891478cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7a6e74546e494d889ec7b336709e3064": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_096217db7b2547279ef1cf7e309ff291",
       "style": "IPY_MODEL_db36e65ffa1145b1b568f64eba90f8e0",
       "value": " 0/104 [00:00&lt;?, ?it/s]"
      }
     },
     "85b437eb9d3b4ae7b98fbb83c2b34233": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2321236a61ab42999e96f607af33b5a5",
       "style": "IPY_MODEL_128ef7a5d3d74691ba953403b6a7dab9",
       "value": "  0%"
      }
     },
     "9911c518b0c848fb87f1e8f50a2ea10d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "visibility": "hidden"
      }
     },
     "9945701c612648c4a5870c86ef0637f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e4665d2fd67f45c9bd3731f304eeff7b",
       "style": "IPY_MODEL_62afaf10bf114f2ba8757ada6b28a91e",
       "value": " 2/2 [00:01&lt;00:00,  1.89it/s]"
      }
     },
     "ac8ab575c1c34277815fb4fd064d325a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bdbcc539966b4dfa9b79ab9f00a3638e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "visibility": "hidden"
      }
     },
     "c02b2e18d7184446b14ae06eaa9ed3e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c219b9b5df3144faafd6b3a40f0fcc90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d4f379a4a26d43e39bb1a6b9602db611": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "db36e65ffa1145b1b568f64eba90f8e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "de3e1c769d4b457fbefb0e08e62fab66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4665d2fd67f45c9bd3731f304eeff7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e596644604374d8b919130758891662d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f9df54548f3848cfa189c1eabf4a1201": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "faa35114f62c41218d834ccb8c0bf17c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
