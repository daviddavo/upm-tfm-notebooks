{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Pytorch Geometric official example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:26.866972Z",
     "iopub.status.busy": "2023-08-17T14:06:26.866832Z",
     "iopub.status.idle": "2023-08-17T14:06:28.582622Z",
     "shell.execute_reply": "2023-08-17T14:06:28.582048Z",
     "shell.execute_reply.started": "2023-08-17T14:06:26.866956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5266/1034952450.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/src/neg_sampling.py:13: UserWarning: This is copied from https://github.com/pyg-team/pytorch_geometric/pull/7816\n",
      "  warnings.warn('This is copied from https://github.com/pyg-team/pytorch_geometric/pull/7816')\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/src/neg_sampling.py:14: UserWarning: REMOVE WHEN MERGED\n",
      "  warnings.warn('REMOVE WHEN MERGED')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm.notebook import tqdm # Progress bars\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "# https://import-as.github.io\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as PyG\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import src\n",
    "from src.data import get_df, filter_df\n",
    "from src.graph_utils import shift_edge_indices, unshift_edge_indices\n",
    "from src.neg_sampling import structured_negative_sampling\n",
    "\n",
    "RANDOM_SEED = 1701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters table in [Google Drive](https://docs.google.com/spreadsheets/d/1riafpWt1563w9pbqdt1g2QZVkc7TfRWGzFaCG5rudDI/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:28.583796Z",
     "iopub.status.busy": "2023-08-17T14:06:28.583645Z",
     "iopub.status.idle": "2023-08-17T14:06:28.586384Z",
     "shell.execute_reply": "2023-08-17T14:06:28.586115Z",
     "shell.execute_reply.started": "2023-08-17T14:06:28.583780Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Remove users with less than 6 votes from the dataset before splitting\n",
    "DatasetConfig = namedtuple('DatasetConfig', ('min_votes_per_user', 'allowed_dao_names', 'num_folds'))\n",
    "datasetConfig = DatasetConfig(\n",
    "    min_votes_per_user=6,\n",
    "    allowed_dao_names={'dxDAO', 'xDXdao'},\n",
    "    num_folds=5,\n",
    ")\n",
    "\n",
    "ModelConfig = namedtuple('ModelConfig', 'max_epochs batch_size learning_rate embedding_dim conv_layers l2')\n",
    "modelConfig = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    embedding_dim=32,\n",
    "    conv_layers=3,\n",
    "    l2=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:28.586888Z",
     "iopub.status.busy": "2023-08-17T14:06:28.586788Z",
     "iopub.status.idle": "2023-08-17T14:06:28.634550Z",
     "shell.execute_reply": "2023-08-17T14:06:28.634204Z",
     "shell.execute_reply.started": "2023-08-17T14:06:28.586879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:          16606\n",
      "Density:       0.3087%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  voter={ num_nodes=104 },\n",
       "  proposal={ num_nodes=2216 },\n",
       "  (voter, votes, proposal)={ edge_index=[2, 8303] },\n",
       "  (proposal, voted, voter)={ edge_index=[2, 8303] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, HeteroData, Data\n",
    "from src.datasets import Daostack\n",
    "\n",
    "def print_graph_stats(g: HeteroData):\n",
    "    density = (g.num_edges) / (g.num_nodes*(g.num_nodes-1))\n",
    "    print(f'Edges:   {g.num_edges:12}')\n",
    "    print(f'Density: {density*100:12.4f}%')\n",
    "\n",
    "data = Daostack(\"./data/dao-analyzer/\", min_vpu=datasetConfig.min_votes_per_user, allowed_daos=datasetConfig.allowed_dao_names)[0]\n",
    "print_graph_stats(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I thought the RandomLinkSplit function was not working properly, but it turns out that I wasn't understanding it very well. The tutorial I used for [01_mvp](./01_mvp.ipynb) is not very good either, it was written by students, and implemented before PyTorch Geometric bundled the LightGCN model with it.\n",
    "\n",
    "> I think this is totally correct. It seems like you are looking at the shapes of edge_index, while you may want to look at the shapes of edge_label and edge_label_index (which correctly model a 80/10/10 split ratio). Here, edge_index is solely used for message passing, i.e.,\n",
    "> \n",
    "> * for training, we exchange messages on all training edges\n",
    "> * for validation, we exchange messages on all training edges\n",
    "> * for testing, we exchange messages on all training and validation edges\n",
    "> Let me know if this resolves your concerns :)\n",
    ">\n",
    "> -- [Split Error in RandomLinkSplit · Issue #3668 · pyg-team/pytorch_geometric · GitHub](https://github.com/pyg-team/pytorch_geometric/issues/3668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:28.635140Z",
     "iopub.status.busy": "2023-08-17T14:06:28.635004Z",
     "iopub.status.idle": "2023-08-17T14:06:28.669336Z",
     "shell.execute_reply": "2023-08-17T14:06:28.669011Z",
     "shell.execute_reply.started": "2023-08-17T14:06:28.635129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6643] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6643] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1660] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1660] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6643] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6643] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1660] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1660] }\n",
       "  ))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def graph_k_fold(g: Data | HeteroData, folds, edge_type=None):\n",
    "    skf = StratifiedKFold(folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    # Stratify by voter\n",
    "    if edge_type is None:\n",
    "        edge_type = g.edge_types[0]\n",
    "        rev_edge_type = g.edge_types[1]\n",
    "        \n",
    "    edge_index = g[edge_type].edge_index\n",
    "    for train_idx, val_idx in skf.split(torch.zeros(edge_index.size(1)), edge_index[0]):\n",
    "        gtrain = g.edge_subgraph({\n",
    "            edge_type:torch.tensor(train_idx),\n",
    "            rev_edge_type:torch.tensor(train_idx),\n",
    "        })\n",
    "        assert gtrain.is_undirected()\n",
    "        assert len(gtrain[edge_type].edge_index[0].unique()) == len(g[edge_type].edge_index[0].unique())\n",
    "        # The negative samples should be different each epoch\n",
    "        # gtrain[edge_type].negative_samples = structured_negative_sampling(gtrain[edge_type].edge_index, (aux[edge_type[0]].num_nodes, aux[edge_type[2]].num_nodes))[2]\n",
    "        gval = g.edge_subgraph({\n",
    "            edge_type:torch.tensor(val_idx),\n",
    "            rev_edge_type:torch.tensor(val_idx),\n",
    "        })\n",
    "        assert gval.is_undirected()\n",
    "        assert len(gval[edge_type].edge_index[0].unique()) == len(g[edge_type].edge_index[0].unique())\n",
    "        assert (gtrain[edge_type].edge_index[0].unique() == gval[edge_type].edge_index[0].unique()).all()\n",
    "\n",
    "        folds.append((gtrain, gval))\n",
    "\n",
    "    return folds\n",
    "\n",
    "graph_folds = graph_k_fold(data, datasetConfig.num_folds)\n",
    "graph_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:28.669921Z",
     "iopub.status.busy": "2023-08-17T14:06:28.669812Z",
     "iopub.status.idle": "2023-08-17T14:06:28.672577Z",
     "shell.execute_reply": "2023-08-17T14:06:28.672298Z",
     "shell.execute_reply.started": "2023-08-17T14:06:28.669911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:28.673034Z",
     "iopub.status.busy": "2023-08-17T14:06:28.672942Z",
     "iopub.status.idle": "2023-08-17T14:06:28.681920Z",
     "shell.execute_reply": "2023-08-17T14:06:28.681627Z",
     "shell.execute_reply.started": "2023-08-17T14:06:28.673025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,1,2,3,4,5,6,7,8,9,10][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:28.683087Z",
     "iopub.status.busy": "2023-08-17T14:06:28.682848Z",
     "iopub.status.idle": "2023-08-17T14:06:28.690478Z",
     "shell.execute_reply": "2023-08-17T14:06:28.690200Z",
     "shell.execute_reply.started": "2023-08-17T14:06:28.683075Z"
    }
   },
   "outputs": [],
   "source": [
    "def recommend_excluding(model, edge_index, src_index, dst_index, exclude_edges=None, k = 1):\n",
    "    emb = model.get_embedding(edge_index)\n",
    "\n",
    "    out_src = emb[src_index]\n",
    "    out_dst = emb[dst_index]\n",
    "\n",
    "    pred = out_src @ out_dst.t()\n",
    "\n",
    "    if exclude_edges is not None:\n",
    "        inv_src = torch.full((src_index.max().item()+1,), -1)\n",
    "        inv_src[src_index] = torch.arange(0, src_index.numel())\n",
    "\n",
    "        inv_dst = torch.full((dst_index.max().item()+1,), -1)\n",
    "        inv_dst[dst_index] = torch.arange(0, dst_index.numel())\n",
    "        \n",
    "        exclude_src = inv_src[exclude_edges[0]]\n",
    "        exclude_dst = inv_dst[exclude_edges[1]]\n",
    "        \n",
    "        pred[exclude_src, exclude_dst] = -np.inf\n",
    "\n",
    "    top_index = pred.topk(k, dim=-1).indices\n",
    "    top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
    "\n",
    "    return top_index\n",
    "\n",
    "# hdata = data.to_homogeneous()\n",
    "# strain = shift_edge_indices(graph_folds[0][0])\n",
    "# users = torch.arange(strain['voter'].shift + 10, strain['voter'].end, 2)\n",
    "# items = torch.arange(strain['proposal'].shift, strain['proposal'].end)\n",
    "# recommend_excluding(model, hdata.edge_index, torch.tensor([4, 8]), items, k=10, exclude_edges=torch.tensor([[8,4,4,4], [2296, 282, 600, 905]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:28.691063Z",
     "iopub.status.busy": "2023-08-17T14:06:28.690876Z",
     "iopub.status.idle": "2023-08-17T14:06:29.771849Z",
     "shell.execute_reply": "2023-08-17T14:06:29.771557Z",
     "shell.execute_reply.started": "2023-08-17T14:06:28.691052Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:06:28,703\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/.direnv/python-3.11/lib/python3.11/site-packages/ray/air/session.py:28: UserWarning: `get_checkpoint` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b1af4ca06243939875b280decf0ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:06:29,236\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/.direnv/python-3.11/lib/python3.11/site-packages/ray/air/session.py:28: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n",
      "2023-08-17 16:06:29,765\tWARNING session.py:100 -- In neither tune session nor train session!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------+----------------+----------+\n",
      "| Layer                  | Input Shape           | Output Shape   | #Param   |\n",
      "|------------------------+-----------------------+----------------+----------|\n",
      "| LightGCN               | [2, 8303]             | [8303]         | 74,240   |\n",
      "| ├─(embedding)Embedding | --                    | --             | 74,240   |\n",
      "| ├─(convs)ModuleList    | --                    | --             | --       |\n",
      "| │    └─(0)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "| │    └─(1)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "| │    └─(2)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "+------------------------+-----------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import LightGCN\n",
    "\n",
    "# Based on:\n",
    "# - https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# - https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
    "# - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "def train_daostack(train: HeteroData, validation: HeteroData, original: HeteroData, modelConfig: ModelConfig, disable_tqdm=False):\n",
    "    if not isinstance(modelConfig, ModelConfig):\n",
    "        modelConfig = ModelConfig(**modelConfig)\n",
    "    \n",
    "    model = LightGCN(\n",
    "        num_nodes=original.num_nodes,\n",
    "        embedding_dim=modelConfig.embedding_dim,\n",
    "        num_layers=modelConfig.conv_layers,\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=modelConfig.learning_rate)\n",
    "\n",
    "    checkpoint = session.get_checkpoint()\n",
    "\n",
    "    if checkpoint:\n",
    "        checkpoint_state = checkpoint.to_dict()\n",
    "        start_epoch = checkpoint_state[\"epoch\"]\n",
    "        model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    assert train.is_undirected()\n",
    "    assert validation.is_undirected()\n",
    "\n",
    "    # We need to convert the edge indices to homogeneous\n",
    "    # In hetero data the numbers are shared between the node types\n",
    "    # while in homo data they are shifted\n",
    "    original, train, validation = map(shift_edge_indices, [original, train, validation])\n",
    "    \n",
    "    # nodes = torch.arange(0, train.num_nodes, device=device)\n",
    "    users = torch.arange(train['voter'].shift, train['voter'].end, device=device)\n",
    "    items = torch.arange(train['proposal'].shift, train['proposal'].end, device=device)\n",
    "    n_users = train['voter'].num_nodes\n",
    "    n_items = train['proposal'].num_nodes\n",
    "\n",
    "    message_passing_edge_index = torch.concat([s.edge_index for s in train.edge_stores], dim=1)\n",
    "\n",
    "    # The official LightGCN usage also uses this line of code (well, for homo graphs)\n",
    "    # - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "    # In our case, we will use just voter ---> proposal\n",
    "    train_edge_label_index = train['voter', 'votes', 'proposal'].edge_index\n",
    "    assert (train_edge_label_index[0] < train['voter'].end).all()\n",
    "    assert (train['proposal'].shift <= train_edge_label_index[1]).all()\n",
    "\n",
    "    # TODO: Use LinkLoader instead (i don't know how)\n",
    "    # Waiting for pyg-team/pytorch_geometric#7817\n",
    "    # train_loader = PyG.loader.LinkLoader(\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        range(train_edge_label_index.size(1)), # dataset\n",
    "        batch_size=modelConfig.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _prec_rec(k: int, remove_training=False):\n",
    "        # gt: ground truth\n",
    "        if remove_training:\n",
    "            gt_index = validation['voter', 'votes', 'proposal'].edge_index\n",
    "            exclude_edges = train['voter', 'votes', 'proposal'].edge_index\n",
    "        else:\n",
    "            # All edges\n",
    "            gt_index = original['voter', 'votes', 'proposal'].edge_index\n",
    "            exclude_edges = None\n",
    "\n",
    "        R = item_count = PyG.utils.degree(gt_index[0], num_nodes=n_users)\n",
    "        # topr.size [104, R.max()]\n",
    "        topr = recommend_excluding(model, message_passing_edge_index, src_index=users, dst_index=items, k=int(R.max()), exclude_edges=exclude_edges)\n",
    "        n_samples = len(users)\n",
    "\n",
    "        # [104, 2216]\n",
    "        ground_truth = torch.full((n_users, n_items), False, dtype=torch.bool, device=device)\n",
    "        ground_truth[gt_index[0], gt_index[1] - original['proposal'].shift] = True\n",
    "\n",
    "        isin_rmat = ground_truth.gather(1, topr - original['proposal'].shift)\n",
    "        isin_mat = isin_rmat[:, :k]\n",
    "\n",
    "        prec = (isin_mat.sum(dim=-1) / k).sum() / n_samples\n",
    "        rec = (isin_mat.sum(dim=-1) / item_count).sum() / n_samples\n",
    "\n",
    "        # Now mask isin_rmat to get only up to :R elements\n",
    "        msk = torch.arange(1, R.max()+1, device=device) > R.unsqueeze(1)\n",
    "        isin_rmat[msk] = 0\n",
    "        rprec = (isin_rmat.sum(dim=-1) / R).sum() / n_samples\n",
    "\n",
    "        # print('prec, rec:', (prec, rec))\n",
    "        \n",
    "        return float(prec), float(rec), float(rprec)\n",
    "\n",
    "    for epoch in trange(start_epoch, modelConfig.max_epochs, disable=disable_tqdm):\n",
    "        # index is an array of batch_size that indicates which edges from \n",
    "        # train.edge_index we should use\n",
    "        acc_loss = n_samples = 0        \n",
    "        \n",
    "        for index in tqdm(train_loader, leave=False, delay=1, disable=disable_tqdm):\n",
    "            pos_edge_index = train_edge_label_index[:, index]\n",
    "            # TODO: Change to negative structured sampling like in original LightGCN implementation\n",
    "            neg_edge_index = torch.stack([\n",
    "                pos_edge_index[0],\n",
    "                torch.randint(train['proposal'].shift, train['proposal'].end,\n",
    "                          (pos_edge_index.size(1), ), device=device)\n",
    "            ], dim=0)\n",
    "            \n",
    "            edge_label_index = torch.cat([\n",
    "                pos_edge_index,\n",
    "                neg_edge_index,\n",
    "            ], dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pos_rank, neg_rank = model(message_passing_edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "            # Learning\n",
    "            loss = model.recommendation_loss(\n",
    "                pos_rank,\n",
    "                neg_rank,\n",
    "                node_id=edge_label_index.unique(),\n",
    "                lambda_reg=modelConfig.l2,\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_loss += float(loss) * pos_rank.numel()\n",
    "            n_samples += pos_rank.numel()\n",
    "\n",
    "        checkpoint = Checkpoint.from_dict({\n",
    "            'epoch': epoch,\n",
    "            'net_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        })\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pos_val_edge_index = validation['voter', 'votes', 'proposal'].edge_index\n",
    "            neg_val_edge_index = torch.stack([\n",
    "                pos_val_edge_index[0],\n",
    "                torch.randint(validation['proposal'].shift, validation['proposal'].end, (pos_val_edge_index.size(1),), device=device)\n",
    "            ], dim=0)\n",
    "            val_label_index = torch.cat([\n",
    "                pos_val_edge_index,\n",
    "                neg_val_edge_index,\n",
    "            ], dim=1)\n",
    "            pos_rank, neg_rank = model(message_passing_edge_index, val_label_index).chunk(2)\n",
    "            val_loss = model.recommendation_loss(\n",
    "                pos_rank, \n",
    "                neg_rank, \n",
    "                node_id=val_label_index.unique(), \n",
    "                lambda_reg=modelConfig.l2\n",
    "            ).item()\n",
    "            \n",
    "            prec5, rec5, rprec = _prec_rec(5, remove_training=False)\n",
    "            prec5t, rec5t, rprect = _prec_rec(5, remove_training=True)\n",
    "            session.report({\n",
    "                'loss': acc_loss/n_samples,\n",
    "                'val_loss': val_loss,\n",
    "                'rprec train': rprec, 'rprec test': rprect,\n",
    "                'p@5 train': prec5, 'p@5 test': prec5t,\n",
    "                'r@5 train': rec5, 'r@5 test': rec5t,\n",
    "            }, checkpoint=checkpoint)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Testing just syntax errors\n",
    "model = train_daostack(graph_folds[0][0].to(device), graph_folds[0][1].to(device), data.to(device), ModelConfig(**(modelConfig._asdict() | {'max_epochs':2})))\n",
    "print(PyG.nn.summary(model, data['voter', 'votes', 'proposal'].edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:06:29.772484Z",
     "iopub.status.busy": "2023-08-17T14:06:29.772317Z",
     "iopub.status.idle": "2023-08-17T14:15:29.560164Z",
     "shell.execute_reply": "2023-08-17T14:15:29.559471Z",
     "shell.execute_reply.started": "2023-08-17T14:06:29.772472Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-17 16:15:29</td></tr>\n",
       "<tr><td>Running for: </td><td>00:08:56.98        </td></tr>\n",
       "<tr><td>Memory:      </td><td>4.7/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 2.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  __trial_index__</th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_layers</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">         l2</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  rprec train</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_aux_train_daostack_8c470f7f</td><td>TERMINATED</td><td>192.168.1.118:5595</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             90</td><td style=\"text-align: right;\">2.04929e-08</td><td style=\"text-align: right;\">        0.00014</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         311.618</td><td style=\"text-align: right;\">0.365323</td><td style=\"text-align: right;\">  0.516067</td><td style=\"text-align: right;\">     0.33327 </td></tr>\n",
       "<tr><td>_aux_train_daostack_dbaed356</td><td>TERMINATED</td><td>192.168.1.118:5629</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             90</td><td style=\"text-align: right;\">2.04929e-08</td><td style=\"text-align: right;\">        0.00014</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         304.508</td><td style=\"text-align: right;\">0.366316</td><td style=\"text-align: right;\">  0.538717</td><td style=\"text-align: right;\">     0.328869</td></tr>\n",
       "<tr><td>_aux_train_daostack_9b123ff6</td><td>TERMINATED</td><td>192.168.1.118:5671</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             90</td><td style=\"text-align: right;\">2.04929e-08</td><td style=\"text-align: right;\">        0.00014</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         314.904</td><td style=\"text-align: right;\">0.368056</td><td style=\"text-align: right;\">  0.536192</td><td style=\"text-align: right;\">     0.335069</td></tr>\n",
       "<tr><td>_aux_train_daostack_d3e40232</td><td>TERMINATED</td><td>192.168.1.118:5629</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             90</td><td style=\"text-align: right;\">2.04929e-08</td><td style=\"text-align: right;\">        0.00014</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         213.795</td><td style=\"text-align: right;\">0.387266</td><td style=\"text-align: right;\">  0.52109 </td><td style=\"text-align: right;\">     0.317737</td></tr>\n",
       "<tr><td>_aux_train_daostack_3ea44134</td><td>TERMINATED</td><td>192.168.1.118:5595</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             90</td><td style=\"text-align: right;\">2.04929e-08</td><td style=\"text-align: right;\">        0.00014</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         223.104</td><td style=\"text-align: right;\">0.368935</td><td style=\"text-align: right;\">  0.523875</td><td style=\"text-align: right;\">     0.332073</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 16:15:29,537\tINFO tune.py:1148 -- Total run time: 537.01 seconds (536.98 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search import Repeater\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "def _aux_train_daostack(config):\n",
    "    # TODO: Is bad practice to pass a dataset trainable\n",
    "    # config['embedding_dim'] = 2**config['embedding_dim']\n",
    "    config['batch_size'] = 2**config['batch_size']\n",
    "    n_fold = config.pop('__trial_index__')\n",
    "    train, validation = graph_folds[n_fold]\n",
    "    train_daostack(train.to(device), validation.to(device), data.to(device), config, disable_tqdm=True)\n",
    "\n",
    "if os.uname().nodename == 'lamarck':\n",
    "    assert torch.cuda.is_available()\n",
    "    \n",
    "    NUM_SAMPLES = 500\n",
    "    # Every run takes approx half a gig of vram (no optimizations)\n",
    "    # The RTX 4090 has 24GB so we can run the model about 48 times\n",
    "    resources_per_trial={\n",
    "        'cpu': 1,\n",
    "        'gpu': 1/32,\n",
    "    }\n",
    "else:\n",
    "    NUM_SAMPLES = 1\n",
    "    resources_per_trial={\n",
    "        'cpu': 2,\n",
    "        'memory': 2e9,\n",
    "    }\n",
    "\n",
    "tryConfigs = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    conv_layers=tune.randint(2,6),\n",
    "    learning_rate=tune.qloguniform(1e-5, 1, 1e-5),\n",
    "    l2=tune.loguniform(1e-9, 1e-1),\n",
    "    # These will be 2 to the power\n",
    "    batch_size=tune.randint(4,10), # 16..1024\n",
    "    # embedding_dim=tune.randint(4,8), # 16..128\n",
    "    embedding_dim=tune.qlograndint(10, 500, 5),\n",
    ")\n",
    "\n",
    "# It is recommended to not use Repeater with a TrialScheduler. Early termination can negatively affect the average reported metric.\n",
    "asha_scheduler = None\n",
    "# asha_scheduler = ASHAScheduler(\n",
    "#     time_attr='training_iteration',\n",
    "#     max_t=50,\n",
    "#     grace_period=5,\n",
    "#     reduction_factor=3,\n",
    "#     brackets=1,\n",
    "# )\n",
    "\n",
    "search_alg = HyperOptSearch()\n",
    "search_alg = Repeater(search_alg,datasetConfig.num_folds)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(_aux_train_daostack, resources_per_trial),\n",
    "    param_space=tryConfigs._asdict(),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        # time_budget_s=60,\n",
    "        num_samples=datasetConfig.num_folds*NUM_SAMPLES,\n",
    "        scheduler=asha_scheduler,\n",
    "        search_alg=search_alg,\n",
    "        metric='rprec test',\n",
    "        mode='max',\n",
    "    )\n",
    ")\n",
    "exp = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:15:29.560885Z",
     "iopub.status.busy": "2023-08-17T14:15:29.560724Z",
     "iopub.status.idle": "2023-08-17T14:15:29.573552Z",
     "shell.execute_reply": "2023-08-17T14:15:29.573268Z",
     "shell.execute_reply.started": "2023-08-17T14:15:29.560874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>rprec train</th>\n",
       "      <th>rprec test</th>\n",
       "      <th>p@5 train</th>\n",
       "      <th>p@5 test</th>\n",
       "      <th>r@5 train</th>\n",
       "      <th>r@5 test</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>config/__trial_index__</th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/conv_layers</th>\n",
       "      <th>config/embedding_dim</th>\n",
       "      <th>config/l2</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>config/max_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.368056</td>\n",
       "      <td>0.536192</td>\n",
       "      <td>0.335069</td>\n",
       "      <td>0.152248</td>\n",
       "      <td>0.446154</td>\n",
       "      <td>0.209615</td>\n",
       "      <td>0.067841</td>\n",
       "      <td>0.107489</td>\n",
       "      <td>6.059479</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>314.904263</td>\n",
       "      <td>314.904263</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>2.049287e-08</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.365323</td>\n",
       "      <td>0.516067</td>\n",
       "      <td>0.333270</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.075116</td>\n",
       "      <td>0.116598</td>\n",
       "      <td>6.405798</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>311.617673</td>\n",
       "      <td>311.617673</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>2.049287e-08</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.368935</td>\n",
       "      <td>0.523875</td>\n",
       "      <td>0.332073</td>\n",
       "      <td>0.151285</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.068911</td>\n",
       "      <td>0.096710</td>\n",
       "      <td>2.739580</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>223.103781</td>\n",
       "      <td>223.103781</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>2.049287e-08</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.387266</td>\n",
       "      <td>0.521090</td>\n",
       "      <td>0.317737</td>\n",
       "      <td>0.136312</td>\n",
       "      <td>0.421154</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>0.102233</td>\n",
       "      <td>3.981609</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>213.795120</td>\n",
       "      <td>213.795120</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>2.049287e-08</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.366316</td>\n",
       "      <td>0.538717</td>\n",
       "      <td>0.328869</td>\n",
       "      <td>0.141526</td>\n",
       "      <td>0.455769</td>\n",
       "      <td>0.180769</td>\n",
       "      <td>0.073946</td>\n",
       "      <td>0.090271</td>\n",
       "      <td>5.960494</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>304.507637</td>\n",
       "      <td>304.507637</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>2.049287e-08</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss  rprec train  rprec test  p@5 train  p@5 test  \\\n",
       "2  0.368056  0.536192     0.335069    0.152248   0.446154  0.209615   \n",
       "0  0.365323  0.516067     0.333270    0.153387   0.430769  0.201923   \n",
       "4  0.368935  0.523875     0.332073    0.151285   0.442308  0.192308   \n",
       "3  0.387266  0.521090     0.317737    0.136312   0.421154  0.184615   \n",
       "1  0.366316  0.538717     0.328869    0.141526   0.455769  0.180769   \n",
       "\n",
       "   r@5 train  r@5 test  time_this_iter_s   done  ...  time_total_s  \\\n",
       "2   0.067841  0.107489          6.059479  False  ...    314.904263   \n",
       "0   0.075116  0.116598          6.405798  False  ...    311.617673   \n",
       "4   0.068911  0.096710          2.739580  False  ...    223.103781   \n",
       "3   0.070307  0.102233          3.981609  False  ...    213.795120   \n",
       "1   0.073946  0.090271          5.960494  False  ...    304.507637   \n",
       "\n",
       "  time_since_restore iterations_since_restore  config/__trial_index__  \\\n",
       "2         314.904263                       50                       2   \n",
       "0         311.617673                       50                       0   \n",
       "4         223.103781                       50                       4   \n",
       "3         213.795120                       50                       3   \n",
       "1         304.507637                       50                       1   \n",
       "\n",
       "   config/batch_size  config/conv_layers  config/embedding_dim     config/l2  \\\n",
       "2                  6                   5                    90  2.049287e-08   \n",
       "0                  6                   5                    90  2.049287e-08   \n",
       "4                  6                   5                    90  2.049287e-08   \n",
       "3                  6                   5                    90  2.049287e-08   \n",
       "1                  6                   5                    90  2.049287e-08   \n",
       "\n",
       "   config/learning_rate  config/max_epochs  \n",
       "2               0.00014                 50  \n",
       "0               0.00014                 50  \n",
       "4               0.00014                 50  \n",
       "3               0.00014                 50  \n",
       "1               0.00014                 50  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = exp.get_dataframe().drop(columns=['hostname', 'node_ip', 'logdir', 'should_checkpoint', 'pid'])\n",
    "exp_df.sort_values('p@5 test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all of this\n",
    "\n",
    "Crearé una función que reciba una dirección de un usuario y retorne k propuestas que puedan interesarle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T14:15:29.574133Z",
     "iopub.status.busy": "2023-08-17T14:15:29.573981Z",
     "iopub.status.idle": "2023-08-17T14:15:29.821114Z",
     "shell.execute_reply": "2023-08-17T14:15:29.820642Z",
     "shell.execute_reply.started": "2023-08-17T14:15:29.574123Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_user' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proposals\n\u001b[1;32m     32\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0x334f12afb7d8740868be04719639616533075234\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# vpu[(12 < vpu) & (vpu < 38)].sample().index[0]\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreatedAt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserVoted\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m, in \u001b[0;36mrecommend\u001b[0;34m(user, K, ignore_train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend\u001b[39m(user: \u001b[38;5;28mstr\u001b[39m, K: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, ignore_train: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     uid \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_user\u001b[49m\u001b[38;5;241m.\u001b[39mtransform([user])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommending \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m proposals for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (uid:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvpu\u001b[38;5;241m.\u001b[39mat[user]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m votes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Getting embedding\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_user' is not defined"
     ]
    }
   ],
   "source": [
    "def recommend(user: str, K: int = 12, ignore_train: bool=False):\n",
    "    uid = encoder_user.transform([user])[0]\n",
    "    print(f\"Recommending {K} proposals for user {user} (uid:{uid}) with {vpu.at[user]} votes\")\n",
    "    \n",
    "    # Getting embedding\n",
    "    out = model(edge_index)\n",
    "    user_embed, item_embed = torch.split(out, (model.n_users, model.n_items))\n",
    "    relevance_score = torch.matmul(user_embed, torch.transpose(item_embed, 0, 1))\n",
    "    if ignore_train:\n",
    "        i = torch.stack([\n",
    "            torch.LongTensor(train_df['uid'].values),\n",
    "            torch.LongTensor(train_df['pid'].values),\n",
    "        ])\n",
    "        v = torch.ones(len(train_df), dtype=torch.float64)\n",
    "        t_interactions = torch.sparse.FloatTensor(i, v, (model.n_users, model.n_items)).to_dense().to(device)\n",
    "        # mask out training user-item interactions from metric computation\n",
    "        # We are only interested in novel items, as a user won't be interested\n",
    "        # in \"voting again\"\n",
    "        relevance_score = torch.mul(relevance_score, (1 - t_interactions))\n",
    "    \n",
    "    topk_relevance_indices = torch.topk(relevance_score, K).indices\n",
    "    \n",
    "    pids = topk_relevance_indices[uid].tolist()\n",
    "    proposals = dfp.loc[encoder_prop.inverse_transform(pids)]\n",
    "    \n",
    "    proposals['userVoted'] = dfv.groupby('proposal')['voter'].apply(lambda x: user in set(x))\n",
    "    \n",
    "    print(f\"precision@{K}={sum(proposals['userVoted'])/len(proposals)*100:.2f}%\")\n",
    "    \n",
    "    return proposals\n",
    "\n",
    "user = \"0x334f12afb7d8740868be04719639616533075234\" # vpu[(12 < vpu) & (vpu < 38)].sample().index[0]\n",
    "recommend(user, ignore_train=True)[['network', 'createdAt', 'title', 'description', 'userVoted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-17T14:15:29.821468Z",
     "iopub.status.idle": "2023-08-17T14:15:29.821624Z",
     "shell.execute_reply": "2023-08-17T14:15:29.821556Z",
     "shell.execute_reply.started": "2023-08-17T14:15:29.821548Z"
    }
   },
   "outputs": [],
   "source": [
    "dfv[dfv['proposal'] == '0xb92d2df99a47244c07a9d7ef73530c273f1d65230dbff9e95873d82c0314534e']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05b82e650fd04c8db60f0d16385870d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_de3e1c769d4b457fbefb0e08e62fab66",
       "max": 104,
       "style": "IPY_MODEL_451c94997d8445279e68734a642b1173",
       "value": 104
      }
     },
     "08e7e0f341634e8c98058184fafe64d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "096217db7b2547279ef1cf7e309ff291": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0d9f9f2ca3fd404393b7e141cbfde82a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e596644604374d8b919130758891662d",
       "style": "IPY_MODEL_c219b9b5df3144faafd6b3a40f0fcc90",
       "value": " 0/104 [00:00&lt;?, ?it/s]"
      }
     },
     "128ef7a5d3d74691ba953403b6a7dab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1afe05b6067c427d81cf0e7785bd5427": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2321236a61ab42999e96f607af33b5a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3121a095e35d42baa2e37c534894db9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1afe05b6067c427d81cf0e7785bd5427",
       "style": "IPY_MODEL_50a0d9640726444b8febd2a672b08533",
       "value": "  0%"
      }
     },
     "451c94997d8445279e68734a642b1173": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4dc9ed1052b7481ab038a0f7ff329f65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_faa35114f62c41218d834ccb8c0bf17c",
       "max": 104,
       "style": "IPY_MODEL_f9df54548f3848cfa189c1eabf4a1201",
       "value": 104
      }
     },
     "50a0d9640726444b8febd2a672b08533": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "52b1af4ca06243939875b280decf0ea0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_77738ee9e0e746188c849163a9520be8",
        "IPY_MODEL_79a3ca333af84b269cb0a1816fa4cfc2",
        "IPY_MODEL_9945701c612648c4a5870c86ef0637f6"
       ],
       "layout": "IPY_MODEL_ac8ab575c1c34277815fb4fd064d325a"
      }
     },
     "62afaf10bf114f2ba8757ada6b28a91e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "77738ee9e0e746188c849163a9520be8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_d4f379a4a26d43e39bb1a6b9602db611",
       "style": "IPY_MODEL_79a77966855a45bba4dd11d1891478cd",
       "value": "100%"
      }
     },
     "79a3ca333af84b269cb0a1816fa4cfc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_08e7e0f341634e8c98058184fafe64d9",
       "max": 2,
       "style": "IPY_MODEL_c02b2e18d7184446b14ae06eaa9ed3e7",
       "value": 2
      }
     },
     "79a77966855a45bba4dd11d1891478cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7a6e74546e494d889ec7b336709e3064": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_096217db7b2547279ef1cf7e309ff291",
       "style": "IPY_MODEL_db36e65ffa1145b1b568f64eba90f8e0",
       "value": " 0/104 [00:00&lt;?, ?it/s]"
      }
     },
     "85b437eb9d3b4ae7b98fbb83c2b34233": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2321236a61ab42999e96f607af33b5a5",
       "style": "IPY_MODEL_128ef7a5d3d74691ba953403b6a7dab9",
       "value": "  0%"
      }
     },
     "9911c518b0c848fb87f1e8f50a2ea10d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "visibility": "hidden"
      }
     },
     "9945701c612648c4a5870c86ef0637f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e4665d2fd67f45c9bd3731f304eeff7b",
       "style": "IPY_MODEL_62afaf10bf114f2ba8757ada6b28a91e",
       "value": " 2/2 [00:01&lt;00:00,  1.89it/s]"
      }
     },
     "ac8ab575c1c34277815fb4fd064d325a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bdbcc539966b4dfa9b79ab9f00a3638e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "visibility": "hidden"
      }
     },
     "c02b2e18d7184446b14ae06eaa9ed3e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c219b9b5df3144faafd6b3a40f0fcc90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d4f379a4a26d43e39bb1a6b9602db611": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "db36e65ffa1145b1b568f64eba90f8e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "de3e1c769d4b457fbefb0e08e62fab66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4665d2fd67f45c9bd3731f304eeff7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e596644604374d8b919130758891662d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f9df54548f3848cfa189c1eabf4a1201": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "faa35114f62c41218d834ccb8c0bf17c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
