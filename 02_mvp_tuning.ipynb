{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Pytorch Geometric official example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33550/1209356143.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm.notebook import tqdm # Progress bars\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "# https://import-as.github.io\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as PyG\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import src\n",
    "from src.data import get_df, filter_df\n",
    "\n",
    "POSSIBLE_PATHS = [\"./datawarehouse\", \"/kaggle/input/dao-analyzer\"]\n",
    "\n",
    "DW = None\n",
    "for p in POSSIBLE_PATHS:\n",
    "    DW = Path(p)\n",
    "    if DW.is_dir():\n",
    "        break\n",
    "else:\n",
    "    print(\"No se ha encontrado el DW\")\n",
    "\n",
    "src.data.DEFAULT_PATH = DW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters table in [Google Drive](https://docs.google.com/spreadsheets/d/1riafpWt1563w9pbqdt1g2QZVkc7TfRWGzFaCG5rudDI/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Remove users with less than 6 votes from the dataset before splitting\n",
    "DatasetConfig = namedtuple('DatasetConfig', ('min_votes_per_user', 'allowed_dao_names', 'train_split'))\n",
    "datasetConfig = DatasetConfig(\n",
    "    min_votes_per_user=6,\n",
    "    allowed_dao_names={'dxDAO', 'xDXdao'},\n",
    "    train_split=1/5,\n",
    ")\n",
    "\n",
    "ModelConfig = namedtuple('ModelConfig', 'max_epochs batch_size learning_rate embedding_dim conv_layers')\n",
    "modelConfig = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    batch_size=16,\n",
    "    learning_rate=0.0001,\n",
    "    embedding_dim=32,\n",
    "    conv_layers=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:          16606\n",
      "Density:       0.3087%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  voter={ num_nodes=104 },\n",
       "  proposal={ num_nodes=2216 },\n",
       "  (voter, votes, proposal)={ edge_index=[2, 8303] },\n",
       "  (proposal, voted, voter)={ edge_index=[2, 8303] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, HeteroData, Data\n",
    "\n",
    "class Daostack(InMemoryDataset):\n",
    "    \"\"\" Creates a heterogeneus graph with two kinds of nodes: voters and proposals \"\"\"\n",
    "    def __init__(self, root: str, min_vpu=6, allowed_daos=None):\n",
    "        self._min_vpu = min_vpu\n",
    "        self._allowed_daos = allowed_daos\n",
    "        \n",
    "        super().__init__(root)\n",
    "\n",
    "        self.data = torch.load(self.processed_paths[0])\n",
    "\n",
    "    def process(self):\n",
    "        import pandas as pd\n",
    "\n",
    "        df = pd.read_csv(self.raw_paths[0])\n",
    "\n",
    "        if self._allowed_daos:\n",
    "            dfd = pd.read_csv(self.raw_paths[1]).set_index('id')\n",
    "            allowed_dao_ids = set(dfd[dfd['name'].isin(self._allowed_daos)].index)\n",
    "            df = df[df['dao'].isin(allowed_dao_ids)]\n",
    "            assert not df.empty, \"Dataframe is empty\"\n",
    "            \n",
    "        if self._min_vpu:\n",
    "            vpu = df.groupby('voter').size()\n",
    "            allowed_voters = vpu[vpu >= self._min_vpu].index\n",
    "            df = df[df['voter'].isin(allowed_voters)]\n",
    "        \n",
    "        data = HeteroData()\n",
    "        node_types = ['voter', 'proposal']\n",
    "        for nt in node_types:\n",
    "            df[nt] = df[nt].astype('category')\n",
    "            data[nt].num_nodes = df[nt].nunique()\n",
    "\n",
    "        u_t = torch.LongTensor(df['voter'].cat.codes)\n",
    "        p_t = torch.LongTensor(df['proposal'].cat.codes)\n",
    "\n",
    "        edge_index = torch.stack([\n",
    "            torch.cat([u_t, p_t]),\n",
    "            torch.cat([p_t, u_t]),\n",
    "        ])\n",
    "\n",
    "        data['voter', 'votes', 'proposal']['edge_index'] = torch.stack([u_t, p_t])\n",
    "        data['proposal', 'voted', 'voter']['edge_index'] = torch.stack([p_t, u_t])\n",
    "\n",
    "        data.validate()\n",
    "        assert not data.is_directed(), \"The created graph shouldn't be directed\"\n",
    "\n",
    "        torch.save(data, self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        return self.root / 'daostack'\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        return self.raw_dir / 'processed'\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return ['votes.csv', 'daos.csv']\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return f\"daostack_votes_{self._min_vpu}_{'-'.join(self._allowed_daos)}.pt\"\n",
    "\n",
    "def print_graph_stats(g: HeteroData):\n",
    "    density = (g.num_edges) / (g.num_nodes*(g.num_nodes-1))\n",
    "    print(f'Edges:   {g.num_edges:12}')\n",
    "    print(f'Density: {density*100:12.4f}%')\n",
    "\n",
    "data = Daostack(DW, min_vpu=datasetConfig.min_votes_per_user, allowed_daos=datasetConfig.allowed_dao_names)[0]\n",
    "print_graph_stats(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I thought the RandomLinkSplit function was not working properly, but it turns out that I wasn't understanding it very well. The tutorial I used for [01_mvp](./01_mvp.ipynb) is not very good either, it was written by students, and implemented before PyTorch Geometric bundled the LightGCN model with it.\n",
    "\n",
    "> I think this is totally correct. It seems like you are looking at the shapes of edge_index, while you may want to look at the shapes of edge_label and edge_label_index (which correctly model a 80/10/10 split ratio). Here, edge_index is solely used for message passing, i.e.,\n",
    "> \n",
    "> * for training, we exchange messages on all training edges\n",
    "> * for validation, we exchange messages on all training edges\n",
    "> * for testing, we exchange messages on all training and validation edges\n",
    "> Let me know if this resolves your concerns :)\n",
    ">\n",
    "> -- [Split Error in RandomLinkSplit · Issue #3668 · pyg-team/pytorch_geometric · GitHub](https://github.com/pyg-team/pytorch_geometric/issues/3668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(HeteroData(\n",
       "   voter={ num_nodes=104 },\n",
       "   proposal={ num_nodes=2216 },\n",
       "   (voter, votes, proposal)={\n",
       "     edge_index=[2, 7266],\n",
       "     edge_label=[14532],\n",
       "     edge_label_index=[2, 14532],\n",
       "   },\n",
       "   (proposal, voted, voter)={ edge_index=[2, 7266] }\n",
       " ),\n",
       " HeteroData(\n",
       "   voter={ num_nodes=104 },\n",
       "   proposal={ num_nodes=2216 },\n",
       "   (voter, votes, proposal)={\n",
       "     edge_index=[2, 7266],\n",
       "     edge_label=[2074],\n",
       "     edge_label_index=[2, 2074],\n",
       "   },\n",
       "   (proposal, voted, voter)={ edge_index=[2, 7266] }\n",
       " ),\n",
       " HeteroData(\n",
       "   voter={ num_nodes=104 },\n",
       "   proposal={ num_nodes=2216 },\n",
       "   (voter, votes, proposal)={\n",
       "     edge_index=[2, 8303],\n",
       "     edge_label=[0],\n",
       "     edge_label_index=[2, 0],\n",
       "   },\n",
       "   (proposal, voted, voter)={ edge_index=[2, 8303] }\n",
       " ))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_val_test(g: Data | HeteroData, train_ratio=0.75):\n",
    "    t = ft.partial(PyG.transforms.RandomLinkSplit, \n",
    "        is_undirected=True,\n",
    "        num_val=1-train_ratio,\n",
    "        # split_labels=True,\n",
    "        add_negative_train_samples=True,\n",
    "        num_test=0,\n",
    "    )\n",
    "    \n",
    "    if isinstance(g, HeteroData):\n",
    "        t = t(\n",
    "            edge_types=[g.edge_types[0]],\n",
    "            rev_edge_types=[g.edge_types[1]] if len(g.edge_types) > 1 else None,\n",
    "        )\n",
    "    elif isinstance(g, Data):\n",
    "        t = t()\n",
    "            \n",
    "    return t(g)\n",
    "\n",
    "tr, val, ts = get_train_val_test(data, train_ratio=7/8)\n",
    "tr, val, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 14532], edge_label=[21798], edge_label_index=[2, 14532], node_type=[2320], edge_type=[14532])\n",
      "[ 0.  1. nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying to make sense of all of this\n",
    "\n",
    "th = tr.to_homogeneous()\n",
    "print(th)\n",
    "print(np.unique(th.edge_label))\n",
    "pos = th.edge_label_index[:, th.edge_label[:14532] == 1]\n",
    "assert (pos == th.edge_index[:, th.edge_type==0]).all()\n",
    "pos.size(), th.edge_index.size()\n",
    "th.node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  98,   52,   43,  ...,   75,   85,    3],\n",
       "        [ 493,  168, 1738,  ..., 1276, 1412,  184]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ensure_homogeneous(*args):\n",
    "    def _apply(g):\n",
    "        if isinstance(g, HeteroData):\n",
    "            hg = g.to_homogeneous()\n",
    "            # Removing final na\n",
    "            if hasattr(hg, 'edge_label'):\n",
    "                assert hg.edge_label[hg.edge_label_index.size(1):].isnan().all()\n",
    "                hg.edge_label = hg.edge_label[:hg.edge_label_index.size(1)].bool()\n",
    "            return hg\n",
    "        else:\n",
    "            return g\n",
    "\n",
    "    ret = tuple(_apply(g) for g in args)\n",
    "    if len(ret) == 1:\n",
    "        return ret[0]\n",
    "    else:\n",
    "        return ret\n",
    "\n",
    "_aux = ensure_homogeneous(val)\n",
    "_aux.edge_label_index[:, _aux.edge_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 11:17:51,758\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/daviddavo/.local/lib/python3.10/site-packages/ray/air/session.py:28: UserWarning: `get_checkpoint` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef8abb2d56a495b89c32d6ce01542e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 11:17:52,667\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/daviddavo/.local/lib/python3.10/site-packages/ray/air/session.py:28: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n",
      "2023-08-02 11:17:53,096\tWARNING session.py:100 -- In neither tune session nor train session!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(LightGCN(2320, 32, num_layers=3),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import LightGCN\n",
    "\n",
    "# Based on:\n",
    "# - https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# - https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
    "# - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "def train_daostack(train: HeteroData, validation: HeteroData, test: HeteroData, modelConfig: ModelConfig, disable_tqdm=False):\n",
    "    if not isinstance(modelConfig, ModelConfig):\n",
    "        modelConfig = ModelConfig(**modelConfig)\n",
    "    \n",
    "    model = LightGCN(\n",
    "        num_nodes=data.num_nodes,\n",
    "        embedding_dim=modelConfig.embedding_dim,\n",
    "        num_layers=modelConfig.conv_layers,\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=modelConfig.learning_rate)\n",
    "\n",
    "    checkpoint = session.get_checkpoint()\n",
    "\n",
    "    if checkpoint:\n",
    "        checkpoint_state = checkpoint.to_dict()\n",
    "        start_epoch = checkpoint_state[\"epoch\"]\n",
    "        model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    # Use all message passing edges as training labels\n",
    "    # TODO: The train/test data should also be saved in a checkpoint?\n",
    "    # TODO: Transform the graph to homogeneous\n",
    "    assert train.is_undirected()\n",
    "    assert validation.is_undirected()\n",
    "\n",
    "    train, validation, test = ensure_homogeneous(train, validation, test)\n",
    "\n",
    "    users = torch.nonzero(train.node_type == 0).squeeze()\n",
    "    items = torch.nonzero(train.node_type == 1).squeeze()\n",
    "    n_users = len(users)\n",
    "    n_items = len(items)\n",
    "\n",
    "    # In message passing, bidirectional edges may cause duplicate information to\n",
    "    # be passed between nodes.\n",
    "    # The official LightGCN usage also uses this line of code (well, for homo graphs)\n",
    "    # - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "    \n",
    "    # train_edge_label_index = train.edge_index[:, train.edge_type == 0]\n",
    "    # train.edge_label = train.edge_label[:train.edge_label_index.size(1)] # Now this is done inside ensure_homogeneous\n",
    "    pos_edge_label_index = train.edge_label_index[:, train.edge_label == 1]\n",
    "    neg_edge_label_index = train.edge_label_index[:, train.edge_label == 0]\n",
    "\n",
    "    # TODO: Use LinkLoader instead (i don't know how)\n",
    "    # Waiting for pyg-team/pytorch_geometric#7817\n",
    "    # train_loader = PyG.loader.LinkLoader(\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        range(pos_edge_label_index.size(1)), # dataset\n",
    "        batch_size=modelConfig.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _prec_rec(k: int, remove_training=False):\n",
    "        # [104, 5]\n",
    "        gt_index = test.edge_index[:, test.edge_type == 0]\n",
    "        if remove_training:\n",
    "            edge_index = validation.edge_label_index[:, validation.edge_label]\n",
    "        else:\n",
    "            # All edges\n",
    "            edge_index = test.edge_index\n",
    "\n",
    "        topk = model.recommend(edge_index, src_index=users, dst_index=items, k=k)\n",
    "        n_samples = len(users)\n",
    "\n",
    "        # [104, 2216]\n",
    "        ground_truth = torch.full((n_users, n_items), False, dtype=torch.bool, device=device)\n",
    "        # print('ground_truth.size()', ground_truth.size())\n",
    "        ground_truth[gt_index[0], gt_index[1] - n_users] = True\n",
    "\n",
    "        # print('topk.size()', topk.size())\n",
    "        # print('topk.min(), max():', topk.min(), topk.max())\n",
    "        isin_mat = ground_truth.gather(1, topk - n_users)\n",
    "        item_count = PyG.utils.degree(pos_edge_label_index[0], num_nodes=n_users)\n",
    "\n",
    "        prec = (isin_mat.sum(dim=-1) / k).sum() / n_samples\n",
    "        rec = (isin_mat.sum(dim=-1) / item_count).sum() / n_samples\n",
    "\n",
    "        # print('prec, rec:', (prec, rec))\n",
    "        \n",
    "        return float(prec), float(rec)\n",
    "\n",
    "    for epoch in trange(start_epoch, modelConfig.max_epochs, disable=disable_tqdm):\n",
    "        # index is an array of batch_size that indicates which edges from \n",
    "        # train.edge_index we should use\n",
    "        acc_loss = n_samples = 0\n",
    "        for index in tqdm(train_loader, leave=False, delay=1, disable=disable_tqdm):\n",
    "            pos_edge_index = pos_edge_label_index[:, index]\n",
    "            # neg_edge_index = torch.stack([\n",
    "            #     pos_edge_index[0],\n",
    "            #     # TODO: Use generated negative samples instead\n",
    "            #     torch.randint(n_users, n_users+n_items, index.size(),device=device),\n",
    "            # ])\n",
    "            neg_edge_index = neg_edge_label_index[:, index]\n",
    "            edge_label_index = torch.cat([\n",
    "                pos_edge_index,\n",
    "                neg_edge_index,\n",
    "            ], dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pos_rank, neg_rank = model(train.edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "            # Learning\n",
    "            loss = model.recommendation_loss(\n",
    "                pos_rank,\n",
    "                neg_rank,\n",
    "                node_id=edge_label_index.unique(),\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_loss += float(loss) * pos_rank.numel()\n",
    "            n_samples += pos_rank.numel()\n",
    "\n",
    "        checkpoint = Checkpoint.from_dict({\n",
    "            'epoch': epoch,\n",
    "            'net_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        })\n",
    "\n",
    "        # Todo: Add val accuracy (pr@5, rec@5, etc.)\n",
    "        prec5, rec5 = _prec_rec(5, remove_training=False)\n",
    "        prec5t, rec5t = _prec_rec(5, remove_training=True)\n",
    "        session.report({\n",
    "            'loss': acc_loss/n_samples,\n",
    "            'p@5 train': prec5, 'p@5 test': prec5t,\n",
    "            'r@5 train': rec5, 'r@5 test': rec5t,\n",
    "        }, checkpoint=checkpoint)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Testing just syntax errors\n",
    "train_daostack(tr.to(device), val.to(device), ts.to(device), ModelConfig(**(modelConfig._asdict() | {'max_epochs':2}))),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-02 16:03:36</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:00.22        </td></tr>\n",
       "<tr><td>Memory:      </td><td>22.8/125.6 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=52<br>Bracket: Iter 45.000: -0.0040018830513929415 | Iter 15.000: -0.004939214667644245 | Iter 5.000: -0.03657081156318962<br>Logical resource usage: 15.0/24 CPUs, 0.46875/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_layers</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">       loss</th><th style=\"text-align: right;\">  p@5 train</th><th style=\"text-align: right;\">  p@5 test</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_aux_train_daostack_e2da9a8a</td><td>TERMINATED</td><td>147.96.81.131:98641 </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.02169</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">       38.4003  </td><td style=\"text-align: right;\"> 0.00504007</td><td style=\"text-align: right;\">   0.630769</td><td style=\"text-align: right;\"> 0.419231 </td></tr>\n",
       "<tr><td>_aux_train_daostack_ba965b5f</td><td>TERMINATED</td><td>147.96.81.131:98685 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.00331</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.548037</td><td style=\"text-align: right;\"> 0.225845  </td><td style=\"text-align: right;\">   0.440385</td><td style=\"text-align: right;\"> 0.296154 </td></tr>\n",
       "<tr><td>_aux_train_daostack_56b7b250</td><td>TERMINATED</td><td>147.96.81.131:98685 </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              7</td><td style=\"text-align: right;\">        1e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        4.56163 </td><td style=\"text-align: right;\"> 0.686882  </td><td style=\"text-align: right;\">   0.636538</td><td style=\"text-align: right;\"> 0.132692 </td></tr>\n",
       "<tr><td>_aux_train_daostack_d061f2b9</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00069</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.827316</td><td style=\"text-align: right;\"> 0.594725  </td><td style=\"text-align: right;\">   0.428846</td><td style=\"text-align: right;\"> 0.253846 </td></tr>\n",
       "<tr><td>_aux_train_daostack_fcd2cce2</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              7</td><td style=\"text-align: right;\">        0.15457</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        4.85991 </td><td style=\"text-align: right;\"> 1.9251    </td><td style=\"text-align: right;\">   0.880769</td><td style=\"text-align: right;\"> 0.851923 </td></tr>\n",
       "<tr><td>_aux_train_daostack_15d7e4be</td><td>TERMINATED</td><td>147.96.81.131:98685 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        3e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.650614</td><td style=\"text-align: right;\"> 0.691751  </td><td style=\"text-align: right;\">   0.715385</td><td style=\"text-align: right;\"> 0.0788462</td></tr>\n",
       "<tr><td>_aux_train_daostack_adebcc16</td><td>TERMINATED</td><td>147.96.81.131:98685 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.07761</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">       22.2906  </td><td style=\"text-align: right;\"> 0.0404303 </td><td style=\"text-align: right;\">   0.761539</td><td style=\"text-align: right;\"> 0.653846 </td></tr>\n",
       "<tr><td>_aux_train_daostack_b47f2338</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.59141</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        1.34602 </td><td style=\"text-align: right;\"> 0.648045  </td><td style=\"text-align: right;\">   0.757692</td><td style=\"text-align: right;\"> 0.634615 </td></tr>\n",
       "<tr><td>_aux_train_daostack_a6a61551</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        3e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.759533</td><td style=\"text-align: right;\"> 0.692317  </td><td style=\"text-align: right;\">   0.519231</td><td style=\"text-align: right;\"> 0.0576923</td></tr>\n",
       "<tr><td>_aux_train_daostack_99c7e7fa</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.17505</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        2.5339  </td><td style=\"text-align: right;\"> 0.266458  </td><td style=\"text-align: right;\">   0.853846</td><td style=\"text-align: right;\"> 0.794231 </td></tr>\n",
       "<tr><td>_aux_train_daostack_f0c0a5da</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.00305</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        2.79645 </td><td style=\"text-align: right;\"> 0.0463983 </td><td style=\"text-align: right;\">   0.467308</td><td style=\"text-align: right;\"> 0.401923 </td></tr>\n",
       "<tr><td>_aux_train_daostack_3325c909</td><td>TERMINATED</td><td>147.96.81.131:99077 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        2e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.974756</td><td style=\"text-align: right;\"> 0.692888  </td><td style=\"text-align: right;\">   0.365385</td><td style=\"text-align: right;\"> 0.05     </td></tr>\n",
       "<tr><td>_aux_train_daostack_959fb24b</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00069</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">       15.5461  </td><td style=\"text-align: right;\"> 0.114896  </td><td style=\"text-align: right;\">   0.45    </td><td style=\"text-align: right;\"> 0.380769 </td></tr>\n",
       "<tr><td>_aux_train_daostack_4a6fae3f</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        2e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        2.32793 </td><td style=\"text-align: right;\"> 0.691944  </td><td style=\"text-align: right;\">   0.507692</td><td style=\"text-align: right;\"> 0.0673077</td></tr>\n",
       "<tr><td>_aux_train_daostack_b04b1c30</td><td>TERMINATED</td><td>147.96.81.131:99077 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.00011</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.33483 </td><td style=\"text-align: right;\"> 0.690617  </td><td style=\"text-align: right;\">   0.692308</td><td style=\"text-align: right;\"> 0.115385 </td></tr>\n",
       "<tr><td>_aux_train_daostack_e4122577</td><td>TERMINATED</td><td>147.96.81.131:99077 </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              7</td><td style=\"text-align: right;\">        0.00714</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">       43.4501  </td><td style=\"text-align: right;\"> 0.00461846</td><td style=\"text-align: right;\">   0.532692</td><td style=\"text-align: right;\"> 0.390385 </td></tr>\n",
       "<tr><td>_aux_train_daostack_18343c9e</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00093</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.589949</td><td style=\"text-align: right;\"> 0.530859  </td><td style=\"text-align: right;\">   0.428846</td><td style=\"text-align: right;\"> 0.282692 </td></tr>\n",
       "<tr><td>_aux_train_daostack_adb7da9c</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.00022</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        4.40643 </td><td style=\"text-align: right;\"> 0.326351  </td><td style=\"text-align: right;\">   0.403846</td><td style=\"text-align: right;\"> 0.373077 </td></tr>\n",
       "<tr><td>_aux_train_daostack_1602c362</td><td>TERMINATED</td><td>147.96.81.131:99437 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.0099 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">       16.6892  </td><td style=\"text-align: right;\"> 0.00500779</td><td style=\"text-align: right;\">   0.530769</td><td style=\"text-align: right;\"> 0.361538 </td></tr>\n",
       "<tr><td>_aux_train_daostack_cbb6d73b</td><td>TERMINATED</td><td>147.96.81.131:99491 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.01726</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">       19.0561  </td><td style=\"text-align: right;\"> 0.00330249</td><td style=\"text-align: right;\">   0.538462</td><td style=\"text-align: right;\"> 0.403846 </td></tr>\n",
       "<tr><td>_aux_train_daostack_c79d36c9</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.00245</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        2.43872 </td><td style=\"text-align: right;\"> 0.0925182 </td><td style=\"text-align: right;\">   0.442308</td><td style=\"text-align: right;\"> 0.317308 </td></tr>\n",
       "<tr><td>_aux_train_daostack_6180b98f</td><td>TERMINATED</td><td>147.96.81.131:99542 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00275</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        1.57014 </td><td style=\"text-align: right;\"> 0.35371   </td><td style=\"text-align: right;\">   0.438462</td><td style=\"text-align: right;\"> 0.263462 </td></tr>\n",
       "<tr><td>_aux_train_daostack_1d38e678</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.05862</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">       10.1629  </td><td style=\"text-align: right;\"> 0.00396225</td><td style=\"text-align: right;\">   0.534615</td><td style=\"text-align: right;\"> 0.346154 </td></tr>\n",
       "<tr><td>_aux_train_daostack_22906bfa</td><td>TERMINATED</td><td>147.96.81.131:99542 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00018</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.995254</td><td style=\"text-align: right;\"> 0.683202  </td><td style=\"text-align: right;\">   0.438462</td><td style=\"text-align: right;\"> 0.151923 </td></tr>\n",
       "<tr><td>_aux_train_daostack_00d8152d</td><td>TERMINATED</td><td>147.96.81.131:99542 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.0024 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">       12.1079  </td><td style=\"text-align: right;\"> 0.0507661 </td><td style=\"text-align: right;\">   0.467308</td><td style=\"text-align: right;\"> 0.378846 </td></tr>\n",
       "<tr><td>_aux_train_daostack_a51783bd</td><td>TERMINATED</td><td>147.96.81.131:99747 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.00162</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        2.22196 </td><td style=\"text-align: right;\"> 0.241487  </td><td style=\"text-align: right;\">   0.438462</td><td style=\"text-align: right;\"> 0.344231 </td></tr>\n",
       "<tr><td>_aux_train_daostack_ca706685</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00036</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.979054</td><td style=\"text-align: right;\"> 0.648297  </td><td style=\"text-align: right;\">   0.442308</td><td style=\"text-align: right;\"> 0.173077 </td></tr>\n",
       "<tr><td>_aux_train_daostack_215aafda</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.00576</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">       12.4817  </td><td style=\"text-align: right;\"> 0.00713537</td><td style=\"text-align: right;\">   0.55    </td><td style=\"text-align: right;\"> 0.492308 </td></tr>\n",
       "<tr><td>_aux_train_daostack_2617d80f</td><td>TERMINATED</td><td>147.96.81.131:98685 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.02789</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">       11.3143  </td><td style=\"text-align: right;\"> 0.00357671</td><td style=\"text-align: right;\">   0.548077</td><td style=\"text-align: right;\"> 0.367308 </td></tr>\n",
       "<tr><td>_aux_train_daostack_9f16e2d6</td><td>TERMINATED</td><td>147.96.81.131:99747 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.87187</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        3.96608 </td><td style=\"text-align: right;\">10.5592    </td><td style=\"text-align: right;\">   0.821154</td><td style=\"text-align: right;\"> 0.821154 </td></tr>\n",
       "<tr><td>_aux_train_daostack_e30f2c94</td><td>TERMINATED</td><td>147.96.81.131:99955 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.07151</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">       14.4375  </td><td style=\"text-align: right;\"> 0.00723675</td><td style=\"text-align: right;\">   0.615385</td><td style=\"text-align: right;\"> 0.453846 </td></tr>\n",
       "<tr><td>_aux_train_daostack_5c5ed71e</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.36619</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">       16.912   </td><td style=\"text-align: right;\"> 1.40119   </td><td style=\"text-align: right;\">   0.757692</td><td style=\"text-align: right;\"> 0.686538 </td></tr>\n",
       "<tr><td>_aux_train_daostack_a8e353b8</td><td>TERMINATED</td><td>147.96.81.131:99747 </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.04087</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">       22.0194  </td><td style=\"text-align: right;\"> 0.00573184</td><td style=\"text-align: right;\">   0.576923</td><td style=\"text-align: right;\"> 0.428846 </td></tr>\n",
       "<tr><td>_aux_train_daostack_b8547a2e</td><td>TERMINATED</td><td>147.96.81.131:99437 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.0831 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">       13.7216  </td><td style=\"text-align: right;\"> 0.00530661</td><td style=\"text-align: right;\">   0.548077</td><td style=\"text-align: right;\"> 0.401923 </td></tr>\n",
       "<tr><td>_aux_train_daostack_8f127ad4</td><td>TERMINATED</td><td>147.96.81.131:100143</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              7</td><td style=\"text-align: right;\">        0.01246</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        3.71454 </td><td style=\"text-align: right;\"> 0.00703464</td><td style=\"text-align: right;\">   0.532692</td><td style=\"text-align: right;\"> 0.382692 </td></tr>\n",
       "<tr><td>_aux_train_daostack_02a85925</td><td>TERMINATED</td><td>147.96.81.131:99542 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.25649</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        2.19982 </td><td style=\"text-align: right;\"> 0.0676961 </td><td style=\"text-align: right;\">   0.713462</td><td style=\"text-align: right;\"> 0.636538 </td></tr>\n",
       "<tr><td>_aux_train_daostack_d6b3e203</td><td>TERMINATED</td><td>147.96.81.131:98641 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              7</td><td style=\"text-align: right;\">        0.00876</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        7.24454 </td><td style=\"text-align: right;\"> 0.00627199</td><td style=\"text-align: right;\">   0.548077</td><td style=\"text-align: right;\"> 0.461538 </td></tr>\n",
       "<tr><td>_aux_train_daostack_c9107c75</td><td>TERMINATED</td><td>147.96.81.131:99491 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.03375</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">       11.231   </td><td style=\"text-align: right;\"> 0.00400146</td><td style=\"text-align: right;\">   0.530769</td><td style=\"text-align: right;\"> 0.35     </td></tr>\n",
       "<tr><td>_aux_train_daostack_295b1493</td><td>TERMINATED</td><td>147.96.81.131:99542 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.01401</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">       17.5116  </td><td style=\"text-align: right;\"> 0.00349644</td><td style=\"text-align: right;\">   0.580769</td><td style=\"text-align: right;\"> 0.519231 </td></tr>\n",
       "<tr><td>_aux_train_daostack_3360af9a</td><td>TERMINATED</td><td>147.96.81.131:98685 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.01989</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">       16.9853  </td><td style=\"text-align: right;\"> 0.00342035</td><td style=\"text-align: right;\">   0.573077</td><td style=\"text-align: right;\"> 0.475    </td></tr>\n",
       "<tr><td>_aux_train_daostack_30a82122</td><td>TERMINATED</td><td>147.96.81.131:100143</td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.12602</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">       10.3721  </td><td style=\"text-align: right;\"> 0.0340364 </td><td style=\"text-align: right;\">   0.715385</td><td style=\"text-align: right;\"> 0.594231 </td></tr>\n",
       "<tr><td>_aux_train_daostack_6ad7486a</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.00524</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.704715</td><td style=\"text-align: right;\"> 0.160976  </td><td style=\"text-align: right;\">   0.475   </td><td style=\"text-align: right;\"> 0.405769 </td></tr>\n",
       "<tr><td>_aux_train_daostack_74e7d1c8</td><td>TERMINATED</td><td>147.96.81.131:98755 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.02569</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">       15.1383  </td><td style=\"text-align: right;\"> 0.00354836</td><td style=\"text-align: right;\">   0.561538</td><td style=\"text-align: right;\"> 0.426923 </td></tr>\n",
       "<tr><td>_aux_train_daostack_42e4138c</td><td>TERMINATED</td><td>147.96.81.131:98641 </td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.32722</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        9.86425 </td><td style=\"text-align: right;\"> 3.09316   </td><td style=\"text-align: right;\">   0.801923</td><td style=\"text-align: right;\"> 0.725    </td></tr>\n",
       "<tr><td>_aux_train_daostack_7cb3c8bb</td><td>TERMINATED</td><td>147.96.81.131:99955 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.6758 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        2.09439 </td><td style=\"text-align: right;\"> 1.9831    </td><td style=\"text-align: right;\">   0.844231</td><td style=\"text-align: right;\"> 0.786539 </td></tr>\n",
       "<tr><td>_aux_train_daostack_56d0fe11</td><td>TERMINATED</td><td>147.96.81.131:99437 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00131</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        1.18335 </td><td style=\"text-align: right;\"> 0.391526  </td><td style=\"text-align: right;\">   0.417308</td><td style=\"text-align: right;\"> 0.338462 </td></tr>\n",
       "<tr><td>_aux_train_daostack_712ab9e2</td><td>TERMINATED</td><td>147.96.81.131:99955 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.16163</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">        1.97063 </td><td style=\"text-align: right;\"> 0.0151993 </td><td style=\"text-align: right;\">   0.676923</td><td style=\"text-align: right;\"> 0.555769 </td></tr>\n",
       "<tr><td>_aux_train_daostack_773687bd</td><td>TERMINATED</td><td>147.96.81.131:99437 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.00427</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        2.26804 </td><td style=\"text-align: right;\"> 0.0761046 </td><td style=\"text-align: right;\">   0.478846</td><td style=\"text-align: right;\"> 0.413462 </td></tr>\n",
       "<tr><td>_aux_train_daostack_3b176f78</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.00047</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        1.16048 </td><td style=\"text-align: right;\"> 0.608777  </td><td style=\"text-align: right;\">   0.461538</td><td style=\"text-align: right;\"> 0.348077 </td></tr>\n",
       "<tr><td>_aux_train_daostack_3b6259e0</td><td>TERMINATED</td><td>147.96.81.131:99491 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.01898</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.735762</td><td style=\"text-align: right;\"> 0.0845383 </td><td style=\"text-align: right;\">   0.461538</td><td style=\"text-align: right;\"> 0.359615 </td></tr>\n",
       "<tr><td>_aux_train_daostack_1e856d54</td><td>TERMINATED</td><td>147.96.81.131:99955 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        6e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        4.24104 </td><td style=\"text-align: right;\"> 0.687457  </td><td style=\"text-align: right;\">   0.528846</td><td style=\"text-align: right;\"> 0.175    </td></tr>\n",
       "<tr><td>_aux_train_daostack_17bad256</td><td>TERMINATED</td><td>147.96.81.131:98947 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.05051</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">        6.1091  </td><td style=\"text-align: right;\"> 0.00361973</td><td style=\"text-align: right;\">   0.692308</td><td style=\"text-align: right;\"> 0.644231 </td></tr>\n",
       "<tr><td>_aux_train_daostack_229a7340</td><td>TERMINATED</td><td>147.96.81.131:99491 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.52528</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        1.2964  </td><td style=\"text-align: right;\"> 0.356651  </td><td style=\"text-align: right;\">   0.788462</td><td style=\"text-align: right;\"> 0.773077 </td></tr>\n",
       "<tr><td>_aux_train_daostack_df9c1d04</td><td>TERMINATED</td><td>147.96.81.131:100143</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.10143</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">        5.16636 </td><td style=\"text-align: right;\"> 0.0236767 </td><td style=\"text-align: right;\">   0.734615</td><td style=\"text-align: right;\"> 0.617308 </td></tr>\n",
       "<tr><td>_aux_train_daostack_9744cae4</td><td>TERMINATED</td><td>147.96.81.131:99437 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              7</td><td style=\"text-align: right;\">        0.20183</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.785669</td><td style=\"text-align: right;\"> 0.0451129 </td><td style=\"text-align: right;\">   0.828846</td><td style=\"text-align: right;\"> 0.807692 </td></tr>\n",
       "<tr><td>_aux_train_daostack_e3329d3c</td><td>TERMINATED</td><td>147.96.81.131:99491 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.0016 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        2.16791 </td><td style=\"text-align: right;\"> 0.177506  </td><td style=\"text-align: right;\">   0.436538</td><td style=\"text-align: right;\"> 0.398077 </td></tr>\n",
       "<tr><td>_aux_train_daostack_0abdd531</td><td>TERMINATED</td><td>147.96.81.131:99437 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.03469</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        1.28785 </td><td style=\"text-align: right;\"> 0.0324169 </td><td style=\"text-align: right;\">   0.517308</td><td style=\"text-align: right;\"> 0.398077 </td></tr>\n",
       "<tr><td>_aux_train_daostack_39cd2db8</td><td>TERMINATED</td><td>147.96.81.131:99437 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              6</td><td style=\"text-align: right;\">        0.00376</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        3.44013 </td><td style=\"text-align: right;\"> 0.0647298 </td><td style=\"text-align: right;\">   0.484615</td><td style=\"text-align: right;\"> 0.434615 </td></tr>\n",
       "<tr><td>_aux_train_daostack_039fa919</td><td>TERMINATED</td><td>147.96.81.131:99491 </td><td style=\"text-align: right;\">           7</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.00086</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        2.31416 </td><td style=\"text-align: right;\"> 0.254088  </td><td style=\"text-align: right;\">   0.413462</td><td style=\"text-align: right;\"> 0.365385 </td></tr>\n",
       "<tr><td>_aux_train_daostack_4ea04daf</td><td>TERMINATED</td><td>147.96.81.131:99955 </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00046</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        1.15442 </td><td style=\"text-align: right;\"> 0.649529  </td><td style=\"text-align: right;\">   0.409615</td><td style=\"text-align: right;\"> 0.257692 </td></tr>\n",
       "<tr><td>_aux_train_daostack_d0939be8</td><td>TERMINATED</td><td>147.96.81.131:99955 </td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        1e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">        0.70568 </td><td style=\"text-align: right;\"> 0.692984  </td><td style=\"text-align: right;\">   0.328846</td><td style=\"text-align: right;\"> 0.0307692</td></tr>\n",
       "<tr><td>_aux_train_daostack_7b840430</td><td>TERMINATED</td><td>147.96.81.131:99955 </td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        8e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>_aux_train_daostack_83f1f7ca</td><td>TERMINATED</td><td>147.96.81.131:99491 </td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">              4</td><td style=\"text-align: right;\">        0.00774</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>_aux_train_daostack_3071016b</td><td>TERMINATED</td><td>                    </td><td style=\"text-align: right;\">           8</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">              5</td><td style=\"text-align: right;\">        0.01309</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">           </td><td style=\"text-align: right;\">          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 16:03:36,007\tINFO timeout.py:54 -- Reached timeout of 60 seconds. Stopping all trials.\n",
      "2023-08-02 16:03:37,547\tINFO tune.py:1148 -- Total run time: 61.74 seconds (60.19 seconds for the tuning loop).\n",
      "2023-08-02 16:03:37,600\tWARNING experiment_analysis.py:916 -- Failed to read the results for 3 trials:\n",
      "- /home/daviddavo/ray_results/_aux_train_daostack_2023-08-02_16-02-35/_aux_train_daostack_7b840430_62_batch_size=6,conv_layers=4,embedding_dim=5,learning_rate=0.0001,max_epochs=50_2023-08-02_16-03-34\n",
      "- /home/daviddavo/ray_results/_aux_train_daostack_2023-08-02_16-02-35/_aux_train_daostack_83f1f7ca_63_batch_size=5,conv_layers=3,embedding_dim=4,learning_rate=0.0077,max_epochs=50_2023-08-02_16-03-35\n",
      "- /home/daviddavo/ray_results/_aux_train_daostack_2023-08-02_16-02-35/_aux_train_daostack_3071016b_64_batch_size=8,conv_layers=4,embedding_dim=5,learning_rate=0.0131,max_epochs=50_2023-08-02_16-03-35\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "def _aux_train_daostack(config):\n",
    "    # TODO: Is bad practice to pass a dataset trainable\n",
    "    config['embedding_dim'] = 2**config['embedding_dim']\n",
    "    config['batch_size'] = 2**config['batch_size']\n",
    "    return train_daostack(tr.to(device), val.to(device), ts.to(device), config, disable_tqdm=True)\n",
    "\n",
    "tryConfigs = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    conv_layers=tune.randint(2,6),\n",
    "    learning_rate=tune.qloguniform(1e-5, 1, 1e-5),\n",
    "    # These will be 2 to the power\n",
    "    batch_size=tune.randint(4,10), # 16..1024\n",
    "    embedding_dim=tune.randint(4,8), # 16..256\n",
    ")\n",
    "\n",
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    max_t=50,\n",
    "    grace_period=5,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "search_alg = HyperOptSearch()\n",
    "\n",
    "# Every run takes approx half a gig of vram (no optimizations)\n",
    "# The RTX 4090 has 24GB so we can run the model about 48 times\n",
    "resources_per_trial={\n",
    "    'cpu': 1,\n",
    "    'memory': 0 if torch.cuda.is_available() else 2e9,\n",
    "    'gpu': 1/32 if torch.cuda.is_available() else 0,\n",
    "}\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(_aux_train_daostack, resources_per_trial),\n",
    "    param_space=tryConfigs._asdict(),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        time_budget_s=60,\n",
    "        num_samples=-1,\n",
    "        scheduler=asha_scheduler,\n",
    "        search_alg=search_alg,\n",
    "        metric='loss',\n",
    "        mode='min',\n",
    "    )\n",
    ")\n",
    "exp = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 15:59:54,520\tWARNING experiment_analysis.py:694 -- Failed to read the config for 1 trials:\n",
      "- /home/daviddavo/ray_results/_aux_train_daostack_2023-08-02_15-52-56/_aux_train_daostack_9ba2bbbb_66_batch_size=8,conv_layers=5,embedding_dim=6,learning_rate=0.9851,max_epochs=50_2023-08-02_15-53-56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>p@5 train</th>\n",
       "      <th>p@5 test</th>\n",
       "      <th>r@5 train</th>\n",
       "      <th>r@5 test</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/conv_layers</th>\n",
       "      <th>config/embedding_dim</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>config/max_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.360198</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.231115</td>\n",
       "      <td>0.189667</td>\n",
       "      <td>0.235776</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>8545afd8</td>\n",
       "      <td>2023-08-02_15-53-56</td>\n",
       "      <td>1690991636</td>\n",
       "      <td>4.243093</td>\n",
       "      <td>4.243093</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.63793</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.815670</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.217099</td>\n",
       "      <td>0.172195</td>\n",
       "      <td>0.105648</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>94969f3b</td>\n",
       "      <td>2023-08-02_15-53-03</td>\n",
       "      <td>1690991583</td>\n",
       "      <td>1.601382</td>\n",
       "      <td>1.601382</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.83618</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.226437</td>\n",
       "      <td>0.805769</td>\n",
       "      <td>0.709615</td>\n",
       "      <td>0.213328</td>\n",
       "      <td>0.159748</td>\n",
       "      <td>0.147412</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "      <td>6eab0a6e</td>\n",
       "      <td>2023-08-02_15-53-33</td>\n",
       "      <td>1690991613</td>\n",
       "      <td>6.636717</td>\n",
       "      <td>6.636717</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.18221</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.467784</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.201313</td>\n",
       "      <td>0.147167</td>\n",
       "      <td>0.067959</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>29154650</td>\n",
       "      <td>2023-08-02_15-53-17</td>\n",
       "      <td>1690991597</td>\n",
       "      <td>0.947414</td>\n",
       "      <td>0.947414</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.89547</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.864354</td>\n",
       "      <td>0.840385</td>\n",
       "      <td>0.686539</td>\n",
       "      <td>0.226512</td>\n",
       "      <td>0.157390</td>\n",
       "      <td>0.124850</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>f8b911c2</td>\n",
       "      <td>2023-08-02_15-53-56</td>\n",
       "      <td>1690991636</td>\n",
       "      <td>5.477503</td>\n",
       "      <td>5.477503</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.33586</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.689345</td>\n",
       "      <td>0.438462</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.099213</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.097300</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>01107862</td>\n",
       "      <td>2023-08-02_15-53-12</td>\n",
       "      <td>1690991592</td>\n",
       "      <td>0.537367</td>\n",
       "      <td>0.537367</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.691613</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>0.218286</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.194479</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>362338af</td>\n",
       "      <td>2023-08-02_15-53-05</td>\n",
       "      <td>1690991585</td>\n",
       "      <td>0.916141</td>\n",
       "      <td>0.916141</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.692199</td>\n",
       "      <td>0.551923</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.140729</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.124343</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>b05f3d84</td>\n",
       "      <td>2023-08-02_15-53-14</td>\n",
       "      <td>1690991594</td>\n",
       "      <td>0.700850</td>\n",
       "      <td>0.700850</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.693034</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.040385</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.128587</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>12ebb57a</td>\n",
       "      <td>2023-08-02_15-53-34</td>\n",
       "      <td>1690991614</td>\n",
       "      <td>0.690873</td>\n",
       "      <td>0.690873</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.692775</td>\n",
       "      <td>0.398077</td>\n",
       "      <td>0.036538</td>\n",
       "      <td>0.106866</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>1.807607</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>1f726d5f</td>\n",
       "      <td>2023-08-02_15-53-56</td>\n",
       "      <td>1690991636</td>\n",
       "      <td>5.668302</td>\n",
       "      <td>5.668302</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  p@5 train  p@5 test  r@5 train  r@5 test  time_this_iter_s  \\\n",
       "62  1.360198   0.842308  0.800000   0.231115  0.189667          0.235776   \n",
       "3   1.815670   0.803846  0.726923   0.217099  0.172195          0.105648   \n",
       "33  0.226437   0.805769  0.709615   0.213328  0.159748          0.147412   \n",
       "21  1.467784   0.769231  0.688462   0.201313  0.147167          0.067959   \n",
       "61  0.864354   0.840385  0.686539   0.226512  0.157390          0.124850   \n",
       "..       ...        ...       ...        ...       ...               ...   \n",
       "13  0.689345   0.438462  0.086538   0.099213  0.006887          0.097300   \n",
       "5   0.691613   0.707692  0.059615   0.218286  0.002830          0.194479   \n",
       "18  0.692199   0.551923  0.057692   0.140729  0.004069          0.124343   \n",
       "43  0.693034   0.184615  0.040385   0.045946  0.002027          0.128587   \n",
       "59  0.692775   0.398077  0.036538   0.106866  0.002282          1.807607   \n",
       "\n",
       "     done  training_iteration  trial_id                 date   timestamp  \\\n",
       "62  False                  18  8545afd8  2023-08-02_15-53-56  1690991636   \n",
       "3    True                  15  94969f3b  2023-08-02_15-53-03  1690991583   \n",
       "33   True                  50  6eab0a6e  2023-08-02_15-53-33  1690991613   \n",
       "21   True                  15  29154650  2023-08-02_15-53-17  1690991597   \n",
       "61  False                  40  f8b911c2  2023-08-02_15-53-56  1690991636   \n",
       "..    ...                 ...       ...                  ...         ...   \n",
       "13   True                   5  01107862  2023-08-02_15-53-12  1690991592   \n",
       "5    True                   5  362338af  2023-08-02_15-53-05  1690991585   \n",
       "18   True                   5  b05f3d84  2023-08-02_15-53-14  1690991594   \n",
       "43   True                   5  12ebb57a  2023-08-02_15-53-34  1690991614   \n",
       "59  False                   3  1f726d5f  2023-08-02_15-53-56  1690991636   \n",
       "\n",
       "    time_total_s  time_since_restore  iterations_since_restore  \\\n",
       "62      4.243093            4.243093                        18   \n",
       "3       1.601382            1.601382                        15   \n",
       "33      6.636717            6.636717                        50   \n",
       "21      0.947414            0.947414                        15   \n",
       "61      5.477503            5.477503                        40   \n",
       "..           ...                 ...                       ...   \n",
       "13      0.537367            0.537367                         5   \n",
       "5       0.916141            0.916141                         5   \n",
       "18      0.700850            0.700850                         5   \n",
       "43      0.690873            0.690873                         5   \n",
       "59      5.668302            5.668302                         3   \n",
       "\n",
       "    config/batch_size  config/conv_layers  config/embedding_dim  \\\n",
       "62                  7                   2                     5   \n",
       "3                   7                   4                     5   \n",
       "33                  7                   3                     6   \n",
       "21                  8                   5                     6   \n",
       "61                  8                   3                     7   \n",
       "..                ...                 ...                   ...   \n",
       "13                  7                   4                     5   \n",
       "5                   6                   3                     6   \n",
       "18                  7                   4                     5   \n",
       "43                  7                   3                     4   \n",
       "59                  4                   3                     5   \n",
       "\n",
       "    config/learning_rate  config/max_epochs  \n",
       "62               0.63793                 50  \n",
       "3                0.83618                 50  \n",
       "33               0.18221                 50  \n",
       "21               0.89547                 50  \n",
       "61               0.33586                 50  \n",
       "..                   ...                ...  \n",
       "13               0.00005                 50  \n",
       "5                0.00002                 50  \n",
       "18               0.00003                 50  \n",
       "43               0.00001                 50  \n",
       "59               0.00001                 50  \n",
       "\n",
       "[65 rows x 19 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = exp.get_dataframe().drop(columns=['hostname', 'node_ip', 'logdir', 'should_checkpoint', 'pid'])\n",
    "exp_df.sort_values('p@5 test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all of this\n",
    "\n",
    "Crearé una función que reciba una dirección de un usuario y retorne k propuestas que puedan interesarle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_user' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proposals\n\u001b[1;32m     32\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0x334f12afb7d8740868be04719639616533075234\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# vpu[(12 < vpu) & (vpu < 38)].sample().index[0]\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreatedAt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserVoted\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m, in \u001b[0;36mrecommend\u001b[0;34m(user, K, ignore_train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend\u001b[39m(user: \u001b[38;5;28mstr\u001b[39m, K: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, ignore_train: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     uid \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_user\u001b[49m\u001b[38;5;241m.\u001b[39mtransform([user])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommending \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m proposals for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (uid:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvpu\u001b[38;5;241m.\u001b[39mat[user]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m votes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Getting embedding\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_user' is not defined"
     ]
    }
   ],
   "source": [
    "def recommend(user: str, K: int = 12, ignore_train: bool=False):\n",
    "    uid = encoder_user.transform([user])[0]\n",
    "    print(f\"Recommending {K} proposals for user {user} (uid:{uid}) with {vpu.at[user]} votes\")\n",
    "    \n",
    "    # Getting embedding\n",
    "    out = model(edge_index)\n",
    "    user_embed, item_embed = torch.split(out, (model.n_users, model.n_items))\n",
    "    relevance_score = torch.matmul(user_embed, torch.transpose(item_embed, 0, 1))\n",
    "    if ignore_train:\n",
    "        i = torch.stack([\n",
    "            torch.LongTensor(train_df['uid'].values),\n",
    "            torch.LongTensor(train_df['pid'].values),\n",
    "        ])\n",
    "        v = torch.ones(len(train_df), dtype=torch.float64)\n",
    "        t_interactions = torch.sparse.FloatTensor(i, v, (model.n_users, model.n_items)).to_dense().to(device)\n",
    "        # mask out training user-item interactions from metric computation\n",
    "        # We are only interested in novel items, as a user won't be interested\n",
    "        # in \"voting again\"\n",
    "        relevance_score = torch.mul(relevance_score, (1 - t_interactions))\n",
    "    \n",
    "    topk_relevance_indices = torch.topk(relevance_score, K).indices\n",
    "    \n",
    "    pids = topk_relevance_indices[uid].tolist()\n",
    "    proposals = dfp.loc[encoder_prop.inverse_transform(pids)]\n",
    "    \n",
    "    proposals['userVoted'] = dfv.groupby('proposal')['voter'].apply(lambda x: user in set(x))\n",
    "    \n",
    "    print(f\"precision@{K}={sum(proposals['userVoted'])/len(proposals)*100:.2f}%\")\n",
    "    \n",
    "    return proposals\n",
    "\n",
    "user = \"0x334f12afb7d8740868be04719639616533075234\" # vpu[(12 < vpu) & (vpu < 38)].sample().index[0]\n",
    "recommend(user, ignore_train=True)[['network', 'createdAt', 'title', 'description', 'userVoted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv[dfv['proposal'] == '0xb92d2df99a47244c07a9d7ef73530c273f1d65230dbff9e95873d82c0314534e']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
