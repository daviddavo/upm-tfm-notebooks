{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Pytorch Geometric official example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-05T08:34:16.741544Z",
     "iopub.status.busy": "2023-09-05T08:34:16.741113Z",
     "iopub.status.idle": "2023-09-05T08:34:18.813415Z",
     "shell.execute_reply": "2023-09-05T08:34:18.813066Z",
     "shell.execute_reply.started": "2023-09-05T08:34:16.741498Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_86936/1034952450.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/src/neg_sampling.py:13: UserWarning: This is copied from https://github.com/pyg-team/pytorch_geometric/pull/7816\n",
      "  warnings.warn('This is copied from https://github.com/pyg-team/pytorch_geometric/pull/7816')\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/src/neg_sampling.py:14: UserWarning: REMOVE WHEN MERGED\n",
      "  warnings.warn('REMOVE WHEN MERGED')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm.notebook import tqdm # Progress bars\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "# https://import-as.github.io\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as PyG\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import src\n",
    "from src.data import get_df, filter_df\n",
    "from src.graph_utils import shift_edge_indices, unshift_edge_indices\n",
    "from src.neg_sampling import structured_negative_sampling\n",
    "\n",
    "RANDOM_SEED = 1701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters table in [Google Drive](https://docs.google.com/spreadsheets/d/1riafpWt1563w9pbqdt1g2QZVkc7TfRWGzFaCG5rudDI/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-09-05T08:34:18.814157Z",
     "iopub.status.busy": "2023-09-05T08:34:18.813921Z",
     "iopub.status.idle": "2023-09-05T08:34:18.817068Z",
     "shell.execute_reply": "2023-09-05T08:34:18.816774Z",
     "shell.execute_reply.started": "2023-09-05T08:34:18.814141Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Remove users with less than 6 votes from the dataset before splitting\n",
    "DatasetConfig = namedtuple('DatasetConfig', ('min_votes_per_user', 'allowed_dao_names', 'num_folds'))\n",
    "datasetConfig = DatasetConfig(\n",
    "    min_votes_per_user=6,\n",
    "    allowed_dao_names={'dxDAO', 'xDXdao'},\n",
    "    num_folds=5,\n",
    ")\n",
    "\n",
    "ModelConfig = namedtuple('ModelConfig', 'max_epochs batch_size learning_rate embedding_dim conv_layers l2')\n",
    "modelConfig = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    embedding_dim=32,\n",
    "    conv_layers=3,\n",
    "    l2=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T08:34:18.817891Z",
     "iopub.status.busy": "2023-09-05T08:34:18.817751Z",
     "iopub.status.idle": "2023-09-05T08:34:18.865844Z",
     "shell.execute_reply": "2023-09-05T08:34:18.865548Z",
     "shell.execute_reply.started": "2023-09-05T08:34:18.817881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:          16606\n",
      "Density:       0.3087%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  voter={ num_nodes=104 },\n",
       "  proposal={ num_nodes=2216 },\n",
       "  (voter, votes, proposal)={ edge_index=[2, 8303] },\n",
       "  (proposal, voted, voter)={ edge_index=[2, 8303] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, HeteroData, Data\n",
    "from src.datasets import Daostack\n",
    "\n",
    "def print_graph_stats(g: HeteroData):\n",
    "    density = (g.num_edges) / (g.num_nodes*(g.num_nodes-1))\n",
    "    print(f'Edges:   {g.num_edges:12}')\n",
    "    print(f'Density: {density*100:12.4f}%')\n",
    "\n",
    "data = Daostack(\"./data/dao-analyzer/\", min_vpu=datasetConfig.min_votes_per_user, allowed_daos=datasetConfig.allowed_dao_names)[0]\n",
    "print_graph_stats(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I thought the RandomLinkSplit function was not working properly, but it turns out that I wasn't understanding it very well. The tutorial I used for [01_mvp](./01_mvp.ipynb) is not very good either, it was written by students, and implemented before PyTorch Geometric bundled the LightGCN model with it.\n",
    "\n",
    "> I think this is totally correct. It seems like you are looking at the shapes of edge_index, while you may want to look at the shapes of edge_label and edge_label_index (which correctly model a 80/10/10 split ratio). Here, edge_index is solely used for message passing, i.e.,\n",
    "> \n",
    "> * for training, we exchange messages on all training edges\n",
    "> * for validation, we exchange messages on all training edges\n",
    "> * for testing, we exchange messages on all training and validation edges\n",
    "> Let me know if this resolves your concerns :)\n",
    ">\n",
    "> -- [Split Error in RandomLinkSplit · Issue #3668 · pyg-team/pytorch_geometric · GitHub](https://github.com/pyg-team/pytorch_geometric/issues/3668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T08:34:18.867285Z",
     "iopub.status.busy": "2023-09-05T08:34:18.867150Z",
     "iopub.status.idle": "2023-09-05T08:34:18.890838Z",
     "shell.execute_reply": "2023-09-05T08:34:18.885330Z",
     "shell.execute_reply.started": "2023-09-05T08:34:18.867275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6643] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6643] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1660] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1660] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6643] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6643] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1660] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1660] }\n",
       "  ))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moved to graph_utils.py\n",
    "from src.graph_utils import k_fold as graph_k_fold\n",
    "\n",
    "graph_folds = graph_k_fold(data, datasetConfig.num_folds, random_state=RANDOM_SEED)\n",
    "graph_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,1,2,3,4,5,6,7,8,9,10][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_excluding(model, edge_index, src_index, dst_index, exclude_edges=None, k = 1):\n",
    "    emb = model.get_embedding(edge_index)\n",
    "\n",
    "    out_src = emb[src_index]\n",
    "    out_dst = emb[dst_index]\n",
    "\n",
    "    pred = out_src @ out_dst.t()\n",
    "\n",
    "    if exclude_edges is not None:\n",
    "        inv_src = torch.full((src_index.max().item()+1,), -1, device=exclude_edges.device)\n",
    "        inv_src[src_index] = torch.arange(0, src_index.numel(), device=exclude_edges.device)\n",
    "\n",
    "        inv_dst = torch.full((dst_index.max().item()+1,), -1, device=exclude_edges.device)\n",
    "        inv_dst[dst_index] = torch.arange(0, dst_index.numel(), device=exclude_edges.device)\n",
    "        \n",
    "        exclude_src = inv_src[exclude_edges[0]]\n",
    "        exclude_dst = inv_dst[exclude_edges[1]]\n",
    "        \n",
    "        pred[exclude_src, exclude_dst] = -np.inf\n",
    "\n",
    "    top_index = pred.topk(k, dim=-1).indices\n",
    "    top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
    "\n",
    "    return top_index\n",
    "\n",
    "# hdata = data.to_homogeneous()\n",
    "# strain = shift_edge_indices(graph_folds[0][0])\n",
    "# users = torch.arange(strain['voter'].shift + 10, strain['voter'].end, 2)\n",
    "# items = torch.arange(strain['proposal'].shift, strain['proposal'].end)\n",
    "# recommend_excluding(model, hdata.edge_index, torch.tensor([4, 8]), items, k=10, exclude_edges=torch.tensor([[8,4,4,4], [2296, 282, 600, 905]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T16:09:22.131087Z",
     "iopub.status.busy": "2023-08-17T16:09:22.130660Z",
     "iopub.status.idle": "2023-08-17T16:09:22.173119Z",
     "shell.execute_reply": "2023-08-17T16:09:22.172727Z",
     "shell.execute_reply.started": "2023-08-17T16:09:22.131050Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HeteroData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightGCN\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Based on:\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# - https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# - https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_daostack\u001b[39m(train: \u001b[43mHeteroData\u001b[49m, validation: HeteroData, original: HeteroData, modelConfig: ModelConfig, disable_tqdm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(modelConfig, ModelConfig):\n\u001b[1;32m      9\u001b[0m         modelConfig \u001b[38;5;241m=\u001b[39m ModelConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodelConfig)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HeteroData' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import LightGCN\n",
    "\n",
    "# Based on:\n",
    "# - https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# - https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
    "# - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "def train_daostack(train: HeteroData, validation: HeteroData, original: HeteroData, modelConfig: ModelConfig, disable_tqdm=False):\n",
    "    if not isinstance(modelConfig, ModelConfig):\n",
    "        modelConfig = ModelConfig(**modelConfig)\n",
    "    \n",
    "    model = LightGCN(\n",
    "        num_nodes=original.num_nodes,\n",
    "        embedding_dim=modelConfig.embedding_dim,\n",
    "        num_layers=modelConfig.conv_layers,\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=modelConfig.learning_rate)\n",
    "\n",
    "    checkpoint = session.get_checkpoint()\n",
    "\n",
    "    if checkpoint:\n",
    "        checkpoint_state = checkpoint.to_dict()\n",
    "        start_epoch = checkpoint_state[\"epoch\"]\n",
    "        model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    assert train.is_undirected()\n",
    "    assert validation.is_undirected()\n",
    "\n",
    "    # We need to convert the edge indices to homogeneous\n",
    "    # In hetero data the numbers are shared between the node types\n",
    "    # while in homo data they are shifted\n",
    "    original, train, validation = map(shift_edge_indices, [original, train, validation])\n",
    "    \n",
    "    # nodes = torch.arange(0, train.num_nodes, device=device)\n",
    "    users = torch.arange(train['voter'].shift, train['voter'].end, device=device)\n",
    "    items = torch.arange(train['proposal'].shift, train['proposal'].end, device=device)\n",
    "    n_users = train['voter'].num_nodes\n",
    "    n_items = train['proposal'].num_nodes\n",
    "\n",
    "    message_passing_edge_index = torch.concat([s.edge_index for s in train.edge_stores], dim=1)\n",
    "\n",
    "    # The official LightGCN usage also uses this line of code (well, for homo graphs)\n",
    "    # - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "    # In our case, we will use just voter ---> proposal\n",
    "    train_edge_label_index = train['voter', 'votes', 'proposal'].edge_index\n",
    "    assert (train_edge_label_index[0] < train['voter'].end).all()\n",
    "    assert (train['proposal'].shift <= train_edge_label_index[1]).all()\n",
    "\n",
    "    # TODO: Use LinkLoader instead (i don't know how)\n",
    "    # Waiting for pyg-team/pytorch_geometric#7817\n",
    "    # train_loader = PyG.loader.LinkLoader(\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        range(train_edge_label_index.size(1)), # dataset\n",
    "        batch_size=modelConfig.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _prec_rec(k: int, remove_training=False):\n",
    "        # gt: ground truth\n",
    "        if remove_training:\n",
    "            gt_index = validation['voter', 'votes', 'proposal'].edge_index\n",
    "            exclude_edges = train['voter', 'votes', 'proposal'].edge_index\n",
    "        else:\n",
    "            # All edges\n",
    "            gt_index = original['voter', 'votes', 'proposal'].edge_index\n",
    "            exclude_edges = None\n",
    "\n",
    "        R = item_count = PyG.utils.degree(gt_index[0], num_nodes=n_users)\n",
    "        # topr.size [104, R.max()]\n",
    "        topr = recommend_excluding(model, message_passing_edge_index, src_index=users, dst_index=items, k=int(R.max()), exclude_edges=exclude_edges)\n",
    "        n_samples = len(users)\n",
    "\n",
    "        # [104, 2216]\n",
    "        ground_truth = torch.full((n_users, n_items), False, dtype=torch.bool, device=device)\n",
    "        ground_truth[gt_index[0], gt_index[1] - original['proposal'].shift] = True\n",
    "\n",
    "        isin_rmat = ground_truth.gather(1, topr - original['proposal'].shift)\n",
    "        isin_mat = isin_rmat[:, :k]\n",
    "\n",
    "        prec = (isin_mat.sum(dim=-1) / k).sum() / n_samples\n",
    "        rec = (isin_mat.sum(dim=-1) / item_count).sum() / n_samples\n",
    "\n",
    "        # Now mask isin_rmat to get only up to :R elements\n",
    "        msk = torch.arange(1, R.max()+1, device=device) > R.unsqueeze(1)\n",
    "        isin_rmat[msk] = 0\n",
    "        rprec = (isin_rmat.sum(dim=-1) / R).sum() / n_samples\n",
    "\n",
    "        # print('prec, rec:', (prec, rec))\n",
    "        \n",
    "        return float(prec), float(rec), float(rprec)\n",
    "\n",
    "    for epoch in trange(start_epoch, modelConfig.max_epochs, disable=disable_tqdm):\n",
    "        # index is an array of batch_size that indicates which edges from \n",
    "        # train.edge_index we should use\n",
    "        acc_loss = n_samples = 0        \n",
    "        \n",
    "        for index in tqdm(train_loader, leave=False, delay=1, disable=disable_tqdm):\n",
    "            pos_edge_index = train_edge_label_index[:, index]\n",
    "            # TODO: Change to negative structured sampling like in original LightGCN implementation\n",
    "            neg_edge_index = torch.stack([\n",
    "                pos_edge_index[0],\n",
    "                torch.randint(train['proposal'].shift, train['proposal'].end,\n",
    "                          (pos_edge_index.size(1), ), device=device)\n",
    "            ], dim=0)\n",
    "            \n",
    "            edge_label_index = torch.cat([\n",
    "                pos_edge_index,\n",
    "                neg_edge_index,\n",
    "            ], dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pos_rank, neg_rank = model(message_passing_edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "            # Learning\n",
    "            loss = model.recommendation_loss(\n",
    "                pos_rank,\n",
    "                neg_rank,\n",
    "                node_id=edge_label_index.unique(),\n",
    "                lambda_reg=modelConfig.l2,\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_loss += float(loss) * pos_rank.numel()\n",
    "            n_samples += pos_rank.numel()\n",
    "\n",
    "        checkpoint = Checkpoint.from_dict({\n",
    "            'epoch': epoch,\n",
    "            'net_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        })\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pos_val_edge_index = validation['voter', 'votes', 'proposal'].edge_index\n",
    "            neg_val_edge_index = torch.stack([\n",
    "                pos_val_edge_index[0],\n",
    "                torch.randint(validation['proposal'].shift, validation['proposal'].end, (pos_val_edge_index.size(1),), device=device)\n",
    "            ], dim=0)\n",
    "            val_label_index = torch.cat([\n",
    "                pos_val_edge_index,\n",
    "                neg_val_edge_index,\n",
    "            ], dim=1)\n",
    "            pos_rank, neg_rank = model(message_passing_edge_index, val_label_index).chunk(2)\n",
    "            val_loss = model.recommendation_loss(\n",
    "                pos_rank, \n",
    "                neg_rank, \n",
    "                node_id=val_label_index.unique(), \n",
    "                lambda_reg=modelConfig.l2\n",
    "            ).item()\n",
    "            \n",
    "            prec5, rec5, rprec = _prec_rec(5, remove_training=False)\n",
    "            prec5t, rec5t, rprect = _prec_rec(5, remove_training=True)\n",
    "            session.report({\n",
    "                'loss': acc_loss/n_samples,\n",
    "                'val_loss': val_loss,\n",
    "                'rprec train': rprec, 'rprec test': rprect,\n",
    "                'p@5 train': prec5, 'p@5 test': prec5t,\n",
    "                'r@5 train': rec5, 'r@5 test': rec5t,\n",
    "            }, checkpoint=checkpoint)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Testing just syntax errors\n",
    "model = train_daostack(graph_folds[0][0].to(device), graph_folds[0][1].to(device), data.to(device), ModelConfig(**(modelConfig._asdict() | {'max_epochs':2})))\n",
    "print(PyG.nn.summary(model, data['voter', 'votes', 'proposal'].edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T16:09:26.172643Z",
     "iopub.status.busy": "2023-08-17T16:09:26.172221Z",
     "iopub.status.idle": "2023-08-17T16:09:26.178565Z",
     "shell.execute_reply": "2023-08-17T16:09:26.178302Z",
     "shell.execute_reply.started": "2023-08-17T16:09:26.172609Z"
    }
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from torch_geometric.nn import LightGCN\n",
    "\n",
    "class TrainDaostack(tune.Trainable):\n",
    "    def setup(self, config):\n",
    "        n_fold = config.pop('__trial_index')\n",
    "        self.train, self.validation = graph_folds[n_fold]\n",
    "\n",
    "        self.modelConfig = ModelConfig(**modelConfig)\n",
    "\n",
    "        self.model = LightGCN(\n",
    "            num_nodes=original.num_nodes,\n",
    "            embedding_dim=modelConfig.embedding_dim,\n",
    "            num_layers=modelConfig.conv_layers,\n",
    "        ).to(device)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=modelConfig.learning_rate)\n",
    "\n",
    "    def step(self):\n",
    "        daostack_train(self.model, self.optimizer, self.train)\n",
    "        metrics = daostack_eval(self.model, self.optimizer, self.validation)\n",
    "        # evaluate_epoch(self.model, self.optimizer, self.validation)\n",
    "        return metrics\n",
    "\n",
    "    def save_checkpoint(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"model.pth\")\n",
    "        torch.save(self.model.state_dict(), checkpoint_path)\n",
    "        return checkpoint_path\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        self.model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-17 15:56:18</td></tr>\n",
       "<tr><td>Running for: </td><td>01:31:37.15        </td></tr>\n",
       "<tr><td>Memory:      </td><td>40.6/125.6 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 24.0/24 CPUs, 0.75/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  ... 789 more trials not shown (14 RUNNING, 774 TERMINATED)\n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  __trial_index__</th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_layers</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">         l2</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  rprec train</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_aux_train_daostack_0a7d7cba</td><td>RUNNING   </td><td>147.96.81.131:1766262</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             25</td><td style=\"text-align: right;\">1.88629e-06</td><td style=\"text-align: right;\">        0.00282</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">        183.978 </td><td style=\"text-align: right;\">0.125328</td><td style=\"text-align: right;\">  0.844526</td><td style=\"text-align: right;\">     0.60739 </td></tr>\n",
       "<tr><td>_aux_train_daostack_0e629806</td><td>RUNNING   </td><td>147.96.81.131:1767242</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             25</td><td style=\"text-align: right;\">1.88629e-06</td><td style=\"text-align: right;\">        0.00282</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">        195.097 </td><td style=\"text-align: right;\">0.129559</td><td style=\"text-align: right;\">  0.823479</td><td style=\"text-align: right;\">     0.64876 </td></tr>\n",
       "<tr><td>_aux_train_daostack_236994a7</td><td>RUNNING   </td><td>147.96.81.131:1766471</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             75</td><td style=\"text-align: right;\">9.18826e-06</td><td style=\"text-align: right;\">        0.0043 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         11.2934</td><td style=\"text-align: right;\">0.220604</td><td style=\"text-align: right;\">  0.601125</td><td style=\"text-align: right;\">     0.460909</td></tr>\n",
       "<tr><td>_aux_train_daostack_3d8a9e28</td><td>RUNNING   </td><td>147.96.81.131:1766032</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">            115</td><td style=\"text-align: right;\">1.05648e-06</td><td style=\"text-align: right;\">        0.00337</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         42.181 </td><td style=\"text-align: right;\">0.135829</td><td style=\"text-align: right;\">  0.726379</td><td style=\"text-align: right;\">     0.628821</td></tr>\n",
       "<tr><td>_aux_train_daostack_3ffcf8e9</td><td>RUNNING   </td><td>147.96.81.131:1766210</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             75</td><td style=\"text-align: right;\">9.18826e-06</td><td style=\"text-align: right;\">        0.0043 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         16.947 </td><td style=\"text-align: right;\">0.203357</td><td style=\"text-align: right;\">  0.637971</td><td style=\"text-align: right;\">     0.482316</td></tr>\n",
       "<tr><td>_aux_train_daostack_45db069a</td><td>RUNNING   </td><td>147.96.81.131:1766523</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             65</td><td style=\"text-align: right;\">2.34467e-06</td><td style=\"text-align: right;\">        0.0223 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         66.712 </td><td style=\"text-align: right;\">0.21477 </td><td style=\"text-align: right;\">  1.41545 </td><td style=\"text-align: right;\">     0.720728</td></tr>\n",
       "<tr><td>_aux_train_daostack_4c37a031</td><td>RUNNING   </td><td>147.96.81.131:1766418</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             65</td><td style=\"text-align: right;\">2.34467e-06</td><td style=\"text-align: right;\">        0.0223 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         66.7118</td><td style=\"text-align: right;\">0.225403</td><td style=\"text-align: right;\">  1.41055 </td><td style=\"text-align: right;\">     0.71893 </td></tr>\n",
       "<tr><td>_aux_train_daostack_6013c92b</td><td>RUNNING   </td><td>147.96.81.131:1765765</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             25</td><td style=\"text-align: right;\">1.88629e-06</td><td style=\"text-align: right;\">        0.00282</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">        206.928 </td><td style=\"text-align: right;\">0.120031</td><td style=\"text-align: right;\">  0.80165 </td><td style=\"text-align: right;\">     0.629484</td></tr>\n",
       "<tr><td>_aux_train_daostack_63fbf10b</td><td>RUNNING   </td><td>147.96.81.131:1765928</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             75</td><td style=\"text-align: right;\">9.18826e-06</td><td style=\"text-align: right;\">        0.0043 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         22.5321</td><td style=\"text-align: right;\">0.183542</td><td style=\"text-align: right;\">  0.681548</td><td style=\"text-align: right;\">     0.532967</td></tr>\n",
       "<tr><td>_aux_train_daostack_65a596f8</td><td>RUNNING   </td><td>147.96.81.131:1766314</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             30</td><td style=\"text-align: right;\">3.27888e-07</td><td style=\"text-align: right;\">        0.00092</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         44.1677</td><td style=\"text-align: right;\">0.302842</td><td style=\"text-align: right;\">  0.480791</td><td style=\"text-align: right;\">     0.342652</td></tr>\n",
       "<tr><td>_aux_train_daostack_e7b5718a</td><td>PENDING   </td><td>                     </td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             75</td><td style=\"text-align: right;\">9.18826e-06</td><td style=\"text-align: right;\">        0.0043 </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">          </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>_aux_train_daostack_007f4626</td><td>TERMINATED</td><td>147.96.81.131:1766099</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             40</td><td style=\"text-align: right;\">1.58421e-05</td><td style=\"text-align: right;\">        0.00681</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        350.688 </td><td style=\"text-align: right;\">0.118606</td><td style=\"text-align: right;\">  0.887839</td><td style=\"text-align: right;\">     0.77569 </td></tr>\n",
       "<tr><td>_aux_train_daostack_01887c54</td><td>TERMINATED</td><td>147.96.81.131:1766366</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             60</td><td style=\"text-align: right;\">6.43956e-05</td><td style=\"text-align: right;\">        0.00211</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        151.744 </td><td style=\"text-align: right;\">0.117374</td><td style=\"text-align: right;\">  0.832717</td><td style=\"text-align: right;\">     0.687838</td></tr>\n",
       "<tr><td>_aux_train_daostack_01e82a1d</td><td>TERMINATED</td><td>147.96.81.131:1765712</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           6</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">            315</td><td style=\"text-align: right;\">0.000480704</td><td style=\"text-align: right;\">        0.00227</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         97.1325</td><td style=\"text-align: right;\">0.130261</td><td style=\"text-align: right;\">  0.737362</td><td style=\"text-align: right;\">     0.715757</td></tr>\n",
       "<tr><td>_aux_train_daostack_01f144fc</td><td>TERMINATED</td><td>147.96.81.131:1765928</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             45</td><td style=\"text-align: right;\">0.000924315</td><td style=\"text-align: right;\">        0.00025</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        344.951 </td><td style=\"text-align: right;\">0.289651</td><td style=\"text-align: right;\">  0.487725</td><td style=\"text-align: right;\">     0.379872</td></tr>\n",
       "<tr><td>_aux_train_daostack_021df1e4</td><td>TERMINATED</td><td>147.96.81.131:1766674</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             70</td><td style=\"text-align: right;\">2.61453e-07</td><td style=\"text-align: right;\">        0.00083</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        331.973 </td><td style=\"text-align: right;\">0.129967</td><td style=\"text-align: right;\">  0.803822</td><td style=\"text-align: right;\">     0.588787</td></tr>\n",
       "<tr><td>_aux_train_daostack_02ad6815</td><td>TERMINATED</td><td>147.96.81.131:1765873</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">            115</td><td style=\"text-align: right;\">0.000130653</td><td style=\"text-align: right;\">        0.04406</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        461.871 </td><td style=\"text-align: right;\">0.820064</td><td style=\"text-align: right;\">  3.88424 </td><td style=\"text-align: right;\">     0.718211</td></tr>\n",
       "<tr><td>_aux_train_daostack_02c8c40b</td><td>TERMINATED</td><td>147.96.81.131:1765928</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             10</td><td style=\"text-align: right;\">1.68819e-06</td><td style=\"text-align: right;\">        0.10941</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        340.268 </td><td style=\"text-align: right;\">0.537183</td><td style=\"text-align: right;\">  2.25975 </td><td style=\"text-align: right;\">     0.421876</td></tr>\n",
       "<tr><td>_aux_train_daostack_038fd854</td><td>TERMINATED</td><td>147.96.81.131:1765712</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">4.69463e-05</td><td style=\"text-align: right;\">        0.00779</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        287.645 </td><td style=\"text-align: right;\">0.115825</td><td style=\"text-align: right;\">  0.914666</td><td style=\"text-align: right;\">     0.725496</td></tr>\n",
       "<tr><td>_aux_train_daostack_03fdc9de</td><td>TERMINATED</td><td>147.96.81.131:1767242</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           5</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">             20</td><td style=\"text-align: right;\">1.35027e-07</td><td style=\"text-align: right;\">        0.16085</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        172.128 </td><td style=\"text-align: right;\">2.24709 </td><td style=\"text-align: right;\"> 12.2892  </td><td style=\"text-align: right;\">     0.535048</td></tr>\n",
       "<tr><td>_aux_train_daostack_0421bec6</td><td>TERMINATED</td><td>147.96.81.131:1767242</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           4</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">            330</td><td style=\"text-align: right;\">9.39322e-07</td><td style=\"text-align: right;\">        5e-05  </td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        315.753 </td><td style=\"text-align: right;\">0.26721 </td><td style=\"text-align: right;\">  0.541337</td><td style=\"text-align: right;\">     0.407784</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search import Repeater\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "def _aux_train_daostack(config):\n",
    "    # TODO: Is bad practice to pass a dataset trainable\n",
    "    # config['embedding_dim'] = 2**config['embedding_dim']\n",
    "    config['batch_size'] = 2**config['batch_size']\n",
    "    n_fold = config.pop('__trial_index__')\n",
    "    train, validation = graph_folds[n_fold]\n",
    "    train_daostack(train.to(device), validation.to(device), data.to(device), config, disable_tqdm=True)\n",
    "\n",
    "if os.uname().nodename == 'lamarck':\n",
    "    assert torch.cuda.is_available()\n",
    "    \n",
    "    NUM_SAMPLES = 250\n",
    "    # Every run takes approx half a gig of vram (no optimizations)\n",
    "    # The RTX 4090 has 24GB so we can run the model about 48 times\n",
    "    resources_per_trial={\n",
    "        'cpu': 1,\n",
    "        'gpu': 1/32,\n",
    "    }\n",
    "else:\n",
    "    NUM_SAMPLES = 1\n",
    "    resources_per_trial={\n",
    "        'cpu': 2,\n",
    "        'memory': 2e9,\n",
    "    }\n",
    "\n",
    "tryConfigs = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    conv_layers=tune.randint(2,6),\n",
    "    learning_rate=tune.qloguniform(1e-5, 1, 1e-5),\n",
    "    l2=tune.loguniform(1e-9, 1e-1),\n",
    "    # These will be 2 to the power\n",
    "    batch_size=tune.randint(4,10), # 16..1024\n",
    "    # embedding_dim=tune.randint(4,8), # 16..128\n",
    "    embedding_dim=tune.qlograndint(10, 500, 5),\n",
    ")\n",
    "\n",
    "# It is recommended to not use Repeater with a TrialScheduler. Early termination can negatively affect the average reported metric.\n",
    "asha_scheduler = None\n",
    "# asha_scheduler = ASHAScheduler(\n",
    "#     time_attr='training_iteration',\n",
    "#     max_t=50,\n",
    "#     grace_period=5,\n",
    "#     reduction_factor=3,\n",
    "#     brackets=1,\n",
    "# )\n",
    "\n",
    "search_alg = HyperOptSearch()\n",
    "search_alg = Repeater(search_alg,datasetConfig.num_folds)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(_aux_train_daostack, resources_per_trial),\n",
    "    param_space=tryConfigs._asdict(),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        # time_budget_s=60,\n",
    "        num_samples=datasetConfig.num_folds*NUM_SAMPLES,\n",
    "        scheduler=asha_scheduler,\n",
    "        search_alg=search_alg,\n",
    "        metric='rprec test',\n",
    "        mode='max',\n",
    "    )\n",
    ")\n",
    "exp = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = exp.get_dataframe().drop(columns=['hostname', 'node_ip', 'logdir', 'should_checkpoint', 'pid'])\n",
    "exp_df.sort_values('p@5 test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all of this\n",
    "\n",
    "Crearé una función que reciba una dirección de un usuario y retorne k propuestas que puedan interesarle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user: str, K: int = 12, ignore_train: bool=False):\n",
    "    uid = encoder_user.transform([user])[0]\n",
    "    print(f\"Recommending {K} proposals for user {user} (uid:{uid}) with {vpu.at[user]} votes\")\n",
    "    \n",
    "    # Getting embedding\n",
    "    out = model(edge_index)\n",
    "    user_embed, item_embed = torch.split(out, (model.n_users, model.n_items))\n",
    "    relevance_score = torch.matmul(user_embed, torch.transpose(item_embed, 0, 1))\n",
    "    if ignore_train:\n",
    "        i = torch.stack([\n",
    "            torch.LongTensor(train_df['uid'].values),\n",
    "            torch.LongTensor(train_df['pid'].values),\n",
    "        ])\n",
    "        v = torch.ones(len(train_df), dtype=torch.float64)\n",
    "        t_interactions = torch.sparse.FloatTensor(i, v, (model.n_users, model.n_items)).to_dense().to(device)\n",
    "        # mask out training user-item interactions from metric computation\n",
    "        # We are only interested in novel items, as a user won't be interested\n",
    "        # in \"voting again\"\n",
    "        relevance_score = torch.mul(relevance_score, (1 - t_interactions))\n",
    "    \n",
    "    topk_relevance_indices = torch.topk(relevance_score, K).indices\n",
    "    \n",
    "    pids = topk_relevance_indices[uid].tolist()\n",
    "    proposals = dfp.loc[encoder_prop.inverse_transform(pids)]\n",
    "    \n",
    "    proposals['userVoted'] = dfv.groupby('proposal')['voter'].apply(lambda x: user in set(x))\n",
    "    \n",
    "    print(f\"precision@{K}={sum(proposals['userVoted'])/len(proposals)*100:.2f}%\")\n",
    "    \n",
    "    return proposals\n",
    "\n",
    "user = \"0x334f12afb7d8740868be04719639616533075234\" # vpu[(12 < vpu) & (vpu < 38)].sample().index[0]\n",
    "recommend(user, ignore_train=True)[['network', 'createdAt', 'title', 'description', 'userVoted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv[dfv['proposal'] == '0xb92d2df99a47244c07a9d7ef73530c273f1d65230dbff9e95873d82c0314534e']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
