{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Pytorch Geometric official example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:14.844780Z",
     "iopub.status.busy": "2023-08-17T11:20:14.844691Z",
     "iopub.status.idle": "2023-08-17T11:20:16.540011Z",
     "shell.execute_reply": "2023-08-17T11:20:16.539663Z",
     "shell.execute_reply.started": "2023-08-17T11:20:14.844770Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9375/1034952450.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/src/neg_sampling.py:13: UserWarning: This is copied from https://github.com/pyg-team/pytorch_geometric/pull/7816\n",
      "  warnings.warn('This is copied from https://github.com/pyg-team/pytorch_geometric/pull/7816')\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/src/neg_sampling.py:14: UserWarning: REMOVE WHEN MERGED\n",
      "  warnings.warn('REMOVE WHEN MERGED')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "import functools as ft\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from tqdm.notebook import tqdm # Progress bars\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "# https://import-as.github.io\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as PyG\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import src\n",
    "from src.data import get_df, filter_df\n",
    "from src.graph_utils import shift_edge_indices, unshift_edge_indices\n",
    "from src.neg_sampling import structured_negative_sampling\n",
    "\n",
    "RANDOM_SEED = 1701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters table in [Google Drive](https://docs.google.com/spreadsheets/d/1riafpWt1563w9pbqdt1g2QZVkc7TfRWGzFaCG5rudDI/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:16.540860Z",
     "iopub.status.busy": "2023-08-17T11:20:16.540747Z",
     "iopub.status.idle": "2023-08-17T11:20:16.543807Z",
     "shell.execute_reply": "2023-08-17T11:20:16.543414Z",
     "shell.execute_reply.started": "2023-08-17T11:20:16.540850Z"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Remove users with less than 6 votes from the dataset before splitting\n",
    "DatasetConfig = namedtuple('DatasetConfig', ('min_votes_per_user', 'allowed_dao_names', 'num_folds'))\n",
    "datasetConfig = DatasetConfig(\n",
    "    min_votes_per_user=6,\n",
    "    allowed_dao_names={'dxDAO', 'xDXdao'},\n",
    "    num_folds=5,\n",
    ")\n",
    "\n",
    "ModelConfig = namedtuple('ModelConfig', 'max_epochs batch_size learning_rate embedding_dim conv_layers l2')\n",
    "modelConfig = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.001,\n",
    "    embedding_dim=32,\n",
    "    conv_layers=3,\n",
    "    l2=1e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:16.544236Z",
     "iopub.status.busy": "2023-08-17T11:20:16.544139Z",
     "iopub.status.idle": "2023-08-17T11:20:16.597589Z",
     "shell.execute_reply": "2023-08-17T11:20:16.597299Z",
     "shell.execute_reply.started": "2023-08-17T11:20:16.544225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:          16606\n",
      "Density:       0.3087%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  voter={ num_nodes=104 },\n",
       "  proposal={ num_nodes=2216 },\n",
       "  (voter, votes, proposal)={ edge_index=[2, 8303] },\n",
       "  (proposal, voted, voter)={ edge_index=[2, 8303] }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, HeteroData, Data\n",
    "from src.datasets import Daostack\n",
    "\n",
    "def print_graph_stats(g: HeteroData):\n",
    "    density = (g.num_edges) / (g.num_nodes*(g.num_nodes-1))\n",
    "    print(f'Edges:   {g.num_edges:12}')\n",
    "    print(f'Density: {density*100:12.4f}%')\n",
    "\n",
    "data = Daostack(\"./data/dao-analyzer/\", min_vpu=datasetConfig.min_votes_per_user, allowed_daos=datasetConfig.allowed_dao_names)[0]\n",
    "print_graph_stats(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, I thought the RandomLinkSplit function was not working properly, but it turns out that I wasn't understanding it very well. The tutorial I used for [01_mvp](./01_mvp.ipynb) is not very good either, it was written by students, and implemented before PyTorch Geometric bundled the LightGCN model with it.\n",
    "\n",
    "> I think this is totally correct. It seems like you are looking at the shapes of edge_index, while you may want to look at the shapes of edge_label and edge_label_index (which correctly model a 80/10/10 split ratio). Here, edge_index is solely used for message passing, i.e.,\n",
    "> \n",
    "> * for training, we exchange messages on all training edges\n",
    "> * for validation, we exchange messages on all training edges\n",
    "> * for testing, we exchange messages on all training and validation edges\n",
    "> Let me know if this resolves your concerns :)\n",
    ">\n",
    "> -- [Split Error in RandomLinkSplit · Issue #3668 · pyg-team/pytorch_geometric · GitHub](https://github.com/pyg-team/pytorch_geometric/issues/3668)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:16.598325Z",
     "iopub.status.busy": "2023-08-17T11:20:16.598114Z",
     "iopub.status.idle": "2023-08-17T11:20:16.635060Z",
     "shell.execute_reply": "2023-08-17T11:20:16.634705Z",
     "shell.execute_reply.started": "2023-08-17T11:20:16.598309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6642] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6642] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1661] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1661] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6643] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6643] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1660] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1660] }\n",
       "  )),\n",
       " (HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 6643] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 6643] }\n",
       "  ),\n",
       "  HeteroData(\n",
       "    voter={ num_nodes=104 },\n",
       "    proposal={ num_nodes=2216 },\n",
       "    (voter, votes, proposal)={ edge_index=[2, 1660] },\n",
       "    (proposal, voted, voter)={ edge_index=[2, 1660] }\n",
       "  ))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def graph_k_fold(g: Data | HeteroData, folds, edge_type=None):\n",
    "    skf = StratifiedKFold(folds, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    folds = []\n",
    "\n",
    "    # Stratify by voter\n",
    "    if edge_type is None:\n",
    "        edge_type = g.edge_types[0]\n",
    "        rev_edge_type = g.edge_types[1]\n",
    "        \n",
    "    edge_index = g[edge_type].edge_index\n",
    "    for train_idx, val_idx in skf.split(torch.zeros(edge_index.size(1)), edge_index[0]):\n",
    "        gtrain = g.edge_subgraph({\n",
    "            edge_type:torch.tensor(train_idx),\n",
    "            rev_edge_type:torch.tensor(train_idx),\n",
    "        })\n",
    "        assert gtrain.is_undirected()\n",
    "        assert len(gtrain[edge_type].edge_index[0].unique()) == len(g[edge_type].edge_index[0].unique())\n",
    "        # The negative samples should be different each epoch\n",
    "        # gtrain[edge_type].negative_samples = structured_negative_sampling(gtrain[edge_type].edge_index, (aux[edge_type[0]].num_nodes, aux[edge_type[2]].num_nodes))[2]\n",
    "        gval = g.edge_subgraph({\n",
    "            edge_type:torch.tensor(val_idx),\n",
    "            rev_edge_type:torch.tensor(val_idx),\n",
    "        })\n",
    "        assert gval.is_undirected()\n",
    "        assert len(gval[edge_type].edge_index[0].unique()) == len(g[edge_type].edge_index[0].unique())\n",
    "        assert (gtrain[edge_type].edge_index[0].unique() == gval[edge_type].edge_index[0].unique()).all()\n",
    "\n",
    "        folds.append((gtrain, gval))\n",
    "\n",
    "    return folds\n",
    "\n",
    "graph_folds = graph_k_fold(data, datasetConfig.num_folds)\n",
    "graph_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:16.635819Z",
     "iopub.status.busy": "2023-08-17T11:20:16.635670Z",
     "iopub.status.idle": "2023-08-17T11:20:16.638909Z",
     "shell.execute_reply": "2023-08-17T11:20:16.638557Z",
     "shell.execute_reply.started": "2023-08-17T11:20:16.635805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:16.639548Z",
     "iopub.status.busy": "2023-08-17T11:20:16.639413Z",
     "iopub.status.idle": "2023-08-17T11:20:16.647506Z",
     "shell.execute_reply": "2023-08-17T11:20:16.647258Z",
     "shell.execute_reply.started": "2023-08-17T11:20:16.639536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,1,2,3,4,5,6,7,8,9,10][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:16.648832Z",
     "iopub.status.busy": "2023-08-17T11:20:16.648706Z",
     "iopub.status.idle": "2023-08-17T11:20:16.656029Z",
     "shell.execute_reply": "2023-08-17T11:20:16.655602Z",
     "shell.execute_reply.started": "2023-08-17T11:20:16.648822Z"
    }
   },
   "outputs": [],
   "source": [
    "def recommend_excluding(model, edge_index, src_index, dst_index, exclude_edges=None, k = 1):\n",
    "    emb = model.get_embedding(edge_index)\n",
    "\n",
    "    out_src = emb[src_index]\n",
    "    out_dst = emb[dst_index]\n",
    "\n",
    "    pred = out_src @ out_dst.t()\n",
    "\n",
    "    if exclude_edges is not None:\n",
    "        inv_src = torch.full((src_index.max().item()+1,), -1)\n",
    "        inv_src[src_index] = torch.arange(0, src_index.numel())\n",
    "\n",
    "        inv_dst = torch.full((dst_index.max().item()+1,), -1)\n",
    "        inv_dst[dst_index] = torch.arange(0, dst_index.numel())\n",
    "        \n",
    "        exclude_src = inv_src[exclude_edges[0]]\n",
    "        exclude_dst = inv_dst[exclude_edges[1]]\n",
    "        \n",
    "        pred[exclude_src, exclude_dst] = -np.inf\n",
    "\n",
    "    top_index = pred.topk(k, dim=-1).indices\n",
    "    top_index = dst_index[top_index.view(-1)].view(*top_index.size())\n",
    "\n",
    "    return top_index\n",
    "\n",
    "# hdata = data.to_homogeneous()\n",
    "# strain = shift_edge_indices(graph_folds[0][0])\n",
    "# users = torch.arange(strain['voter'].shift + 10, strain['voter'].end, 2)\n",
    "# items = torch.arange(strain['proposal'].shift, strain['proposal'].end)\n",
    "# recommend_excluding(model, hdata.edge_index, torch.tensor([4, 8]), items, k=10, exclude_edges=torch.tensor([[8,4,4,4], [2296, 282, 600, 905]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:16.656586Z",
     "iopub.status.busy": "2023-08-17T11:20:16.656486Z",
     "iopub.status.idle": "2023-08-17T11:20:17.679237Z",
     "shell.execute_reply": "2023-08-17T11:20:17.678890Z",
     "shell.execute_reply.started": "2023-08-17T11:20:16.656576Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 13:20:16,667\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/.direnv/python-3.11/lib/python3.11/site-packages/ray/air/session.py:28: UserWarning: `get_checkpoint` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64944b306dc469280d14327798d23f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 13:20:17,187\tWARNING session.py:100 -- In neither tune session nor train session!\n",
      "/home/davo/Documents/MUIA/upm-tfm-notebooks/.direnv/python-3.11/lib/python3.11/site-packages/ray/air/session.py:28: UserWarning: `report` is meant to only be called inside a function that is executed by a Tuner or Trainer. Returning `None`.\n",
      "  warnings.warn(\n",
      "2023-08-17 13:20:17,672\tWARNING session.py:100 -- In neither tune session nor train session!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------+----------------+----------+\n",
      "| Layer                  | Input Shape           | Output Shape   | #Param   |\n",
      "|------------------------+-----------------------+----------------+----------|\n",
      "| LightGCN               | [2, 8303]             | [8303]         | 74,240   |\n",
      "| ├─(embedding)Embedding | --                    | --             | 74,240   |\n",
      "| ├─(convs)ModuleList    | --                    | --             | --       |\n",
      "| │    └─(0)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "| │    └─(1)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "| │    └─(2)LGConv       | [2320, 32], [2, 8303] | [2320, 32]     | --       |\n",
      "+------------------------+-----------------------+----------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import LightGCN\n",
    "\n",
    "# Based on:\n",
    "# - https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "# - https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html\n",
    "# - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "def train_daostack(train: HeteroData, validation: HeteroData, original: HeteroData, modelConfig: ModelConfig, disable_tqdm=False):\n",
    "    if not isinstance(modelConfig, ModelConfig):\n",
    "        modelConfig = ModelConfig(**modelConfig)\n",
    "    \n",
    "    model = LightGCN(\n",
    "        num_nodes=original.num_nodes,\n",
    "        embedding_dim=modelConfig.embedding_dim,\n",
    "        num_layers=modelConfig.conv_layers,\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=modelConfig.learning_rate)\n",
    "\n",
    "    checkpoint = session.get_checkpoint()\n",
    "\n",
    "    if checkpoint:\n",
    "        checkpoint_state = checkpoint.to_dict()\n",
    "        start_epoch = checkpoint_state[\"epoch\"]\n",
    "        model.load_state_dict(checkpoint_state[\"net_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint_state[\"optimizer_state_dict\"])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "\n",
    "    assert train.is_undirected()\n",
    "    assert validation.is_undirected()\n",
    "\n",
    "    # We need to convert the edge indices to homogeneous\n",
    "    # In hetero data the numbers are shared between the node types\n",
    "    # while in homo data they are shifted\n",
    "    original, train, validation = map(shift_edge_indices, [original, train, validation])\n",
    "    \n",
    "    # nodes = torch.arange(0, train.num_nodes, device=device)\n",
    "    users = torch.arange(train['voter'].shift, train['voter'].end, device=device)\n",
    "    items = torch.arange(train['proposal'].shift, train['proposal'].end, device=device)\n",
    "    n_users = train['voter'].num_nodes\n",
    "    n_items = train['proposal'].num_nodes\n",
    "\n",
    "    message_passing_edge_index = torch.concat([s.edge_index for s in train.edge_stores], dim=1)\n",
    "\n",
    "    # The official LightGCN usage also uses this line of code (well, for homo graphs)\n",
    "    # - https://github.com/pyg-team/pytorch_geometric/blob/master/examples/lightgcn.py\n",
    "    # In our case, we will use just voter ---> proposal\n",
    "    train_edge_label_index = train['voter', 'votes', 'proposal'].edge_index\n",
    "    assert (train_edge_label_index[0] < train['voter'].end).all()\n",
    "    assert (train['proposal'].shift <= train_edge_label_index[1]).all()\n",
    "\n",
    "    # TODO: Use LinkLoader instead (i don't know how)\n",
    "    # Waiting for pyg-team/pytorch_geometric#7817\n",
    "    # train_loader = PyG.loader.LinkLoader(\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        range(train_edge_label_index.size(1)), # dataset\n",
    "        batch_size=modelConfig.batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _prec_rec(k: int, remove_training=False):\n",
    "        # gt: ground truth\n",
    "        if remove_training:\n",
    "            gt_index = validation['voter', 'votes', 'proposal'].edge_index\n",
    "            exclude_edges = train['voter', 'votes', 'proposal'].edge_index\n",
    "        else:\n",
    "            # All edges\n",
    "            gt_index = original['voter', 'votes', 'proposal'].edge_index\n",
    "            exclude_edges = None\n",
    "\n",
    "        R = item_count = PyG.utils.degree(gt_index[0], num_nodes=n_users)\n",
    "        # topr.size [104, R.max()]\n",
    "        topr = recommend_excluding(model, message_passing_edge_index, src_index=users, dst_index=items, k=int(R.max()), exclude_edges=exclude_edges)\n",
    "        n_samples = len(users)\n",
    "\n",
    "        # [104, 2216]\n",
    "        ground_truth = torch.full((n_users, n_items), False, dtype=torch.bool, device=device)\n",
    "        ground_truth[gt_index[0], gt_index[1] - original['proposal'].shift] = True\n",
    "\n",
    "        isin_rmat = ground_truth.gather(1, topr - original['proposal'].shift)\n",
    "        isin_mat = isin_rmat[:, :k]\n",
    "\n",
    "        prec = (isin_mat.sum(dim=-1) / k).sum() / n_samples\n",
    "        rec = (isin_mat.sum(dim=-1) / item_count).sum() / n_samples\n",
    "\n",
    "        # Now mask isin_rmat to get only up to :R elements\n",
    "        msk = torch.arange(1, R.max()+1, device=device) > R.unsqueeze(1)\n",
    "        isin_rmat[msk] = 0\n",
    "        rprec = (isin_rmat.sum(dim=-1) / R).sum() / n_samples\n",
    "\n",
    "        # print('prec, rec:', (prec, rec))\n",
    "        \n",
    "        return float(prec), float(rec), float(rprec)\n",
    "\n",
    "    for epoch in trange(start_epoch, modelConfig.max_epochs, disable=disable_tqdm):\n",
    "        # index is an array of batch_size that indicates which edges from \n",
    "        # train.edge_index we should use\n",
    "        acc_loss = n_samples = 0        \n",
    "        \n",
    "        for index in tqdm(train_loader, leave=False, delay=1, disable=disable_tqdm):\n",
    "            pos_edge_index = train_edge_label_index[:, index]\n",
    "            # TODO: Change to negative structured sampling like in original LightGCN implementation\n",
    "            neg_edge_index = torch.stack([\n",
    "                pos_edge_index[0],\n",
    "                torch.randint(train['proposal'].shift, train['proposal'].end,\n",
    "                          (pos_edge_index.size(1), ), device=device)\n",
    "            ], dim=0)\n",
    "            \n",
    "            edge_label_index = torch.cat([\n",
    "                pos_edge_index,\n",
    "                neg_edge_index,\n",
    "            ], dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pos_rank, neg_rank = model(message_passing_edge_index, edge_label_index).chunk(2)\n",
    "\n",
    "            # Learning\n",
    "            loss = model.recommendation_loss(\n",
    "                pos_rank,\n",
    "                neg_rank,\n",
    "                node_id=edge_label_index.unique(),\n",
    "                lambda_reg=modelConfig.l2,\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_loss += float(loss) * pos_rank.numel()\n",
    "            n_samples += pos_rank.numel()\n",
    "\n",
    "        checkpoint = Checkpoint.from_dict({\n",
    "            'epoch': epoch,\n",
    "            'net_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        })\n",
    "\n",
    "        prec5, rec5, rprec = _prec_rec(5, remove_training=False)\n",
    "        prec5t, rec5t, rprect = _prec_rec(5, remove_training=True)\n",
    "        session.report({\n",
    "            'loss': acc_loss/n_samples,\n",
    "            'val_loss': np.NaN,\n",
    "            'rprec train': rprec, 'rprec test': rprect,\n",
    "            'p@5 train': prec5, 'p@5 test': prec5t,\n",
    "            'r@5 train': rec5, 'r@5 test': rec5t,\n",
    "        }, checkpoint=checkpoint)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Testing just syntax errors\n",
    "model = train_daostack(graph_folds[0][0].to(device), graph_folds[0][1].to(device), data.to(device), ModelConfig(**(modelConfig._asdict() | {'max_epochs':2})))\n",
    "print(PyG.nn.summary(model, data['voter', 'votes', 'proposal'].edge_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:17.679794Z",
     "iopub.status.busy": "2023-08-17T11:20:17.679688Z",
     "iopub.status.idle": "2023-08-17T11:20:42.115000Z",
     "shell.execute_reply": "2023-08-17T11:20:42.114683Z",
     "shell.execute_reply.started": "2023-08-17T11:20:17.679784Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-17 13:20:42</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:21.64        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.2/15.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc               </th><th style=\"text-align: right;\">  __trial_index__</th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  conv_layers</th><th style=\"text-align: right;\">  embedding_dim</th><th style=\"text-align: right;\">         l2</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  rprec train</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_aux_train_daostack_dc009135</td><td>TERMINATED</td><td>192.168.1.118:9704</td><td style=\"text-align: right;\">                0</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">5.38773e-05</td><td style=\"text-align: right;\">        0.00539</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         8.47714</td><td style=\"text-align: right;\">0.1969  </td><td style=\"text-align: right;\">       nan</td><td style=\"text-align: right;\">     0.458991</td></tr>\n",
       "<tr><td>_aux_train_daostack_21e4a506</td><td>TERMINATED</td><td>192.168.1.118:9735</td><td style=\"text-align: right;\">                1</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">5.38773e-05</td><td style=\"text-align: right;\">        0.00539</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         8.64642</td><td style=\"text-align: right;\">0.211476</td><td style=\"text-align: right;\">       nan</td><td style=\"text-align: right;\">     0.440045</td></tr>\n",
       "<tr><td>_aux_train_daostack_029d93e2</td><td>TERMINATED</td><td>192.168.1.118:9769</td><td style=\"text-align: right;\">                2</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">5.38773e-05</td><td style=\"text-align: right;\">        0.00539</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         9.00618</td><td style=\"text-align: right;\">0.215746</td><td style=\"text-align: right;\">       nan</td><td style=\"text-align: right;\">     0.451619</td></tr>\n",
       "<tr><td>_aux_train_daostack_e876fafc</td><td>TERMINATED</td><td>192.168.1.118:9704</td><td style=\"text-align: right;\">                3</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">5.38773e-05</td><td style=\"text-align: right;\">        0.00539</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         8.81805</td><td style=\"text-align: right;\">0.221384</td><td style=\"text-align: right;\">       nan</td><td style=\"text-align: right;\">     0.430809</td></tr>\n",
       "<tr><td>_aux_train_daostack_303c4985</td><td>TERMINATED</td><td>192.168.1.118:9735</td><td style=\"text-align: right;\">                4</td><td style=\"text-align: right;\">           9</td><td style=\"text-align: right;\">            5</td><td style=\"text-align: right;\">             15</td><td style=\"text-align: right;\">5.38773e-05</td><td style=\"text-align: right;\">        0.00539</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">         8.59413</td><td style=\"text-align: right;\">0.20883 </td><td style=\"text-align: right;\">       nan</td><td style=\"text-align: right;\">     0.437084</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 13:20:42,087\tINFO tune.py:1148 -- Total run time: 21.66 seconds (21.64 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search import Repeater\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "\n",
    "def _aux_train_daostack(config):\n",
    "    # TODO: Is bad practice to pass a dataset trainable\n",
    "    # config['embedding_dim'] = 2**config['embedding_dim']\n",
    "    config['batch_size'] = 2**config['batch_size']\n",
    "    n_fold = config.pop('__trial_index__')\n",
    "    train, validation = graph_folds[n_fold]\n",
    "    train_daostack(train.to(device), validation.to(device), data.to(device), config, disable_tqdm=True)\n",
    "\n",
    "if os.uname().nodename == 'lamarck':\n",
    "    assert torch.cuda.is_available()\n",
    "    \n",
    "    NUM_SAMPLES = 500\n",
    "    # Every run takes approx half a gig of vram (no optimizations)\n",
    "    # The RTX 4090 has 24GB so we can run the model about 48 times\n",
    "    resources_per_trial={\n",
    "        'cpu': 1,\n",
    "        'gpu': 1/32,\n",
    "    }\n",
    "else:\n",
    "    NUM_SAMPLES = 1\n",
    "    resources_per_trial={\n",
    "        'cpu': 2,\n",
    "        'memory': 2e9,\n",
    "    }\n",
    "\n",
    "tryConfigs = ModelConfig(\n",
    "    max_epochs=50,\n",
    "    conv_layers=tune.randint(2,6),\n",
    "    learning_rate=tune.qloguniform(1e-5, 1, 1e-5),\n",
    "    l2=tune.loguniform(1e-9, 1e-1),\n",
    "    # These will be 2 to the power\n",
    "    batch_size=tune.randint(4,10), # 16..1024\n",
    "    # embedding_dim=tune.randint(4,8), # 16..128\n",
    "    embedding_dim=tune.qlograndint(10, 500, 5),\n",
    ")\n",
    "\n",
    "# It is recommended to not use Repeater with a TrialScheduler. Early termination can negatively affect the average reported metric.\n",
    "asha_scheduler = None\n",
    "# asha_scheduler = ASHAScheduler(\n",
    "#     time_attr='training_iteration',\n",
    "#     max_t=50,\n",
    "#     grace_period=5,\n",
    "#     reduction_factor=3,\n",
    "#     brackets=1,\n",
    "# )\n",
    "\n",
    "search_alg = HyperOptSearch()\n",
    "search_alg = Repeater(search_alg,datasetConfig.num_folds)\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    tune.with_resources(_aux_train_daostack, resources_per_trial),\n",
    "    param_space=tryConfigs._asdict(),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        # time_budget_s=60,\n",
    "        num_samples=datasetConfig.num_folds*NUM_SAMPLES,\n",
    "        scheduler=asha_scheduler,\n",
    "        search_alg=search_alg,\n",
    "        metric='rprec test',\n",
    "        mode='max',\n",
    "    )\n",
    ")\n",
    "exp = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:42.115630Z",
     "iopub.status.busy": "2023-08-17T11:20:42.115495Z",
     "iopub.status.idle": "2023-08-17T11:20:42.127677Z",
     "shell.execute_reply": "2023-08-17T11:20:42.127348Z",
     "shell.execute_reply.started": "2023-08-17T11:20:42.115615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>rprec train</th>\n",
       "      <th>rprec test</th>\n",
       "      <th>p@5 train</th>\n",
       "      <th>p@5 test</th>\n",
       "      <th>r@5 train</th>\n",
       "      <th>r@5 test</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>config/__trial_index__</th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/conv_layers</th>\n",
       "      <th>config/embedding_dim</th>\n",
       "      <th>config/l2</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>config/max_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.196900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.458991</td>\n",
       "      <td>0.178784</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.111877</td>\n",
       "      <td>0.129045</td>\n",
       "      <td>0.174819</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8.477139</td>\n",
       "      <td>8.477139</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.215746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.451619</td>\n",
       "      <td>0.186664</td>\n",
       "      <td>0.611538</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.113457</td>\n",
       "      <td>0.125849</td>\n",
       "      <td>0.189713</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>9.006183</td>\n",
       "      <td>9.006183</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440045</td>\n",
       "      <td>0.168371</td>\n",
       "      <td>0.573077</td>\n",
       "      <td>0.207692</td>\n",
       "      <td>0.106057</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8.646419</td>\n",
       "      <td>8.646419</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.208830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437084</td>\n",
       "      <td>0.160207</td>\n",
       "      <td>0.598077</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.108222</td>\n",
       "      <td>0.101691</td>\n",
       "      <td>0.157570</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8.594135</td>\n",
       "      <td>8.594135</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.430809</td>\n",
       "      <td>0.160740</td>\n",
       "      <td>0.580769</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.106999</td>\n",
       "      <td>0.121245</td>\n",
       "      <td>0.164398</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>8.818049</td>\n",
       "      <td>8.818049</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss  rprec train  rprec test  p@5 train  p@5 test  \\\n",
       "0  0.196900       NaN     0.458991    0.178784   0.619231  0.242308   \n",
       "2  0.215746       NaN     0.451619    0.186664   0.611538  0.211538   \n",
       "1  0.211476       NaN     0.440045    0.168371   0.573077  0.207692   \n",
       "4  0.208830       NaN     0.437084    0.160207   0.598077  0.201923   \n",
       "3  0.221384       NaN     0.430809    0.160740   0.580769  0.200000   \n",
       "\n",
       "   r@5 train  r@5 test  time_this_iter_s   done  ...  time_total_s  \\\n",
       "0   0.111877  0.129045          0.174819  False  ...      8.477139   \n",
       "2   0.113457  0.125849          0.189713  False  ...      9.006183   \n",
       "1   0.106057  0.105841          0.182251  False  ...      8.646419   \n",
       "4   0.108222  0.101691          0.157570  False  ...      8.594135   \n",
       "3   0.106999  0.121245          0.164398  False  ...      8.818049   \n",
       "\n",
       "  time_since_restore iterations_since_restore  config/__trial_index__  \\\n",
       "0           8.477139                       50                       0   \n",
       "2           9.006183                       50                       2   \n",
       "1           8.646419                       50                       1   \n",
       "4           8.594135                       50                       4   \n",
       "3           8.818049                       50                       3   \n",
       "\n",
       "   config/batch_size  config/conv_layers  config/embedding_dim  config/l2  \\\n",
       "0                  9                   5                    15   0.000054   \n",
       "2                  9                   5                    15   0.000054   \n",
       "1                  9                   5                    15   0.000054   \n",
       "4                  9                   5                    15   0.000054   \n",
       "3                  9                   5                    15   0.000054   \n",
       "\n",
       "   config/learning_rate  config/max_epochs  \n",
       "0               0.00539                 50  \n",
       "2               0.00539                 50  \n",
       "1               0.00539                 50  \n",
       "4               0.00539                 50  \n",
       "3               0.00539                 50  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df = exp.get_dataframe().drop(columns=['hostname', 'node_ip', 'logdir', 'should_checkpoint', 'pid'])\n",
    "exp_df.sort_values('p@5 test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using all of this\n",
    "\n",
    "Crearé una función que reciba una dirección de un usuario y retorne k propuestas que puedan interesarle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-17T11:20:42.128203Z",
     "iopub.status.busy": "2023-08-17T11:20:42.128096Z",
     "iopub.status.idle": "2023-08-17T11:20:42.372081Z",
     "shell.execute_reply": "2023-08-17T11:20:42.371604Z",
     "shell.execute_reply.started": "2023-08-17T11:20:42.128193Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_user' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m proposals\n\u001b[1;32m     32\u001b[0m user \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0x334f12afb7d8740868be04719639616533075234\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# vpu[(12 < vpu) & (vpu < 38)].sample().index[0]\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreatedAt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserVoted\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m, in \u001b[0;36mrecommend\u001b[0;34m(user, K, ignore_train)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend\u001b[39m(user: \u001b[38;5;28mstr\u001b[39m, K: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, ignore_train: \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     uid \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_user\u001b[49m\u001b[38;5;241m.\u001b[39mtransform([user])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommending \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mK\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m proposals for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (uid:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvpu\u001b[38;5;241m.\u001b[39mat[user]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m votes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Getting embedding\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_user' is not defined"
     ]
    }
   ],
   "source": [
    "def recommend(user: str, K: int = 12, ignore_train: bool=False):\n",
    "    uid = encoder_user.transform([user])[0]\n",
    "    print(f\"Recommending {K} proposals for user {user} (uid:{uid}) with {vpu.at[user]} votes\")\n",
    "    \n",
    "    # Getting embedding\n",
    "    out = model(edge_index)\n",
    "    user_embed, item_embed = torch.split(out, (model.n_users, model.n_items))\n",
    "    relevance_score = torch.matmul(user_embed, torch.transpose(item_embed, 0, 1))\n",
    "    if ignore_train:\n",
    "        i = torch.stack([\n",
    "            torch.LongTensor(train_df['uid'].values),\n",
    "            torch.LongTensor(train_df['pid'].values),\n",
    "        ])\n",
    "        v = torch.ones(len(train_df), dtype=torch.float64)\n",
    "        t_interactions = torch.sparse.FloatTensor(i, v, (model.n_users, model.n_items)).to_dense().to(device)\n",
    "        # mask out training user-item interactions from metric computation\n",
    "        # We are only interested in novel items, as a user won't be interested\n",
    "        # in \"voting again\"\n",
    "        relevance_score = torch.mul(relevance_score, (1 - t_interactions))\n",
    "    \n",
    "    topk_relevance_indices = torch.topk(relevance_score, K).indices\n",
    "    \n",
    "    pids = topk_relevance_indices[uid].tolist()\n",
    "    proposals = dfp.loc[encoder_prop.inverse_transform(pids)]\n",
    "    \n",
    "    proposals['userVoted'] = dfv.groupby('proposal')['voter'].apply(lambda x: user in set(x))\n",
    "    \n",
    "    print(f\"precision@{K}={sum(proposals['userVoted'])/len(proposals)*100:.2f}%\")\n",
    "    \n",
    "    return proposals\n",
    "\n",
    "user = \"0x334f12afb7d8740868be04719639616533075234\" # vpu[(12 < vpu) & (vpu < 38)].sample().index[0]\n",
    "recommend(user, ignore_train=True)[['network', 'createdAt', 'title', 'description', 'userVoted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-08-17T11:20:42.372486Z",
     "iopub.status.idle": "2023-08-17T11:20:42.372642Z",
     "shell.execute_reply": "2023-08-17T11:20:42.372577Z",
     "shell.execute_reply.started": "2023-08-17T11:20:42.372569Z"
    }
   },
   "outputs": [],
   "source": [
    "dfv[dfv['proposal'] == '0xb92d2df99a47244c07a9d7ef73530c273f1d65230dbff9e95873d82c0314534e']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00bebd801d7441d7889394b21d1906dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0554c55ce11c4686afcf8baee8cd7967": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_838562afd56d436dbc2db31482f3bbb0",
       "max": 2,
       "style": "IPY_MODEL_29121a7dfb694b23ad7129bd038b3d95",
       "value": 2
      }
     },
     "1e3b01c23dc744fe9e9a4e95b4403ff1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "29121a7dfb694b23ad7129bd038b3d95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2afb324c0efa499d9995f16fd39e8d1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_daf86056255e49a99a0030196305bb37",
       "max": 104,
       "style": "IPY_MODEL_46d2f2f317c94d76968b270746985d3c",
       "value": 104
      }
     },
     "3e3fa974b63440b59a405c022f241efc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4e5702c1dcd94cd2b2a538922d28f686",
       "style": "IPY_MODEL_d0e2df2b8ba74158809406754ea30870",
       "value": " 0/104 [00:00&lt;?, ?it/s]"
      }
     },
     "46480a87509e4ce58f597c0cf3e665c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "46d2f2f317c94d76968b270746985d3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4e5702c1dcd94cd2b2a538922d28f686": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "62aef40f0ee24bf79e858fa57dd841d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_9ec2620211994200872692b305e3638b",
       "max": 104,
       "style": "IPY_MODEL_00bebd801d7441d7889394b21d1906dd",
       "value": 104
      }
     },
     "801d213a34ca4e25b4a1cce7343340b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_fdbe44a7a8d24c2980458f66ec4f45ab",
       "style": "IPY_MODEL_ce4c4cde9f4a4ed58bd7f5cc5355f37d",
       "value": " 2/2 [00:01&lt;00:00,  2.01it/s]"
      }
     },
     "8100043e48d8476e9242e66d7fd4861f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "visibility": "hidden"
      }
     },
     "838562afd56d436dbc2db31482f3bbb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "84db51825dba42288cd64779fc81709d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e82434b7d95243f4935efd190bb8dbbb",
       "style": "IPY_MODEL_8dff5c2eb8b6496d85fd0f1380576988",
       "value": " 0/104 [00:00&lt;?, ?it/s]"
      }
     },
     "8dff5c2eb8b6496d85fd0f1380576988": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9cdba4d4b32b4125840fafe305ae1018": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "visibility": "hidden"
      }
     },
     "9eaa5aaf00e04b25bd83fc37340b7855": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f2d5806a1950474697c170c2c26630df",
       "style": "IPY_MODEL_46480a87509e4ce58f597c0cf3e665c1",
       "value": "  0%"
      }
     },
     "9ec2620211994200872692b305e3638b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a3289a5e46a2415ea112e801222e9bb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e4b129cb0f7a4a1caf106dde3a0f072e",
       "style": "IPY_MODEL_fbe4a428af6844598068ef8191888cc8",
       "value": "  0%"
      }
     },
     "bec93918368240a2836c62c97e8076b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce4c4cde9f4a4ed58bd7f5cc5355f37d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cf0237cde32f43bab132799746863766": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d0e2df2b8ba74158809406754ea30870": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "daf86056255e49a99a0030196305bb37": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e4b129cb0f7a4a1caf106dde3a0f072e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e82434b7d95243f4935efd190bb8dbbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f2d5806a1950474697c170c2c26630df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f2e902f5b85442b4ab8dd080ba80fe79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_cf0237cde32f43bab132799746863766",
       "style": "IPY_MODEL_1e3b01c23dc744fe9e9a4e95b4403ff1",
       "value": "100%"
      }
     },
     "f64944b306dc469280d14327798d23f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f2e902f5b85442b4ab8dd080ba80fe79",
        "IPY_MODEL_0554c55ce11c4686afcf8baee8cd7967",
        "IPY_MODEL_801d213a34ca4e25b4a1cce7343340b8"
       ],
       "layout": "IPY_MODEL_bec93918368240a2836c62c97e8076b8"
      }
     },
     "fbe4a428af6844598068ef8191888cc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fdbe44a7a8d24c2980458f66ec4f45ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
