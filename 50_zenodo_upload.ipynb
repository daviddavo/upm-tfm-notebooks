{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c5488a-4f6b-4a0f-95ef-3d1d19c6c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4906c653-70d6-4a99-a90d-c9a0b4683514",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZENODO_SANDBOX = False\n",
    "\n",
    "ZENODO_NOMODELS_ID = \"11072579\"\n",
    "ZENODO_MODELS_ID = \"11116984\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c416a061-b95e-4b4b-a5ce-8452ae0f45bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_results_path = Path(\"~/ray_results\").expanduser()\n",
    "assert ray_results_path.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281da0d7-9086-4dca-84c4-5564f13f33c6",
   "metadata": {},
   "source": [
    "# Upload results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb286e7-50c3-438d-a936-76fea3386a1c",
   "metadata": {},
   "source": [
    "## Select files to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda1711e-7ffe-429d-8445-d4ffde104318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GB: 24.8716683909297 files: 32229\n"
     ]
    }
   ],
   "source": [
    "def get_files_nomodel():\n",
    "    total = 0\n",
    "    all_paths = []\n",
    "    for f in ray_results_path.rglob('*'):\n",
    "        if not f.is_file() or f.name.startswith('model.data'):\n",
    "            continue\n",
    "        \n",
    "        total += f.stat().st_size\n",
    "        all_paths.append(f)\n",
    "\n",
    "    return total, all_paths\n",
    "\n",
    "total, all_paths = get_files_nomodel()\n",
    "print(\"Total GB:\", total / 2**30, \"files:\", len(all_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824e9ac4-170d-4e10-aa92-27ea0f6465c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('ray_results/LightGCN_optim=map@10,dao=DEAD FoundationsDAO,freq=2d,normalize=True,cutoff_date=2021-11-28T00:00:00,fold=0_2024-03-21T22:11:14.136280/.validate_storage_marker')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths[0].relative_to(Path('~').expanduser())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e47a5d-e95f-4839-8b1f-6aa77ccaa094",
   "metadata": {},
   "source": [
    "## Create tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ffcd768-37b0-4360-882a-c8b513285b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2945/1387312145.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5857b946-2347-4ff2-8a54-ce4dcac274af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6840aaf830742c9aa41b4c9013f2fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 24.8716683909297G, New size: 2.085955971851945G, ratio: 8.39%\n"
     ]
    }
   ],
   "source": [
    "def compress_files(tar_fname, compress, flist):\n",
    "    if tar_fname.exists():\n",
    "        try:\n",
    "            with tarfile.open(tar_fname, f'r:*') as tar:\n",
    "                if len(tar.getnames()) == len(flist):\n",
    "                    print(\"Same length, not removing\", len(tar.getnames()), len(flist))\n",
    "                    return\n",
    "                else:\n",
    "                    print(\"Removing old file\")\n",
    "                    tar_fname.unlink()\n",
    "        except:\n",
    "            tar_fname.unlink()\n",
    "    \n",
    "    original_size = 0\n",
    "    original_total = sum(f.stat().st_size for f in flist)\n",
    "    with tarfile.open(tar_fname, f'x:{compress}') as tar:\n",
    "        with tqdm(total=len(flist)) as pbar:\n",
    "            for i, f in enumerate(flist):\n",
    "                original_size += f.stat().st_size\n",
    "                tar.add(f, recursive=False, arcname=f.relative_to(Path('~').expanduser()))\n",
    "                pbar.update()\n",
    "    \n",
    "                if i % 5 == 0 and i > 1:\n",
    "                    final_size = tar_fname.stat().st_size\n",
    "                    ratio = final_size / original_size\n",
    "                    pbar.set_postfix({\n",
    "                        'ratio': f'{ratio*100:.2f}%',\n",
    "                        'original': f'{original_size / 2**30:.2f}G',\n",
    "                        'actual': f'{final_size / 2**30:.2f}G',\n",
    "                        'est.': f'{ratio*original_total / 2**30:.2f}G',\n",
    "                    })\n",
    "\n",
    "    print(f\"Original size: {original_size/ 2**30}G, New size: {final_size / 2**30}G, ratio: {final_size / original_size*100:.2f}%\")\n",
    "\n",
    "\n",
    "compress_files(Path(\"ray_results_nomodels.tar.xz\"), \"xz\", all_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f00384-67e5-45c9-8256-18d1b2bba3f6",
   "metadata": {},
   "source": [
    "## Upload to Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7dcc99-2f29-435c-a88f-0c3ba3d1b4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3ba771d323dc8c5b9a285eeab8b3731c'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def big_hash(fname):\n",
    "    with open(fname, \"rb\") as f:\n",
    "        file_hash = hashlib.md5()\n",
    "        while chunk := f.read(8192):\n",
    "            file_hash.update(chunk)\n",
    "    \n",
    "    return file_hash.hexdigest()\n",
    "\n",
    "big_hash(\"ray_results_nomodels.tar.xz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6470c65-2be8-4aed-ba45-e3abe04a1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping already uploaded file ray_results_nomodels.tar.xz with hash 3ba771d323dc8c5b9a285eeab8b3731c\n",
      "Remember to publish https://zenodo.org/api/deposit/depositions/11072579\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterable, Union\n",
    "\n",
    "import io\n",
    "\n",
    "import hashlib\n",
    "import requests\n",
    "import backoff\n",
    "from zenodo_client import Zenodo\n",
    "\n",
    "# https://stackoverflow.com/a/64423275/4505998\n",
    "class UploadChunksIterator(Iterable):\n",
    "    \"\"\"\n",
    "    This is an interface between python requests and tqdm.\n",
    "    Make tqdm to be accessed just like IOBase for requests lib.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, file: io.BufferedReader, total_size: int, chunk_size: int = 16 * 1024\n",
    "    ):  # 16MiB\n",
    "        self.file = file\n",
    "        self.chunk_size = chunk_size\n",
    "        self.total_size = total_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        data = self.file.read(self.chunk_size)\n",
    "        if not data:\n",
    "            raise StopIteration\n",
    "        return data\n",
    "\n",
    "    # we dont retrive len from io.BufferedReader because CallbackIOWrapper only has read() method.\n",
    "    def __len__(self):\n",
    "        return self.total_size\n",
    "\n",
    "class ZenodoPlus(Zenodo):\n",
    "    def _upload_big_files(self, *, bucket: str, paths, done=[]) -> List[requests.Response]:\n",
    "        _paths = [paths] if isinstance(paths, (str, Path)) else paths\n",
    "        _paths = [ Path(p) for p in _paths]\n",
    "        _done_dict = { f['filename'] : f for f in done }\n",
    "    \n",
    "        rv = []\n",
    "        # see https://developers.zenodo.org/#quickstart-upload\n",
    "        for path in _paths:\n",
    "            total_size = path.stat().st_size\n",
    "            \n",
    "            if path.name in _done_dict:\n",
    "                _info = _done_dict[path.name]\n",
    "                skip = False\n",
    "                md5sum = big_hash(path)\n",
    "                \n",
    "                if _info['filesize'] == total_size and _info['checksum'] == md5sum:\n",
    "                    print(\"Skipping already uploaded file\", path, \"with hash\", md5sum)\n",
    "                    continue\n",
    "\n",
    "                raise\n",
    "                if skip: continue\n",
    "\n",
    "            with open(path, \"rb\") as file:\n",
    "                file = tqdm.wrapattr(\n",
    "                    file, \n",
    "                    \"read\",\n",
    "                    miniters=1, \n",
    "                    total=total_size, \n",
    "                    unit='B',\n",
    "                    unit_scale=True,\n",
    "                    unit_divisor=1024,\n",
    "                )\n",
    "\n",
    "                with file as f:\n",
    "                    res = requests.put(\n",
    "                        f\"{bucket}/{path.name}\",\n",
    "                        data=UploadChunksIterator(f, total_size),\n",
    "                        params={\"access_token\": self.access_token},\n",
    "                        # headers={'Content-Type': m.content_type},\n",
    "                    )\n",
    "\n",
    "            res.raise_for_status()\n",
    "            rv.append(res)\n",
    "        return rv\n",
    "    \n",
    "    def upload_to_record(self, deposition_id: str, paths):\n",
    "        url = f\"{self.depositions_base}/{deposition_id}\"\n",
    "        res = requests.get(url, params={\"access_token\": self.access_token})\n",
    "        res.raise_for_status()\n",
    "\n",
    "        deposition_data = res.json()\n",
    "\n",
    "        bucket = deposition_data['links']['bucket']\n",
    "        self._upload_big_files(bucket=bucket, paths=paths, done=deposition_data['files'])\n",
    "\n",
    "Z = ZenodoPlus(sandbox=ZENODO_SANDBOX)\n",
    "Z.upload_to_record(ZENODO_NOMODELS_ID, [\"ray_results_nomodels.tar.xz\"])\n",
    "print(f\"Remember to publish {Z.depositions_base}/{ZENODO_NOMODELS_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43072d7b-376e-4a4d-a62d-656190871207",
   "metadata": {},
   "source": [
    "# Upload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51fb05b4-6275-4ce3-81e1-414f78f26f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GB: 62.57409965991974 files: 4000\n"
     ]
    }
   ],
   "source": [
    "def get_files_model():\n",
    "    total = 0\n",
    "    all_paths = []\n",
    "    for f in ray_results_path.rglob('*'):\n",
    "        if not f.is_file() or not f.name.startswith('model.data'):\n",
    "            continue\n",
    "        \n",
    "        total += f.stat().st_size\n",
    "        all_paths.append(f)\n",
    "\n",
    "    return total, all_paths\n",
    "\n",
    "total, model_paths = get_files_model()\n",
    "print(\"Total GB:\", total / 2**30, \"files:\", len(model_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771fb086-f20f-4373-9a08-8db95c46edfa",
   "metadata": {},
   "source": [
    "### Won't do it because it takes too much space. It's 48 GiB compressed as xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcfcd80b-77a7-4f59-9482-4fbd35238bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same length, not removing 4000 4000\n"
     ]
    }
   ],
   "source": [
    "# compress_files(Path(\"ray_results_models.tar.xz\"), \"xz\", model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ae3023c-d985-475f-adf4-94c9a2e03f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac1ee68bc5846e4924962b740fb6704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/47.9G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: BAD REQUEST for url: https://zenodo.org/api/files/abe5a128-6c67-4ae7-95e1-33b457033480/ray_results_models.tar.xz?access_token=S759O8lbNaha4LkEi0mAu5OiCL0QcPsWVRPE8TL3xsj0JSbFeN58NXPBIQLu",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mZ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_to_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZENODO_MODELS_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mray_results_models.tar.xz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemember to publish \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mZ\u001b[38;5;241m.\u001b[39mdepositions_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mZENODO_MODELS_ID\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 90\u001b[0m, in \u001b[0;36mZenodoPlus.upload_to_record\u001b[0;34m(self, deposition_id, paths)\u001b[0m\n\u001b[1;32m     87\u001b[0m deposition_data \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     89\u001b[0m bucket \u001b[38;5;241m=\u001b[39m deposition_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbucket\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_big_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeposition_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 78\u001b[0m, in \u001b[0;36mZenodoPlus._upload_big_files\u001b[0;34m(self, bucket, paths, done)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m file \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     71\u001b[0m             res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mput(\n\u001b[1;32m     72\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbucket\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     73\u001b[0m                 data\u001b[38;5;241m=\u001b[39mUploadChunksIterator(f, total_size),\n\u001b[1;32m     74\u001b[0m                 params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccess_token\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccess_token},\n\u001b[1;32m     75\u001b[0m                 \u001b[38;5;66;03m# headers={'Content-Type': m.content_type},\u001b[39;00m\n\u001b[1;32m     76\u001b[0m             )\n\u001b[0;32m---> 78\u001b[0m     \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     rv\u001b[38;5;241m.\u001b[39mappend(res)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "File \u001b[0;32m~/upm-tfm-notebooks/.direnv/python-3.9/lib/python3.9/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: BAD REQUEST for url: https://zenodo.org/api/files/abe5a128-6c67-4ae7-95e1-33b457033480/ray_results_models.tar.xz?access_token=S759O8lbNaha4LkEi0mAu5OiCL0QcPsWVRPE8TL3xsj0JSbFeN58NXPBIQLu"
     ]
    }
   ],
   "source": [
    "# Z.upload_to_record(ZENODO_MODELS_ID, [\"ray_results_models.tar.xz\"])\n",
    "# print(f\"Remember to publish {Z.depositions_base}/{ZENODO_MODELS_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16636e5-08c6-4dce-b605-fcad04ed0c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0997529ae8a442adbc57d6b06f3cf910": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "103c35f31a3147a7bba5ebeb9913ad4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "312bb62027a84a64a97270867274fe4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_ec3f69fdefe141f38d8ea073cfe1d481",
       "max": 32229,
       "style": "IPY_MODEL_0997529ae8a442adbc57d6b06f3cf910",
       "value": 32229
      }
     },
     "31e938ea0044410b99d40529809c97f2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "36c5bc69cf08425fa3db69e5901d9e16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3dc25e587883442da6d3b592876e2df2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_103c35f31a3147a7bba5ebeb9913ad4f",
       "style": "IPY_MODEL_7ad892c5b5da4560b3e8a7e71c90120e",
       "value": " 32229/32229 [1:17:31&lt;00:00, 132.20it/s, ratio=8.39%, original=24.87G, actual=2.09G, est.=2.09G]"
      }
     },
     "5dcce93db77344969a921f5007d13dd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_759678d2b5a84494bc11bb367afc9671",
       "style": "IPY_MODEL_94c77169e2ae4441be1c408c57ca3594",
       "value": "  1%"
      }
     },
     "6045e3e432dd4b3c9362ec6065f1dfad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "622076d82c384bc1a0a7be19c5e6f127": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6a48ea0a31044d1f930da18549bca6ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e0a1c326b8664e55908227691bbc5784",
       "style": "IPY_MODEL_7b63bcdc707a4fb782528f96a9292c06",
       "value": " 339M/47.9G [00:29&lt;1:11:05, 12.0MB/s]"
      }
     },
     "6ac1ee68bc5846e4924962b740fb6704": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5dcce93db77344969a921f5007d13dd5",
        "IPY_MODEL_7e198cf4244c4302b099e8ac15995366",
        "IPY_MODEL_6a48ea0a31044d1f930da18549bca6ef"
       ],
       "layout": "IPY_MODEL_31e938ea0044410b99d40529809c97f2"
      }
     },
     "759678d2b5a84494bc11bb367afc9671": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7ad892c5b5da4560b3e8a7e71c90120e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7b63bcdc707a4fb782528f96a9292c06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7e198cf4244c4302b099e8ac15995366": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "danger",
       "layout": "IPY_MODEL_f4cc164c0e8045199d538bd66b226b04",
       "max": 51450768120,
       "style": "IPY_MODEL_622076d82c384bc1a0a7be19c5e6f127",
       "value": 355778560
      }
     },
     "94c77169e2ae4441be1c408c57ca3594": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9da1551351fd4be68a1b09e91942b550": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cd0b9395d7e646d48a458bb1e8a16cb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_36c5bc69cf08425fa3db69e5901d9e16",
       "style": "IPY_MODEL_9da1551351fd4be68a1b09e91942b550",
       "value": "100%"
      }
     },
     "e0a1c326b8664e55908227691bbc5784": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec3f69fdefe141f38d8ea073cfe1d481": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4cc164c0e8045199d538bd66b226b04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f6840aaf830742c9aa41b4c9013f2fbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cd0b9395d7e646d48a458bb1e8a16cb0",
        "IPY_MODEL_312bb62027a84a64a97270867274fe4c",
        "IPY_MODEL_3dc25e587883442da6d3b592876e2df2"
       ],
       "layout": "IPY_MODEL_6045e3e432dd4b3c9362ec6065f1dfad"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
