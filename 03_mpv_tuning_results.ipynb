{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8ba0eb-f442-4507-8155-d693d0eec309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868ad4b4-7c92-4f26-ad15-cf83e0a139c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from /home/daviddavo/ray_results/_aux_train_daostack_2023-08-17_14-24-39...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 15:50:14,443\tINFO experiment_analysis.py:972 -- No trial data passed in during `ExperimentAnalysis` initialization -- you are most likely loading the experiment after it has completed.\n",
      "Loading trial data from the experiment checkpoint file. This may result in loading some stale information, since checkpointing is periodic.\n",
      "2023-08-17 15:50:17,653\tWARNING experiment_analysis.py:916 -- Failed to read the results for 1 trials:\n",
      "- /home/daviddavo/ray_results/_aux_train_daostack_2023-08-17_14-24-39/_aux_train_daostack_7a9516a0_745_trial_index=4,batch_size=4,conv_layers=3,embedding_dim=80,l2=0.0000,learning_rate=0.0012,max_epoc_2023-08-17_15-49-14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'loss': 0.10872686423784196, 'val_loss': 0.8530769944190979, 'rprec train': 0.7320367097854614, 'rprec test': 0.22052255272865295, 'p@5 train': 0.8942307829856873, 'p@5 test': 0.248076930642128, 'r@5 train': 0.21720772981643677, 'r@5 test': 0.15670859813690186, 'should_checkpoint': True, 'done': True, 'trial_id': '066d560f', 'experiment_tag': '241_trial_index=0,batch_size=4,conv_layers=3,embedding_dim=105,l2=0.0000,learning_rate=0.0017,max_epochs=50'},\n",
       "  path='/home/daviddavo/ray_results/_aux_train_daostack_2023-08-17_14-24-39/_aux_train_daostack_066d560f_241_trial_index=0,batch_size=4,conv_layers=3,embedding_dim=105,l2=0.0000,learning_rate=0.0017,max_epo_2023-08-17_14-50-59',\n",
       "  checkpoint=Checkpoint(local_path=/home/daviddavo/ray_results/_aux_train_daostack_2023-08-17_14-24-39/_aux_train_daostack_066d560f_241_trial_index=0,batch_size=4,conv_layers=3,embedding_dim=105,l2=0.0000,learning_rate=0.0017,max_epo_2023-08-17_14-50-59/checkpoint_000049)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray_results = Path(\"~/ray_results\").expanduser()\n",
    "assert ray_results.is_dir()\n",
    "last_experiment = max(ray_results.glob('_aux_train_daostack_*'), key=lambda x: x.stat().st_ctime)\n",
    "print(f\"Loading results from {last_experiment}...\")\n",
    "assert last_experiment.is_dir()\n",
    "\n",
    "def _aux_train_daostack(*args, **kwargs):\n",
    "    raise NotImplementedError\n",
    "\n",
    "# TODO: Create an experiment grid or whatever is called\n",
    "tuner = tune.Tuner.restore(str(last_experiment), _aux_train_daostack)\n",
    "rg = tuner.get_results()\n",
    "rg.get_best_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cbeaf2-c8ff-4afa-b1bc-887d58143984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 15:50:21,513\tWARNING experiment_analysis.py:694 -- Failed to read the config for 1 trials:\n",
      "- /home/daviddavo/ray_results/_aux_train_daostack_2023-08-17_14-24-39/_aux_train_daostack_7a9516a0_745_trial_index=4,batch_size=4,conv_layers=3,embedding_dim=80,l2=0.0000,learning_rate=0.0012,max_epoc_2023-08-17_15-49-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loss', 'val_loss', 'rprec train', 'rprec test', 'p@5 train',\n",
      "       'p@5 test', 'r@5 train', 'r@5 test', 'time_this_iter_s',\n",
      "       'should_checkpoint', 'done', 'training_iteration', 'trial_id',\n",
      "       'time_total_s', 'config/__trial_index__', 'config/batch_size',\n",
      "       'config/conv_layers', 'config/embedding_dim', 'config/l2',\n",
      "       'config/learning_rate', 'config/max_epochs'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>rprec train</th>\n",
       "      <th>rprec test</th>\n",
       "      <th>p@5 train</th>\n",
       "      <th>p@5 test</th>\n",
       "      <th>r@5 train</th>\n",
       "      <th>r@5 test</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>...</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>config/__trial_index__</th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/conv_layers</th>\n",
       "      <th>config/embedding_dim</th>\n",
       "      <th>config/l2</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>config/max_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.102057</td>\n",
       "      <td>0.852359</td>\n",
       "      <td>0.754251</td>\n",
       "      <td>0.213974</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.135020</td>\n",
       "      <td>0.489816</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>a80077e6</td>\n",
       "      <td>25.089469</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>1.873735e-09</td>\n",
       "      <td>0.01014</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.106146</td>\n",
       "      <td>0.857666</td>\n",
       "      <td>0.695261</td>\n",
       "      <td>0.204977</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.255769</td>\n",
       "      <td>0.202373</td>\n",
       "      <td>0.139001</td>\n",
       "      <td>3.155101</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>6d9e28b3</td>\n",
       "      <td>153.993793</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>3.167378e-08</td>\n",
       "      <td>0.00469</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.106258</td>\n",
       "      <td>0.913202</td>\n",
       "      <td>0.701287</td>\n",
       "      <td>0.203587</td>\n",
       "      <td>0.873077</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>0.215629</td>\n",
       "      <td>0.155976</td>\n",
       "      <td>2.810326</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>539cae6c</td>\n",
       "      <td>136.346081</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>4.646772e-06</td>\n",
       "      <td>0.00253</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.106943</td>\n",
       "      <td>0.856024</td>\n",
       "      <td>0.775790</td>\n",
       "      <td>0.210333</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.229748</td>\n",
       "      <td>0.142838</td>\n",
       "      <td>4.060142</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>c48cc275</td>\n",
       "      <td>187.852929</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>435</td>\n",
       "      <td>5.457861e-05</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.107736</td>\n",
       "      <td>0.863567</td>\n",
       "      <td>0.722021</td>\n",
       "      <td>0.203510</td>\n",
       "      <td>0.894231</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.220726</td>\n",
       "      <td>0.121135</td>\n",
       "      <td>3.462508</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>0b1a4784</td>\n",
       "      <td>197.281092</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>345</td>\n",
       "      <td>1.670515e-05</td>\n",
       "      <td>0.00163</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  val_loss  rprec train  rprec test  p@5 train  p@5 test  \\\n",
       "471  0.102057  0.852359     0.754251    0.213974   0.900000  0.240385   \n",
       "331  0.106146  0.857666     0.695261    0.204977   0.861538  0.255769   \n",
       "259  0.106258  0.913202     0.701287    0.203587   0.873077  0.259615   \n",
       "561  0.106943  0.856024     0.775790    0.210333   0.923077  0.242308   \n",
       "29   0.107736  0.863567     0.722021    0.203510   0.894231  0.223077   \n",
       "\n",
       "     r@5 train  r@5 test  time_this_iter_s  should_checkpoint  ...  \\\n",
       "471   0.218218  0.135020          0.489816               True  ...   \n",
       "331   0.202373  0.139001          3.155101               True  ...   \n",
       "259   0.215629  0.155976          2.810326               True  ...   \n",
       "561   0.229748  0.142838          4.060142               True  ...   \n",
       "29    0.220726  0.121135          3.462508               True  ...   \n",
       "\n",
       "     training_iteration  trial_id time_total_s  config/__trial_index__  \\\n",
       "471                  50  a80077e6    25.089469                       0   \n",
       "331                  50  6d9e28b3   153.993793                       0   \n",
       "259                  50  539cae6c   136.346081                       2   \n",
       "561                  47  c48cc275   187.852929                       0   \n",
       "29                   48  0b1a4784   197.281092                       1   \n",
       "\n",
       "     config/batch_size  config/conv_layers  config/embedding_dim  \\\n",
       "471                256                   2                    65   \n",
       "331                 32                   5                    55   \n",
       "259                 64                   5                   175   \n",
       "561                 32                   5                   435   \n",
       "29                  32                   5                   345   \n",
       "\n",
       "        config/l2  config/learning_rate  config/max_epochs  \n",
       "471  1.873735e-09               0.01014                 50  \n",
       "331  3.167378e-08               0.00469                 50  \n",
       "259  4.646772e-06               0.00253                 50  \n",
       "561  5.457861e-05               0.00295                 50  \n",
       "29   1.670515e-05               0.00163                 50  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe and drop some unneeded columns\n",
    "rdf = rg.get_dataframe('rprec test', 'max').drop(columns=['timestamp', 'node_ip', 'pid', 'hostname', 'time_since_restore', 'iterations_since_restore', 'logdir'])\n",
    "rdf = rdf.drop(columns=['date'])\n",
    "# rdf = rdf[rdf['done']]\n",
    "print(rdf.columns)\n",
    "\n",
    "for c in ['config/batch_size']: #, 'config/embedding_dim']:\n",
    "    rdf[c] = 2**rdf[c]\n",
    "\n",
    "rdf.sort_values('loss').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8852a2e8-82c4-40a3-8ffb-a4b6baaffcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 configurations were tested\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/conv_layers</th>\n",
       "      <th>config/embedding_dim</th>\n",
       "      <th>config/l2</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>rprec train</th>\n",
       "      <th>rprec test</th>\n",
       "      <th>p@5 train</th>\n",
       "      <th>p@5 test</th>\n",
       "      <th>r@5 train</th>\n",
       "      <th>r@5 test</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>time_total_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>8.390419e-04</td>\n",
       "      <td>0.01003</td>\n",
       "      <td>0.170990</td>\n",
       "      <td>0.763743</td>\n",
       "      <td>0.736409</td>\n",
       "      <td>0.216214</td>\n",
       "      <td>0.908462</td>\n",
       "      <td>0.239231</td>\n",
       "      <td>0.229216</td>\n",
       "      <td>0.156154</td>\n",
       "      <td>2.436677</td>\n",
       "      <td>30.0</td>\n",
       "      <td>73.652825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>1.031174e-05</td>\n",
       "      <td>0.00174</td>\n",
       "      <td>0.116141</td>\n",
       "      <td>0.848857</td>\n",
       "      <td>0.694024</td>\n",
       "      <td>0.211434</td>\n",
       "      <td>0.856538</td>\n",
       "      <td>0.245769</td>\n",
       "      <td>0.205194</td>\n",
       "      <td>0.149718</td>\n",
       "      <td>5.971010</td>\n",
       "      <td>35.6</td>\n",
       "      <td>242.533603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>1.364939e-04</td>\n",
       "      <td>0.00158</td>\n",
       "      <td>0.122078</td>\n",
       "      <td>0.784717</td>\n",
       "      <td>0.720510</td>\n",
       "      <td>0.209439</td>\n",
       "      <td>0.885385</td>\n",
       "      <td>0.251154</td>\n",
       "      <td>0.216106</td>\n",
       "      <td>0.152304</td>\n",
       "      <td>5.332652</td>\n",
       "      <td>45.2</td>\n",
       "      <td>213.626645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>315</td>\n",
       "      <td>4.807041e-04</td>\n",
       "      <td>0.00227</td>\n",
       "      <td>0.134665</td>\n",
       "      <td>0.752983</td>\n",
       "      <td>0.702888</td>\n",
       "      <td>0.209063</td>\n",
       "      <td>0.872308</td>\n",
       "      <td>0.247692</td>\n",
       "      <td>0.212053</td>\n",
       "      <td>0.143924</td>\n",
       "      <td>1.935120</td>\n",
       "      <td>39.4</td>\n",
       "      <td>75.684666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>4.876183e-07</td>\n",
       "      <td>0.00852</td>\n",
       "      <td>0.129401</td>\n",
       "      <td>0.855096</td>\n",
       "      <td>0.738879</td>\n",
       "      <td>0.208211</td>\n",
       "      <td>0.911154</td>\n",
       "      <td>0.237308</td>\n",
       "      <td>0.228557</td>\n",
       "      <td>0.147229</td>\n",
       "      <td>2.015847</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.924756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>345</td>\n",
       "      <td>1.670515e-05</td>\n",
       "      <td>0.00163</td>\n",
       "      <td>0.113829</td>\n",
       "      <td>0.830618</td>\n",
       "      <td>0.701002</td>\n",
       "      <td>0.207112</td>\n",
       "      <td>0.870769</td>\n",
       "      <td>0.242308</td>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.144016</td>\n",
       "      <td>3.951857</td>\n",
       "      <td>41.6</td>\n",
       "      <td>172.038790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>2.453462e-05</td>\n",
       "      <td>0.00522</td>\n",
       "      <td>0.117889</td>\n",
       "      <td>0.793560</td>\n",
       "      <td>0.664615</td>\n",
       "      <td>0.206489</td>\n",
       "      <td>0.832308</td>\n",
       "      <td>0.237308</td>\n",
       "      <td>0.193931</td>\n",
       "      <td>0.142587</td>\n",
       "      <td>1.968628</td>\n",
       "      <td>40.4</td>\n",
       "      <td>80.954232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>2.802851e-09</td>\n",
       "      <td>0.00351</td>\n",
       "      <td>0.124993</td>\n",
       "      <td>0.826314</td>\n",
       "      <td>0.621461</td>\n",
       "      <td>0.205680</td>\n",
       "      <td>0.783846</td>\n",
       "      <td>0.236154</td>\n",
       "      <td>0.176188</td>\n",
       "      <td>0.141547</td>\n",
       "      <td>3.220001</td>\n",
       "      <td>42.4</td>\n",
       "      <td>140.656338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>4.646772e-06</td>\n",
       "      <td>0.00253</td>\n",
       "      <td>0.120075</td>\n",
       "      <td>0.818807</td>\n",
       "      <td>0.655931</td>\n",
       "      <td>0.205539</td>\n",
       "      <td>0.830385</td>\n",
       "      <td>0.247692</td>\n",
       "      <td>0.192844</td>\n",
       "      <td>0.147237</td>\n",
       "      <td>2.681880</td>\n",
       "      <td>41.6</td>\n",
       "      <td>113.474665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>3.167378e-08</td>\n",
       "      <td>0.00469</td>\n",
       "      <td>0.118592</td>\n",
       "      <td>0.821016</td>\n",
       "      <td>0.661145</td>\n",
       "      <td>0.205145</td>\n",
       "      <td>0.827692</td>\n",
       "      <td>0.241538</td>\n",
       "      <td>0.194213</td>\n",
       "      <td>0.143571</td>\n",
       "      <td>3.084360</td>\n",
       "      <td>37.2</td>\n",
       "      <td>114.276741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>2.342827e-03</td>\n",
       "      <td>0.00375</td>\n",
       "      <td>0.183066</td>\n",
       "      <td>0.730290</td>\n",
       "      <td>0.716524</td>\n",
       "      <td>0.205108</td>\n",
       "      <td>0.885385</td>\n",
       "      <td>0.236923</td>\n",
       "      <td>0.217516</td>\n",
       "      <td>0.143662</td>\n",
       "      <td>2.055616</td>\n",
       "      <td>32.0</td>\n",
       "      <td>65.366575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1.155399e-09</td>\n",
       "      <td>0.01773</td>\n",
       "      <td>0.124816</td>\n",
       "      <td>0.772577</td>\n",
       "      <td>0.648180</td>\n",
       "      <td>0.203976</td>\n",
       "      <td>0.813462</td>\n",
       "      <td>0.230385</td>\n",
       "      <td>0.186950</td>\n",
       "      <td>0.138238</td>\n",
       "      <td>0.510658</td>\n",
       "      <td>33.6</td>\n",
       "      <td>17.209127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>2.579641e-07</td>\n",
       "      <td>0.00214</td>\n",
       "      <td>0.121191</td>\n",
       "      <td>0.793678</td>\n",
       "      <td>0.638332</td>\n",
       "      <td>0.203213</td>\n",
       "      <td>0.807308</td>\n",
       "      <td>0.231538</td>\n",
       "      <td>0.185729</td>\n",
       "      <td>0.135284</td>\n",
       "      <td>2.001990</td>\n",
       "      <td>42.2</td>\n",
       "      <td>82.765383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>185</td>\n",
       "      <td>1.256228e-05</td>\n",
       "      <td>0.00180</td>\n",
       "      <td>0.118435</td>\n",
       "      <td>0.806032</td>\n",
       "      <td>0.642750</td>\n",
       "      <td>0.203204</td>\n",
       "      <td>0.808846</td>\n",
       "      <td>0.245385</td>\n",
       "      <td>0.185294</td>\n",
       "      <td>0.139489</td>\n",
       "      <td>1.772338</td>\n",
       "      <td>41.2</td>\n",
       "      <td>73.527767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1.642465e-07</td>\n",
       "      <td>0.00590</td>\n",
       "      <td>0.125964</td>\n",
       "      <td>0.818921</td>\n",
       "      <td>0.607245</td>\n",
       "      <td>0.203153</td>\n",
       "      <td>0.781538</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.175375</td>\n",
       "      <td>0.135376</td>\n",
       "      <td>2.088751</td>\n",
       "      <td>39.8</td>\n",
       "      <td>84.215046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>465</td>\n",
       "      <td>6.063329e-05</td>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.784218</td>\n",
       "      <td>0.678730</td>\n",
       "      <td>0.203082</td>\n",
       "      <td>0.847692</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.199746</td>\n",
       "      <td>0.135109</td>\n",
       "      <td>5.134592</td>\n",
       "      <td>39.6</td>\n",
       "      <td>211.299286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>1.873735e-09</td>\n",
       "      <td>0.01014</td>\n",
       "      <td>0.115724</td>\n",
       "      <td>0.793876</td>\n",
       "      <td>0.727697</td>\n",
       "      <td>0.202651</td>\n",
       "      <td>0.883462</td>\n",
       "      <td>0.233462</td>\n",
       "      <td>0.213393</td>\n",
       "      <td>0.138652</td>\n",
       "      <td>0.489817</td>\n",
       "      <td>36.8</td>\n",
       "      <td>18.369195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>4.441680e-05</td>\n",
       "      <td>0.00307</td>\n",
       "      <td>0.120025</td>\n",
       "      <td>0.862288</td>\n",
       "      <td>0.685055</td>\n",
       "      <td>0.202645</td>\n",
       "      <td>0.853462</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.201701</td>\n",
       "      <td>0.141153</td>\n",
       "      <td>7.114729</td>\n",
       "      <td>40.8</td>\n",
       "      <td>286.255365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>435</td>\n",
       "      <td>5.457861e-05</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.131083</td>\n",
       "      <td>0.800380</td>\n",
       "      <td>0.688564</td>\n",
       "      <td>0.202086</td>\n",
       "      <td>0.856923</td>\n",
       "      <td>0.236538</td>\n",
       "      <td>0.205647</td>\n",
       "      <td>0.139217</td>\n",
       "      <td>4.014992</td>\n",
       "      <td>23.8</td>\n",
       "      <td>95.094156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>1.491382e-06</td>\n",
       "      <td>0.00415</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>0.759266</td>\n",
       "      <td>0.201743</td>\n",
       "      <td>0.921154</td>\n",
       "      <td>0.233462</td>\n",
       "      <td>0.232158</td>\n",
       "      <td>0.144041</td>\n",
       "      <td>6.383916</td>\n",
       "      <td>30.2</td>\n",
       "      <td>185.113676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>1.653899e-09</td>\n",
       "      <td>0.01934</td>\n",
       "      <td>0.128798</td>\n",
       "      <td>0.826571</td>\n",
       "      <td>0.745632</td>\n",
       "      <td>0.201666</td>\n",
       "      <td>0.920769</td>\n",
       "      <td>0.225385</td>\n",
       "      <td>0.230524</td>\n",
       "      <td>0.138162</td>\n",
       "      <td>0.297844</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.359369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>7.152255e-09</td>\n",
       "      <td>0.00435</td>\n",
       "      <td>0.116631</td>\n",
       "      <td>0.851236</td>\n",
       "      <td>0.695523</td>\n",
       "      <td>0.201441</td>\n",
       "      <td>0.855385</td>\n",
       "      <td>0.236154</td>\n",
       "      <td>0.203438</td>\n",
       "      <td>0.144012</td>\n",
       "      <td>5.927702</td>\n",
       "      <td>37.2</td>\n",
       "      <td>222.041884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>7.766765e-05</td>\n",
       "      <td>0.00561</td>\n",
       "      <td>0.127541</td>\n",
       "      <td>0.808849</td>\n",
       "      <td>0.696235</td>\n",
       "      <td>0.201191</td>\n",
       "      <td>0.861923</td>\n",
       "      <td>0.240769</td>\n",
       "      <td>0.207282</td>\n",
       "      <td>0.139047</td>\n",
       "      <td>1.770937</td>\n",
       "      <td>36.8</td>\n",
       "      <td>64.502758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>4.094975e-04</td>\n",
       "      <td>0.01349</td>\n",
       "      <td>0.154395</td>\n",
       "      <td>0.860774</td>\n",
       "      <td>0.749595</td>\n",
       "      <td>0.201083</td>\n",
       "      <td>0.917692</td>\n",
       "      <td>0.222308</td>\n",
       "      <td>0.232875</td>\n",
       "      <td>0.148176</td>\n",
       "      <td>2.838867</td>\n",
       "      <td>33.0</td>\n",
       "      <td>97.671027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>385</td>\n",
       "      <td>1.762222e-03</td>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.169495</td>\n",
       "      <td>0.700013</td>\n",
       "      <td>0.643068</td>\n",
       "      <td>0.200921</td>\n",
       "      <td>0.809615</td>\n",
       "      <td>0.236923</td>\n",
       "      <td>0.191394</td>\n",
       "      <td>0.136369</td>\n",
       "      <td>6.803618</td>\n",
       "      <td>41.6</td>\n",
       "      <td>292.113171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>7.940730e-04</td>\n",
       "      <td>0.00391</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0.739689</td>\n",
       "      <td>0.644500</td>\n",
       "      <td>0.200670</td>\n",
       "      <td>0.818462</td>\n",
       "      <td>0.227692</td>\n",
       "      <td>0.189262</td>\n",
       "      <td>0.135806</td>\n",
       "      <td>2.777759</td>\n",
       "      <td>39.2</td>\n",
       "      <td>108.994836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>9.551605e-05</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.120954</td>\n",
       "      <td>0.783932</td>\n",
       "      <td>0.640073</td>\n",
       "      <td>0.200455</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.233077</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.134221</td>\n",
       "      <td>3.373393</td>\n",
       "      <td>43.8</td>\n",
       "      <td>139.880611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1.399437e-04</td>\n",
       "      <td>0.01241</td>\n",
       "      <td>0.126386</td>\n",
       "      <td>0.805096</td>\n",
       "      <td>0.669130</td>\n",
       "      <td>0.200072</td>\n",
       "      <td>0.825385</td>\n",
       "      <td>0.235769</td>\n",
       "      <td>0.192997</td>\n",
       "      <td>0.140681</td>\n",
       "      <td>0.873510</td>\n",
       "      <td>34.6</td>\n",
       "      <td>30.422725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>1.079114e-02</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.287991</td>\n",
       "      <td>0.655620</td>\n",
       "      <td>0.615471</td>\n",
       "      <td>0.199965</td>\n",
       "      <td>0.790769</td>\n",
       "      <td>0.215769</td>\n",
       "      <td>0.182664</td>\n",
       "      <td>0.144080</td>\n",
       "      <td>1.727136</td>\n",
       "      <td>19.4</td>\n",
       "      <td>33.326038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>1.584207e-05</td>\n",
       "      <td>0.00681</td>\n",
       "      <td>0.125958</td>\n",
       "      <td>0.820383</td>\n",
       "      <td>0.703559</td>\n",
       "      <td>0.199718</td>\n",
       "      <td>0.867308</td>\n",
       "      <td>0.229615</td>\n",
       "      <td>0.211282</td>\n",
       "      <td>0.140061</td>\n",
       "      <td>7.083873</td>\n",
       "      <td>29.6</td>\n",
       "      <td>206.721655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     config/batch_size  config/conv_layers  config/embedding_dim  \\\n",
       "101                 64                   4                   200   \n",
       "14                  16                   3                   105   \n",
       "77                  32                   5                   460   \n",
       "103                 64                   4                   315   \n",
       "112                 64                   5                   200   \n",
       "73                  32                   5                   345   \n",
       "95                  64                   4                    50   \n",
       "66                  32                   5                    45   \n",
       "109                 64                   5                   175   \n",
       "68                  32                   5                    55   \n",
       "91                  64                   3                   500   \n",
       "142                256                   4                    25   \n",
       "87                  64                   3                    90   \n",
       "100                 64                   4                   185   \n",
       "104                 64                   5                    30   \n",
       "78                  32                   5                   465   \n",
       "134                256                   2                    65   \n",
       "32                  16                   5                    60   \n",
       "75                  32                   5                   435   \n",
       "12                  16                   3                    90   \n",
       "145                512                   2                   125   \n",
       "19                  16                   4                    30   \n",
       "86                  64                   3                    75   \n",
       "51                  32                   3                    40   \n",
       "17                  16                   3                   385   \n",
       "49                  32                   3                    30   \n",
       "54                  32                   3                    60   \n",
       "114                128                   3                    25   \n",
       "81                  64                   2                   260   \n",
       "30                  16                   5                    40   \n",
       "\n",
       "        config/l2  config/learning_rate      loss  val_loss  rprec train  \\\n",
       "101  8.390419e-04               0.01003  0.170990  0.763743     0.736409   \n",
       "14   1.031174e-05               0.00174  0.116141  0.848857     0.694024   \n",
       "77   1.364939e-04               0.00158  0.122078  0.784717     0.720510   \n",
       "103  4.807041e-04               0.00227  0.134665  0.752983     0.702888   \n",
       "112  4.876183e-07               0.00852  0.129401  0.855096     0.738879   \n",
       "73   1.670515e-05               0.00163  0.113829  0.830618     0.701002   \n",
       "95   2.453462e-05               0.00522  0.117889  0.793560     0.664615   \n",
       "66   2.802851e-09               0.00351  0.124993  0.826314     0.621461   \n",
       "109  4.646772e-06               0.00253  0.120075  0.818807     0.655931   \n",
       "68   3.167378e-08               0.00469  0.118592  0.821016     0.661145   \n",
       "91   2.342827e-03               0.00375  0.183066  0.730290     0.716524   \n",
       "142  1.155399e-09               0.01773  0.124816  0.772577     0.648180   \n",
       "87   2.579641e-07               0.00214  0.121191  0.793678     0.638332   \n",
       "100  1.256228e-05               0.00180  0.118435  0.806032     0.642750   \n",
       "104  1.642465e-07               0.00590  0.125964  0.818921     0.607245   \n",
       "78   6.063329e-05               0.00128  0.127273  0.784218     0.678730   \n",
       "134  1.873735e-09               0.01014  0.115724  0.793876     0.727697   \n",
       "32   4.441680e-05               0.00307  0.120025  0.862288     0.685055   \n",
       "75   5.457861e-05               0.00295  0.131083  0.800380     0.688564   \n",
       "12   1.491382e-06               0.00415  0.121978  0.890455     0.759266   \n",
       "145  1.653899e-09               0.01934  0.128798  0.826571     0.745632   \n",
       "19   7.152255e-09               0.00435  0.116631  0.851236     0.695523   \n",
       "86   7.766765e-05               0.00561  0.127541  0.808849     0.696235   \n",
       "51   4.094975e-04               0.01349  0.154395  0.860774     0.749595   \n",
       "17   1.762222e-03               0.00056  0.169495  0.700013     0.643068   \n",
       "49   7.940730e-04               0.00391  0.144414  0.739689     0.644500   \n",
       "54   9.551605e-05               0.00203  0.120954  0.783932     0.640073   \n",
       "114  1.399437e-04               0.01241  0.126386  0.805096     0.669130   \n",
       "81   1.079114e-02               0.00528  0.287991  0.655620     0.615471   \n",
       "30   1.584207e-05               0.00681  0.125958  0.820383     0.703559   \n",
       "\n",
       "     rprec test  p@5 train  p@5 test  r@5 train  r@5 test  time_this_iter_s  \\\n",
       "101    0.216214   0.908462  0.239231   0.229216  0.156154          2.436677   \n",
       "14     0.211434   0.856538  0.245769   0.205194  0.149718          5.971010   \n",
       "77     0.209439   0.885385  0.251154   0.216106  0.152304          5.332652   \n",
       "103    0.209063   0.872308  0.247692   0.212053  0.143924          1.935120   \n",
       "112    0.208211   0.911154  0.237308   0.228557  0.147229          2.015847   \n",
       "73     0.207112   0.870769  0.242308   0.209120  0.144016          3.951857   \n",
       "95     0.206489   0.832308  0.237308   0.193931  0.142587          1.968628   \n",
       "66     0.205680   0.783846  0.236154   0.176188  0.141547          3.220001   \n",
       "109    0.205539   0.830385  0.247692   0.192844  0.147237          2.681880   \n",
       "68     0.205145   0.827692  0.241538   0.194213  0.143571          3.084360   \n",
       "91     0.205108   0.885385  0.236923   0.217516  0.143662          2.055616   \n",
       "142    0.203976   0.813462  0.230385   0.186950  0.138238          0.510658   \n",
       "87     0.203213   0.807308  0.231538   0.185729  0.135284          2.001990   \n",
       "100    0.203204   0.808846  0.245385   0.185294  0.139489          1.772338   \n",
       "104    0.203153   0.781538  0.230000   0.175375  0.135376          2.088751   \n",
       "78     0.203082   0.847692  0.240385   0.199746  0.135109          5.134592   \n",
       "134    0.202651   0.883462  0.233462   0.213393  0.138652          0.489817   \n",
       "32     0.202645   0.853462  0.246154   0.201701  0.141153          7.114729   \n",
       "75     0.202086   0.856923  0.236538   0.205647  0.139217          4.014992   \n",
       "12     0.201743   0.921154  0.233462   0.232158  0.144041          6.383916   \n",
       "145    0.201666   0.920769  0.225385   0.230524  0.138162          0.297844   \n",
       "19     0.201441   0.855385  0.236154   0.203438  0.144012          5.927702   \n",
       "86     0.201191   0.861923  0.240769   0.207282  0.139047          1.770937   \n",
       "51     0.201083   0.917692  0.222308   0.232875  0.148176          2.838867   \n",
       "17     0.200921   0.809615  0.236923   0.191394  0.136369          6.803618   \n",
       "49     0.200670   0.818462  0.227692   0.189262  0.135806          2.777759   \n",
       "54     0.200455   0.820000  0.233077   0.186400  0.134221          3.373393   \n",
       "114    0.200072   0.825385  0.235769   0.192997  0.140681          0.873510   \n",
       "81     0.199965   0.790769  0.215769   0.182664  0.144080          1.727136   \n",
       "30     0.199718   0.867308  0.229615   0.211282  0.140061          7.083873   \n",
       "\n",
       "     training_iteration  time_total_s  \n",
       "101                30.0     73.652825  \n",
       "14                 35.6    242.533603  \n",
       "77                 45.2    213.626645  \n",
       "103                39.4     75.684666  \n",
       "112                25.0     48.924756  \n",
       "73                 41.6    172.038790  \n",
       "95                 40.4     80.954232  \n",
       "66                 42.4    140.656338  \n",
       "109                41.6    113.474665  \n",
       "68                 37.2    114.276741  \n",
       "91                 32.0     65.366575  \n",
       "142                33.6     17.209127  \n",
       "87                 42.2     82.765383  \n",
       "100                41.2     73.527767  \n",
       "104                39.8     84.215046  \n",
       "78                 39.6    211.299286  \n",
       "134                36.8     18.369195  \n",
       "32                 40.8    286.255365  \n",
       "75                 23.8     95.094156  \n",
       "12                 30.2    185.113676  \n",
       "145                21.0      6.359369  \n",
       "19                 37.2    222.041884  \n",
       "86                 36.8     64.502758  \n",
       "51                 33.0     97.671027  \n",
       "17                 41.6    292.113171  \n",
       "49                 39.2    108.994836  \n",
       "54                 43.8    139.880611  \n",
       "114                34.6     30.422725  \n",
       "81                 19.4     33.326038  \n",
       "30                 29.6    206.721655  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by config (except trial index) and do the mean\n",
    "non_config_columns = ['config/__trial_index__', 'config/max_epochs']\n",
    "cfg_columns = [c for c in rdf.columns if c.startswith('config/') and c not in non_config_columns]\n",
    "non_results_cols = ['should_checkpoint', 'done', 'config/__trial_index__'] + non_config_columns\n",
    "rdfgb = rdf.drop(columns=non_results_cols).groupby(cfg_columns).mean(numeric_only=True).reset_index()\n",
    "print(len(rdfgb), \"configurations were tested\")\n",
    "rdfgb.sort_values('rprec test', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fcca96-c12d-4322-8373-b64c084a9ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
