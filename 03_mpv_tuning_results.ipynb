{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8ba0eb-f442-4507-8155-d693d0eec309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868ad4b4-7c92-4f26-ad15-cf83e0a139c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results from /home/daviddavo/ray_results/_aux_train_daostack_2023-08-04_18-10-33...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-05 14:44:10,796\tINFO experiment_analysis.py:972 -- No trial data passed in during `ExperimentAnalysis` initialization -- you are most likely loading the experiment after it has completed.\n",
      "Loading trial data from the experiment checkpoint file. This may result in loading some stale information, since checkpointing is periodic.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(\n",
       "  metrics={'loss': 0.36464700296949626, 'rprec train': 0.4460618197917938, 'rprec test': 0.24987199902534485, 'p@5 train': 0.576923131942749, 'p@5 test': 0.5173077583312988, 'r@5 train': 0.11515726894140244, 'r@5 test': 0.11842279136180878, 'should_checkpoint': True, 'done': True, 'trial_id': '7d17313d', 'experiment_tag': '1420_trial_index=4,batch_size=9,conv_layers=4,embedding_dim=255,l2=0.0000,learning_rate=0.9984,max_epochs=50'},\n",
       "  path='/home/daviddavo/ray_results/_aux_train_daostack_2023-08-04_18-10-33/_aux_train_daostack_7d17313d_1420_trial_index=4,batch_size=9,conv_layers=4,embedding_dim=255,l2=0.0000,learning_rate=0.9984,max_ep_2023-08-04_18-56-00',\n",
       "  checkpoint=Checkpoint(local_path=/home/daviddavo/ray_results/_aux_train_daostack_2023-08-04_18-10-33/_aux_train_daostack_7d17313d_1420_trial_index=4,batch_size=9,conv_layers=4,embedding_dim=255,l2=0.0000,learning_rate=0.9984,max_ep_2023-08-04_18-56-00/checkpoint_000049)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray_results = Path(\"~/ray_results\").expanduser()\n",
    "assert ray_results.is_dir()\n",
    "last_experiment = max(ray_results.glob('_aux_train_daostack_*'), key=lambda x: x.stat().st_ctime)\n",
    "print(f\"Loading results from {last_experiment}...\")\n",
    "assert last_experiment.is_dir()\n",
    "\n",
    "def _aux_train_daostack(*args, **kwargs):\n",
    "    raise NotImplementedError\n",
    "\n",
    "# TODO: Create an experiment grid or whatever is called\n",
    "tuner = tune.Tuner.restore(str(last_experiment), _aux_train_daostack)\n",
    "rg = tuner.get_results()\n",
    "rg.get_best_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cbeaf2-c8ff-4afa-b1bc-887d58143984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loss', 'rprec train', 'rprec test', 'p@5 train', 'p@5 test',\n",
      "       'r@5 train', 'r@5 test', 'time_this_iter_s', 'should_checkpoint',\n",
      "       'done', 'training_iteration', 'trial_id', 'time_total_s',\n",
      "       'config/__trial_index__', 'config/batch_size', 'config/conv_layers',\n",
      "       'config/embedding_dim', 'config/l2', 'config/learning_rate',\n",
      "       'config/max_epochs'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>rprec train</th>\n",
       "      <th>rprec test</th>\n",
       "      <th>p@5 train</th>\n",
       "      <th>p@5 test</th>\n",
       "      <th>r@5 train</th>\n",
       "      <th>r@5 test</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>should_checkpoint</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>config/__trial_index__</th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/conv_layers</th>\n",
       "      <th>config/embedding_dim</th>\n",
       "      <th>config/l2</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>config/max_epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.341698</td>\n",
       "      <td>0.187381</td>\n",
       "      <td>0.428846</td>\n",
       "      <td>0.359615</td>\n",
       "      <td>0.063187</td>\n",
       "      <td>0.057253</td>\n",
       "      <td>0.242601</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>48</td>\n",
       "      <td>72ce5191</td>\n",
       "      <td>11.779700</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>1.008631e-09</td>\n",
       "      <td>0.09383</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.333034</td>\n",
       "      <td>0.188084</td>\n",
       "      <td>0.467308</td>\n",
       "      <td>0.328846</td>\n",
       "      <td>0.070219</td>\n",
       "      <td>0.055709</td>\n",
       "      <td>0.244043</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>3012a977</td>\n",
       "      <td>9.830602</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>1.008631e-09</td>\n",
       "      <td>0.09383</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.322663</td>\n",
       "      <td>0.136328</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>0.226923</td>\n",
       "      <td>0.062413</td>\n",
       "      <td>0.025628</td>\n",
       "      <td>3.742894</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>093824ed</td>\n",
       "      <td>153.019838</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>395</td>\n",
       "      <td>2.291114e-09</td>\n",
       "      <td>0.02109</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.341493</td>\n",
       "      <td>0.178222</td>\n",
       "      <td>0.463462</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.068529</td>\n",
       "      <td>0.052727</td>\n",
       "      <td>0.272583</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "      <td>ad73e657</td>\n",
       "      <td>6.189987</td>\n",
       "      <td>4</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>1.316051e-09</td>\n",
       "      <td>0.09943</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.339063</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.294231</td>\n",
       "      <td>0.079739</td>\n",
       "      <td>0.049389</td>\n",
       "      <td>0.420175</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "      <td>c10393ca</td>\n",
       "      <td>17.130680</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>320</td>\n",
       "      <td>1.322222e-09</td>\n",
       "      <td>0.20245</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          loss  rprec train  rprec test  p@5 train  p@5 test  r@5 train  \\\n",
       "1084  0.000002     0.341698    0.187381   0.428846  0.359615   0.063187   \n",
       "474   0.000003     0.333034    0.188084   0.467308  0.328846   0.070219   \n",
       "108   0.000003     0.322663    0.136328   0.451923  0.226923   0.062413   \n",
       "1688  0.000005     0.341493    0.178222   0.463462  0.346154   0.068529   \n",
       "1884  0.000005     0.339063    0.172414   0.480769  0.294231   0.079739   \n",
       "\n",
       "      r@5 test  time_this_iter_s  should_checkpoint   done  \\\n",
       "1084  0.057253          0.242601               True  False   \n",
       "474   0.055709          0.244043               True  False   \n",
       "108   0.025628          3.742894               True  False   \n",
       "1688  0.052727          0.272583               True  False   \n",
       "1884  0.049389          0.420175               True  False   \n",
       "\n",
       "      training_iteration  trial_id  time_total_s  config/__trial_index__  \\\n",
       "1084                  48  72ce5191     11.779700                       1   \n",
       "474                   40  3012a977      9.830602                       3   \n",
       "108                   40  093824ed    153.019838                       1   \n",
       "1688                  22  ad73e657      6.189987                       4   \n",
       "1884                  49  c10393ca     17.130680                       1   \n",
       "\n",
       "      config/batch_size  config/conv_layers  config/embedding_dim  \\\n",
       "1084                512                   2                   225   \n",
       "474                 512                   2                   225   \n",
       "108                  32                   4                   395   \n",
       "1688                512                   2                   225   \n",
       "1884                512                   5                   320   \n",
       "\n",
       "         config/l2  config/learning_rate  config/max_epochs  \n",
       "1084  1.008631e-09               0.09383                 50  \n",
       "474   1.008631e-09               0.09383                 50  \n",
       "108   2.291114e-09               0.02109                 50  \n",
       "1688  1.316051e-09               0.09943                 50  \n",
       "1884  1.322222e-09               0.20245                 50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe and drop some unneeded columns\n",
    "rdf = rg.get_dataframe('p@5 test', 'max').drop(columns=['timestamp', 'node_ip', 'pid', 'hostname', 'time_since_restore', 'iterations_since_restore', 'logdir'])\n",
    "rdf = rdf.drop(columns=['date'])\n",
    "# rdf = rdf[rdf['done']]\n",
    "print(rdf.columns)\n",
    "\n",
    "for c in ['config/batch_size']: #, 'config/embedding_dim']:\n",
    "    rdf[c] = 2**rdf[c]\n",
    "\n",
    "rdf.sort_values('loss').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8852a2e8-82c4-40a3-8ffb-a4b6baaffcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 configurations were tested\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config/batch_size</th>\n",
       "      <th>config/conv_layers</th>\n",
       "      <th>config/embedding_dim</th>\n",
       "      <th>config/l2</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>rprec train</th>\n",
       "      <th>rprec test</th>\n",
       "      <th>p@5 train</th>\n",
       "      <th>p@5 test</th>\n",
       "      <th>r@5 train</th>\n",
       "      <th>r@5 test</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>time_total_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>245</td>\n",
       "      <td>9.914827e-07</td>\n",
       "      <td>0.00964</td>\n",
       "      <td>0.241608</td>\n",
       "      <td>0.242316</td>\n",
       "      <td>0.098725</td>\n",
       "      <td>0.341538</td>\n",
       "      <td>0.165769</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.015395</td>\n",
       "      <td>2.053089</td>\n",
       "      <td>16.6</td>\n",
       "      <td>34.066409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>405</td>\n",
       "      <td>1.584187e-07</td>\n",
       "      <td>0.00185</td>\n",
       "      <td>0.150563</td>\n",
       "      <td>0.224705</td>\n",
       "      <td>0.093210</td>\n",
       "      <td>0.328077</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.036903</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.627006</td>\n",
       "      <td>25.6</td>\n",
       "      <td>16.211258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>445</td>\n",
       "      <td>1.732332e-09</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>0.307133</td>\n",
       "      <td>0.216381</td>\n",
       "      <td>0.096421</td>\n",
       "      <td>0.321154</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.036596</td>\n",
       "      <td>0.017662</td>\n",
       "      <td>0.396081</td>\n",
       "      <td>27.2</td>\n",
       "      <td>9.514649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>3.840663e-09</td>\n",
       "      <td>0.00847</td>\n",
       "      <td>0.194887</td>\n",
       "      <td>0.217179</td>\n",
       "      <td>0.092560</td>\n",
       "      <td>0.317692</td>\n",
       "      <td>0.164615</td>\n",
       "      <td>0.036657</td>\n",
       "      <td>0.015135</td>\n",
       "      <td>0.265311</td>\n",
       "      <td>26.6</td>\n",
       "      <td>6.984504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>225</td>\n",
       "      <td>2.105721e-08</td>\n",
       "      <td>0.00231</td>\n",
       "      <td>0.213107</td>\n",
       "      <td>0.216814</td>\n",
       "      <td>0.096675</td>\n",
       "      <td>0.318462</td>\n",
       "      <td>0.164615</td>\n",
       "      <td>0.035424</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.309438</td>\n",
       "      <td>31.2</td>\n",
       "      <td>9.989760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2.496945e-08</td>\n",
       "      <td>0.12938</td>\n",
       "      <td>0.256727</td>\n",
       "      <td>0.218319</td>\n",
       "      <td>0.099074</td>\n",
       "      <td>0.317308</td>\n",
       "      <td>0.164231</td>\n",
       "      <td>0.039383</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>0.363311</td>\n",
       "      <td>11.2</td>\n",
       "      <td>3.916391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>9.521968e-02</td>\n",
       "      <td>0.80491</td>\n",
       "      <td>2.358417</td>\n",
       "      <td>0.251073</td>\n",
       "      <td>0.085161</td>\n",
       "      <td>0.354615</td>\n",
       "      <td>0.161923</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.014133</td>\n",
       "      <td>0.265382</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.819533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>1.846316e-04</td>\n",
       "      <td>0.00185</td>\n",
       "      <td>0.243835</td>\n",
       "      <td>0.220650</td>\n",
       "      <td>0.083026</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.160769</td>\n",
       "      <td>0.037476</td>\n",
       "      <td>0.012908</td>\n",
       "      <td>0.714866</td>\n",
       "      <td>23.8</td>\n",
       "      <td>16.914875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>225</td>\n",
       "      <td>2.069621e-02</td>\n",
       "      <td>0.13739</td>\n",
       "      <td>1.253451</td>\n",
       "      <td>0.239358</td>\n",
       "      <td>0.088685</td>\n",
       "      <td>0.351538</td>\n",
       "      <td>0.159615</td>\n",
       "      <td>0.041451</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>2.469692</td>\n",
       "      <td>11.8</td>\n",
       "      <td>28.320639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>215</td>\n",
       "      <td>1.265913e-07</td>\n",
       "      <td>0.00361</td>\n",
       "      <td>0.150869</td>\n",
       "      <td>0.225793</td>\n",
       "      <td>0.094648</td>\n",
       "      <td>0.327308</td>\n",
       "      <td>0.159615</td>\n",
       "      <td>0.037542</td>\n",
       "      <td>0.013152</td>\n",
       "      <td>0.577506</td>\n",
       "      <td>24.2</td>\n",
       "      <td>13.803180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "      <td>5.209855e-02</td>\n",
       "      <td>0.28983</td>\n",
       "      <td>1.404204</td>\n",
       "      <td>0.244688</td>\n",
       "      <td>0.085539</td>\n",
       "      <td>0.355385</td>\n",
       "      <td>0.159231</td>\n",
       "      <td>0.042308</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>0.353688</td>\n",
       "      <td>14.2</td>\n",
       "      <td>4.455094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>8.924661e-05</td>\n",
       "      <td>0.00112</td>\n",
       "      <td>0.401994</td>\n",
       "      <td>0.205940</td>\n",
       "      <td>0.083761</td>\n",
       "      <td>0.305769</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.035289</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0.452694</td>\n",
       "      <td>20.8</td>\n",
       "      <td>9.239584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "      <td>1.144952e-06</td>\n",
       "      <td>0.00315</td>\n",
       "      <td>0.201066</td>\n",
       "      <td>0.227312</td>\n",
       "      <td>0.090389</td>\n",
       "      <td>0.331538</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>3.430244</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.350618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>90</td>\n",
       "      <td>2.773413e-09</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.188959</td>\n",
       "      <td>0.218169</td>\n",
       "      <td>0.087084</td>\n",
       "      <td>0.318462</td>\n",
       "      <td>0.157692</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.013890</td>\n",
       "      <td>0.063025</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.634636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3.783898e-06</td>\n",
       "      <td>0.01277</td>\n",
       "      <td>0.275304</td>\n",
       "      <td>0.203899</td>\n",
       "      <td>0.086429</td>\n",
       "      <td>0.313462</td>\n",
       "      <td>0.157308</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>0.307873</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.192668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>9.868599e-02</td>\n",
       "      <td>0.72275</td>\n",
       "      <td>3.597202</td>\n",
       "      <td>0.233445</td>\n",
       "      <td>0.086079</td>\n",
       "      <td>0.333462</td>\n",
       "      <td>0.156538</td>\n",
       "      <td>0.040025</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.227958</td>\n",
       "      <td>37.2</td>\n",
       "      <td>8.677094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3.329143e-08</td>\n",
       "      <td>0.03786</td>\n",
       "      <td>0.271823</td>\n",
       "      <td>0.207538</td>\n",
       "      <td>0.088003</td>\n",
       "      <td>0.306154</td>\n",
       "      <td>0.156154</td>\n",
       "      <td>0.035161</td>\n",
       "      <td>0.015226</td>\n",
       "      <td>0.603040</td>\n",
       "      <td>14.8</td>\n",
       "      <td>8.952818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8.116358e-09</td>\n",
       "      <td>0.04283</td>\n",
       "      <td>0.132487</td>\n",
       "      <td>0.221923</td>\n",
       "      <td>0.095260</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.155769</td>\n",
       "      <td>0.038489</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>0.593711</td>\n",
       "      <td>14.8</td>\n",
       "      <td>9.016412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>175</td>\n",
       "      <td>7.011937e-08</td>\n",
       "      <td>0.00611</td>\n",
       "      <td>0.162733</td>\n",
       "      <td>0.240478</td>\n",
       "      <td>0.094577</td>\n",
       "      <td>0.342308</td>\n",
       "      <td>0.155769</td>\n",
       "      <td>0.039229</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>3.938676</td>\n",
       "      <td>20.2</td>\n",
       "      <td>78.494808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8.466347e-05</td>\n",
       "      <td>0.10148</td>\n",
       "      <td>0.147650</td>\n",
       "      <td>0.226350</td>\n",
       "      <td>0.095357</td>\n",
       "      <td>0.328846</td>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.036225</td>\n",
       "      <td>0.013977</td>\n",
       "      <td>0.467893</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.331862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>1.321830e-09</td>\n",
       "      <td>0.00231</td>\n",
       "      <td>0.211680</td>\n",
       "      <td>0.213735</td>\n",
       "      <td>0.090666</td>\n",
       "      <td>0.312308</td>\n",
       "      <td>0.152692</td>\n",
       "      <td>0.034603</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.565687</td>\n",
       "      <td>30.4</td>\n",
       "      <td>16.872417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2.025833e-06</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.691975</td>\n",
       "      <td>0.202245</td>\n",
       "      <td>0.079024</td>\n",
       "      <td>0.300385</td>\n",
       "      <td>0.151923</td>\n",
       "      <td>0.034870</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>1.060080</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.502945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>1.288639e-09</td>\n",
       "      <td>0.03147</td>\n",
       "      <td>0.174413</td>\n",
       "      <td>0.219360</td>\n",
       "      <td>0.093065</td>\n",
       "      <td>0.324615</td>\n",
       "      <td>0.149231</td>\n",
       "      <td>0.039325</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>0.670415</td>\n",
       "      <td>24.6</td>\n",
       "      <td>15.154624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>1.720917e-08</td>\n",
       "      <td>0.00270</td>\n",
       "      <td>0.153714</td>\n",
       "      <td>0.232933</td>\n",
       "      <td>0.089252</td>\n",
       "      <td>0.337692</td>\n",
       "      <td>0.149231</td>\n",
       "      <td>0.038205</td>\n",
       "      <td>0.012728</td>\n",
       "      <td>1.759004</td>\n",
       "      <td>16.0</td>\n",
       "      <td>25.424808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>9.125593e-06</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.295068</td>\n",
       "      <td>0.211359</td>\n",
       "      <td>0.078748</td>\n",
       "      <td>0.315769</td>\n",
       "      <td>0.148462</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>6.924939</td>\n",
       "      <td>24.4</td>\n",
       "      <td>168.654531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>2.745393e-02</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.534142</td>\n",
       "      <td>0.194085</td>\n",
       "      <td>0.077654</td>\n",
       "      <td>0.297308</td>\n",
       "      <td>0.148462</td>\n",
       "      <td>0.034289</td>\n",
       "      <td>0.016381</td>\n",
       "      <td>5.989740</td>\n",
       "      <td>20.6</td>\n",
       "      <td>132.784690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>5.710999e-09</td>\n",
       "      <td>0.00668</td>\n",
       "      <td>0.143356</td>\n",
       "      <td>0.231839</td>\n",
       "      <td>0.091570</td>\n",
       "      <td>0.329231</td>\n",
       "      <td>0.147692</td>\n",
       "      <td>0.038217</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>3.847148</td>\n",
       "      <td>25.0</td>\n",
       "      <td>94.041968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>3.813095e-04</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.315986</td>\n",
       "      <td>0.200228</td>\n",
       "      <td>0.078522</td>\n",
       "      <td>0.298846</td>\n",
       "      <td>0.141923</td>\n",
       "      <td>0.033683</td>\n",
       "      <td>0.014277</td>\n",
       "      <td>0.478726</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.642168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.064962e-07</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.692837</td>\n",
       "      <td>0.195603</td>\n",
       "      <td>0.074097</td>\n",
       "      <td>0.301154</td>\n",
       "      <td>0.133846</td>\n",
       "      <td>0.036416</td>\n",
       "      <td>0.013660</td>\n",
       "      <td>0.241231</td>\n",
       "      <td>14.8</td>\n",
       "      <td>4.149832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>260</td>\n",
       "      <td>6.752387e-02</td>\n",
       "      <td>0.04662</td>\n",
       "      <td>0.507900</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.074811</td>\n",
       "      <td>0.333846</td>\n",
       "      <td>0.132308</td>\n",
       "      <td>0.039483</td>\n",
       "      <td>0.010048</td>\n",
       "      <td>0.615208</td>\n",
       "      <td>13.4</td>\n",
       "      <td>8.629742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     config/batch_size  config/conv_layers  config/embedding_dim  \\\n",
       "48                  64                   4                   245   \n",
       "215                256                   5                   405   \n",
       "471                512                   5                   445   \n",
       "367                512                   5                   100   \n",
       "388                512                   5                   225   \n",
       "359                512                   5                    25   \n",
       "254                512                   3                   105   \n",
       "79                 128                   4                   135   \n",
       "53                  64                   5                   225   \n",
       "186                256                   5                   215   \n",
       "404                512                   5                   275   \n",
       "142                256                   4                    85   \n",
       "17                  32                   3                   105   \n",
       "172                256                   5                    90   \n",
       "297                512                   4                    10   \n",
       "319                512                   4                   200   \n",
       "162                256                   5                    10   \n",
       "165                256                   5                    35   \n",
       "24                  32                   4                   175   \n",
       "110                256                   3                    10   \n",
       "174                256                   5                   130   \n",
       "163                256                   5                    15   \n",
       "168                256                   5                    45   \n",
       "18                  32                   3                   115   \n",
       "4                   16                   4                   145   \n",
       "5                   16                   4                   300   \n",
       "22                  32                   4                    70   \n",
       "167                256                   5                    40   \n",
       "353                512                   5                    10   \n",
       "189                256                   5                   260   \n",
       "\n",
       "        config/l2  config/learning_rate      loss  rprec train  rprec test  \\\n",
       "48   9.914827e-07               0.00964  0.241608     0.242316    0.098725   \n",
       "215  1.584187e-07               0.00185  0.150563     0.224705    0.093210   \n",
       "471  1.732332e-09               0.00156  0.307133     0.216381    0.096421   \n",
       "367  3.840663e-09               0.00847  0.194887     0.217179    0.092560   \n",
       "388  2.105721e-08               0.00231  0.213107     0.216814    0.096675   \n",
       "359  2.496945e-08               0.12938  0.256727     0.218319    0.099074   \n",
       "254  9.521968e-02               0.80491  2.358417     0.251073    0.085161   \n",
       "79   1.846316e-04               0.00185  0.243835     0.220650    0.083026   \n",
       "53   2.069621e-02               0.13739  1.253451     0.239358    0.088685   \n",
       "186  1.265913e-07               0.00361  0.150869     0.225793    0.094648   \n",
       "404  5.209855e-02               0.28983  1.404204     0.244688    0.085539   \n",
       "142  8.924661e-05               0.00112  0.401994     0.205940    0.083761   \n",
       "17   1.144952e-06               0.00315  0.201066     0.227312    0.090389   \n",
       "172  2.773413e-09               0.00594  0.188959     0.218169    0.087084   \n",
       "297  3.783898e-06               0.01277  0.275304     0.203899    0.086429   \n",
       "319  9.868599e-02               0.72275  3.597202     0.233445    0.086079   \n",
       "162  3.329143e-08               0.03786  0.271823     0.207538    0.088003   \n",
       "165  8.116358e-09               0.04283  0.132487     0.221923    0.095260   \n",
       "24   7.011937e-08               0.00611  0.162733     0.240478    0.094577   \n",
       "110  8.466347e-05               0.10148  0.147650     0.226350    0.095357   \n",
       "174  1.321830e-09               0.00231  0.211680     0.213735    0.090666   \n",
       "163  2.025833e-06               0.00021  0.691975     0.202245    0.079024   \n",
       "168  1.288639e-09               0.03147  0.174413     0.219360    0.093065   \n",
       "18   1.720917e-08               0.00270  0.153714     0.232933    0.089252   \n",
       "4    9.125593e-06               0.00019  0.295068     0.211359    0.078748   \n",
       "5    2.745393e-02               0.00009  0.534142     0.194085    0.077654   \n",
       "22   5.710999e-09               0.00668  0.143356     0.231839    0.091570   \n",
       "167  3.813095e-04               0.00245  0.315986     0.200228    0.078522   \n",
       "353  1.064962e-07               0.00002  0.692837     0.195603    0.074097   \n",
       "189  6.752387e-02               0.04662  0.507900     0.218830    0.074811   \n",
       "\n",
       "     p@5 train  p@5 test  r@5 train  r@5 test  time_this_iter_s  \\\n",
       "48    0.341538  0.165769   0.040000  0.015395          2.053089   \n",
       "215   0.328077  0.165000   0.036903  0.013761          0.627006   \n",
       "471   0.321154  0.165000   0.036596  0.017662          0.396081   \n",
       "367   0.317692  0.164615   0.036657  0.015135          0.265311   \n",
       "388   0.318462  0.164615   0.035424  0.015232          0.309438   \n",
       "359   0.317308  0.164231   0.039383  0.015402          0.363311   \n",
       "254   0.354615  0.161923   0.042400  0.014133          0.265382   \n",
       "79    0.326923  0.160769   0.037476  0.012908          0.714866   \n",
       "53    0.351538  0.159615   0.041451  0.016235          2.469692   \n",
       "186   0.327308  0.159615   0.037542  0.013152          0.577506   \n",
       "404   0.355385  0.159231   0.042308  0.013401          0.353688   \n",
       "142   0.305769  0.158462   0.035289  0.014724          0.452694   \n",
       "17    0.331538  0.158462   0.036938  0.013496          3.430244   \n",
       "172   0.318462  0.157692   0.037576  0.013890          0.063025   \n",
       "297   0.313462  0.157308   0.035372  0.015386          0.307873   \n",
       "319   0.333462  0.156538   0.040025  0.015092          0.227958   \n",
       "162   0.306154  0.156154   0.035161  0.015226          0.603040   \n",
       "165   0.326923  0.155769   0.038489  0.013683          0.593711   \n",
       "24    0.342308  0.155769   0.039229  0.013841          3.938676   \n",
       "110   0.328846  0.155385   0.036225  0.013977          0.467893   \n",
       "174   0.312308  0.152692   0.034603  0.013917          0.565687   \n",
       "163   0.300385  0.151923   0.034870  0.016532          1.060080   \n",
       "168   0.324615  0.149231   0.039325  0.014940          0.670415   \n",
       "18    0.337692  0.149231   0.038205  0.012728          1.759004   \n",
       "4     0.315769  0.148462   0.036032  0.013964          6.924939   \n",
       "5     0.297308  0.148462   0.034289  0.016381          5.989740   \n",
       "22    0.329231  0.147692   0.038217  0.012545          3.847148   \n",
       "167   0.298846  0.141923   0.033683  0.014277          0.478726   \n",
       "353   0.301154  0.133846   0.036416  0.013660          0.241231   \n",
       "189   0.333846  0.132308   0.039483  0.010048          0.615208   \n",
       "\n",
       "     training_iteration  time_total_s  \n",
       "48                 16.6     34.066409  \n",
       "215                25.6     16.211258  \n",
       "471                27.2      9.514649  \n",
       "367                26.6      6.984504  \n",
       "388                31.2      9.989760  \n",
       "359                11.2      3.916391  \n",
       "254                29.0      7.819533  \n",
       "79                 23.8     16.914875  \n",
       "53                 11.8     28.320639  \n",
       "186                24.2     13.803180  \n",
       "404                14.2      4.455094  \n",
       "142                20.8      9.239584  \n",
       "17                  9.0     31.350618  \n",
       "172                24.4      1.634636  \n",
       "297                13.0      4.192668  \n",
       "319                37.2      8.677094  \n",
       "162                14.8      8.952818  \n",
       "165                14.8      9.016412  \n",
       "24                 20.2     78.494808  \n",
       "110                11.6      5.331862  \n",
       "174                30.4     16.872417  \n",
       "163                 2.0      1.502945  \n",
       "168                24.6     15.154624  \n",
       "18                 16.0     25.424808  \n",
       "4                  24.4    168.654531  \n",
       "5                  20.6    132.784690  \n",
       "22                 25.0     94.041968  \n",
       "167                22.0     10.642168  \n",
       "353                14.8      4.149832  \n",
       "189                13.4      8.629742  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by config (except trial index) and do the mean\n",
    "non_config_columns = ['config/__trial_index__', 'config/max_epochs']\n",
    "cfg_columns = [c for c in rdf.columns if c.startswith('config/') and c not in non_config_columns]\n",
    "non_results_cols = ['should_checkpoint', 'done', 'config/__trial_index__'] + non_config_columns\n",
    "rdfgb = rdf.drop(columns=non_results_cols).groupby(cfg_columns).mean(numeric_only=True).reset_index()\n",
    "print(len(rdfgb), \"configurations were tested\")\n",
    "rdfgb.sort_values('p@5 test', ascending=False).tail(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
